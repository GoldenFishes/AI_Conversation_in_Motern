### Allen: Rethinking MAS Design through Step-Level Policy Autonomy



## Abstract

We intruduce a new Multi-Agent System (MAS) —— Allen, designed to address two core challenges in current MAS design: (1) improve system's policy autonomy, empowering agents to dynamically adapt their behavioral strategies, and (2) achieving the trade-off between collaborative efficiency, task supervision, and human oversight in complex network topologies. 

Our core insight is to redefined the basic execution unit in the MAS，allowing agents to autonomously form different patterns by combining these units. We have constructed a four-tier  state architecture (Task, Stage, Agent, Step) to constrain system behavior from both task-oriented and execution-oriented perspectives. This achieves a unification of topological optimization and controllable progress.

Allen grants unprecedented Policy Autonomy, while making a trade-off for the controllability of the collaborative structure. The project code has been open-sourced at: https://github.com/motern88/Allen



## 1. Introduction

Multi-Agent Systems (MAS) can handle complex parallel tasks better than single-agent systems, attracting widespread attention in recent years. When designing a MAS, researchers often break it down into two sub-problems: 

- **Intra-Agent Architecture Design:** How to design an agent's internal logic/workflow.

- **Inter-Agent Collaboration Framework Design:** How to design the collaboration framework between agents.

For the first sub-problem—how to design an agent's internal logic/workflow—a key 2024 survey paper [[1](#Reference 1)] summarized various agent architectures. These were categorized into 18 distinct patterns, along with guidance on selecting the right pattern for different scenarios. These patterns include: prompt optimization and response generation, Retrieval-Augmented Generation (RAG), single-path and multi-path planning, self-reflection mechanisms, voting-based multi-agent collaboration, role-based collaborative frameworks, and debate-driven collective decision-making paradigms.

Currently, it has become extremely difficult to propose fundamental innovations at the level of agent behavior patterns - that is, to design completely novel behavior patterns for specific new scenarios. The good news is that we believe the current bottleneck for agents lies not in proposing more new patterns, but rather in making proper decisions to enable agents to use the most suitable behavior patterns - including specific workflows or task procedures - across different scenarios.

We argue that an agent's operational logic and behavior patterns should not be confined to a single, fixed paradigm. Instead, it should possess the capability to dynamically determine and select optimal patterns based on situational context. We define the scope and flexibility of such decision-making capacity as the system's **Policy Autonomy**, whose upper bound determines the system's intelligence and adaptability levels.

For instance, in some systems, agents are strictly constrained within predefined workflows, where their Policy Autonomy is limited to making choices at a few predetermined branch points. In other systems, Policy Autonomy manifests through the system's ability to autonomously select and combine multiple predefined agents with specialized functions according to task requirements.

Therefore, we reframe the first sub-goal—"designing reasonable internal agent logic/workflows"—as a more fundamental question:

- How to maximize a system's Policy Autonomy?

Concerning the second sub-problem—constructing the collaborative framework among agents—a paper published by Google in February 2025 [[2](#Reference 2)] states that the key to enhancing the performance of multi-agent frameworks lies in optimizing the topological structure. Our methodology aligns with this principle. First, we optimize the internal decision-making topology within each agent. Second, at the system level, we unlock the potential for optimizing the overall topology by empowering agents with the autonomy to define task workflows and determine communication timing with other agents.

Optimizing the topological structure of Multi-Agent Systems (MAS) can improve collaborative efficiency among agents. However, in practical applications, we must also consider two additional usability factors: task progress monitoring and human intervention capability. Yet, complex and flexible topological structures often conflict with both progress monitoring and human intervention. Therefore, we reformulate the second objective - designing the inter-agent collaborative task framework - as: 

- How can Multi-Agent Systems achieve optimal balance between collaborative efficiency, progress monitoring, and human intervention capability?

To achieve these two primary objectives, we redefine the minimal unit of agent execution and introduce a four-tier state hierarchy comprising Task, Stage, Agent, and Step. To this end, we have designed and implemented a Multi-Agent System named Allen.

Specifically, the contributions of this paper are as follows:

1. **Novel Perspective**: We introduce "System Policy Autonomy" as a novel perspective to guide the design and evaluation of agent systems.
2. **Execution Model**: We propose a Step-centric execution model to reconstruct the agent's operational logic. This model achieves a state-of-the-art level of System Policy Autonomy, enabling it to simulate and execute virtually any existing agent work pattern.
3. **Collaborative Architecture**: Building upon this execution model, we have constructed a four-tier collaborative architecture for the multi-agent system. This architecture strikes an exceptional balance among synergistic efficiency, progress observability, and human intervenability.



## 2. Related Work

If we examine the agent architectures from the perspective of 'Policy Autonomy,' a non-rigorous conceptual comparison is shown below:

<a id="Figure 1"></a>

![细粒度程度横向对比](./asset/细粒度程度横向对比.jpg)

- **Figure 1**: We evaluate different agent frameworks from the perspective of Policy Autonomy. The two ends of this spectrum represent two extreme paradigms: on the left, the token-wise approach treats a single token as the minimal unit of execution, thus offering the highest degree of Policy Autonomy. On the right, the workflow-wise approach uses a predefined workflow as the minimal unit of execution, resulting in the lowest Policy Autonomy. Our architecture, Allen, is positioned within this spectrum at the step-wise level, situated closer to the left side.

All current mainstream agent implementation frameworks  (not the final products) can all be evaluated along the Policy Autonomy spectrum shown in Figure [[1](#Figure 1)]. On the far left of the spectrum, representing the highest policy autonomy, are foundational LLMs, where every generated token is effectively an autonomous decision. On the far right, representing the lowest policy autonomy, are workflow-level systems. With these, we can only choose between pre-defined workflows and must build a new, complete, and adapted workflow for each new task and environment.

In Figure [[1](#Figure 1)], frameworks like LangChain [[3](#Reference 3)] and Dify [[4](#Reference 4)] implement Policy Autonomy at the workflow level, requiring custom workflow construction for each scenario. Strictly speaking, these are workflow implementation tools. In contrast, AutoGen [[5](#Reference 5)] achieves agent-wise Policy Autonomy - users only need to create new agents for novel scenarios, and the framework autonomously selects participating agents.

MetaGPT [[6](#Reference 6)] demonstrates even higher Policy Autonomy, achieving action-wise decision capability. Here, each agent can dynamically select from predefined actions during execution, where actions closely resemble agent behavioral patterns. Agents operate via think-act cycles, autonomously choosing different actions in each iteration from a skill and tool library. Thus, MetaGPT [[6](#Reference 6)] represents a highly flexible framework with superior Policy Autonomy.

However, we aim to avoid implementing task-specific actions when adapting to new scenarios. We believe action-level composition (using predefined skills/tools) doesn't represent the theoretical limit of agent Policy Autonomy. Instead, we pursue minimal executable units - when properly sequenced, these units should macroscopically generate diverse agent behaviors without manual logic adaptation. Natural transitions between units should enable autonomous workflow determination.

We define the minimal execution unit within our system as a "Step." Consequently, our Allen framework implements a system with step-wise policy autonomy. We posit that a purely token-wise system (such as a raw LLM), despite having the highest theoretical freedom, is impractical for complex tasks due to its lack of structured task-orientation and reliable state judgment. Furthermore, imposing fixed output validation on it is tantamount to degrading it to a workflow-wise system.

Therefore, to our knowledge, Allen is the agent system that achieves the highest degree of policy autonomy while maintaining a crucial balance between structure and flexibility. It empowers each agent to autonomously select and combine Steps, enabling it to dynamically generate and execute a sequence of Actions best suited for the current context. This achieves adaptive behavioral patterns without the need for manual pre-define.



## 3. Agent's Internal Mechanisms





## 4. Inter-Agent Collaboration Mechanism





## 5. Disscussion

**Agents Direct Communication.**

It is particularly noteworthy that in our Allen architecture's MAS, both the initiation and termination of inter-agent communication are determined by Agents. To be exact, it's by the Agent that created the most recent message. An Agent can proactively add a 'Send Message' action to create message for other Agents. Within the 'Send Message' capability, the Agent may also decide whether the message requires a reply. The absence of a reply requirement typically signifies the end of that communication instance.

This closely mirrors human behavior: we may interrupt colleagues at will during work simply because we choose to, without even asking first. Consequently, in Allen's architecture, prompt engineering must be carefully designed to prevent Agents from over-communicating about small things. Each communication requires both participating Agents to temporarily allocate their threads to the communication steps (Send Message and Process Message), diverting resources from their primary tasks - particularly when step-locking mechanisms are triggered [[Appendix C](#Appendix C)] .

We also added another rule: Agents can only communicate if they're on the same Task. Agents from completely different tasks can't message each other directly—all message must pass through the Task State.

**Message Intervening Agent Actions**

Here we specify what forms of message-based intervention are allowed. We require the Agent to autonomously generate Actions based on message content. Specifically, we should not manually define how the Agent should respond to every non-command message, but instead allow it to make it's own decisions.

Thus, our message-handling logic leads to a decision branch that generates actions. Specifically, it adds a skill step called 'Decision', where the Decision Step plans immediate short-term steps to interact with the MAS environment.

To achieve this, we introduce a new decison branch at both ends of the Agent's message-handling logic: the Send Message and Process Message skills. These skills can now insert an additional Decision Step when needed to enable environment interaction, going beyond simply replying  to or understanding messages.

**Agent processes multi-stage tasks concurrently**

Our system does not restrict Agents from accepting tasks across multiple stages simultaneously. However, since the Agent executes Steps in a single-threaded sequential manner, handling multi-stage task does not improve overall efficiency. Instead, it may lead to interleaved execution of Steps from different stages, potentially prolonging each stages's completion time.

In terms of task focus, Agents closely mimic human work patterns. We should keep an Agent focused on a single task stage whenever possible. To prevent Agents from handing too many stages concurrently, we can instantiate multiple functionally similar Agents to achieve true parallelism.

**From Single-Agent System to Multi-Agent System**

From the perspective of policy autonomy, when our decision granularity shifts from workflow-level to agent-level, a single-Agent system naturally evolves into a multi-Agent system. At this point, you gain the ability to select different Agents based on specific needs - where each Agent embodies a distinct workflow.

**Allen enables simple iteration and optimization**

Our framework can accommodate any model-level optimizations, context-level improvements, or tool-level methods, as the July 2025 survey [[8](#References 8)] pointed out for iteration directions. Our architectural innovation lies in redefining the operation mode of Multi-Agent Systems, while all model policies, model experiences, context prompts, context memories, and other module improvements can be freely replaced to adapt to the latest research approaches.



## 6. Conclusion

We introduce the Allen framework, a novel Multi-Agent System. Within this framework, we propose using 'Step' as the minimal execution unit, enabling agents to iteratively execute their workflows step-by-step. This approach can generalize to most scenarios with unprecedented policy autonomy, only requiring interaction with the system’s manager agent and no code modifications.

Furthermore, the Allen framework implements a step-wise execution paradigm. Using four-level states to define and track complex tasks and multi-agent collaboration processes, it effectively balances collaboration efficiency, progress visibility, and human intervention capability.



## Author Contributions





## References

<a id="References 1"></a>

[1] Liu, Yue, et al. "Agent design pattern catalogue: A collection of architectural patterns for foundation model based agents." *Journal of Systems and Software* 220 (2025): 112278.

<a id="References 2"></a>

[2] Zhou, Han, et al. "Multi-agent design: Optimizing agents with better prompts and topologies." *arXiv preprint arXiv:2502.02533* (2025).

<a id="References 3"></a>

[3] LangChain AI. "LangChain." *GitHub*, https://github.com/langchain-ai/langchain. Accessed 25 Oct. 2022.

<a id="References 4"></a>

[4] Langgenius. "Diffy." *GitHub*, https://github.com/langgenius/dify. Accessed 25 May. 2023.

<a id="References 5"></a>

[5] Wu, Qingyun, et al. "Autogen: Enabling next-gen LLM applications via multi-agent conversations." *First Conference on Language Modeling*. 2024.

<a id="References 6"></a>

[6] Hong, Sirui, et al. "MetaGPT: Meta programming for a multi-agent collaborative framework." *The Twelfth International Conference on Learning Representations*. 2023.

<a id="References 7"></a>

[7] Elman, Jeffrey L. "Finding structure in time." *Cognitive science* 14.2 (1990): 179-211.

<a id="References 8"></a>

[8] Gao, Huan-ang, et al. "A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence." *arXiv preprint arXiv:2507.21046* (2025).





## Appendix

For specific implementation details of the Allen architecture, please refer to the project's documentation (in Chinese) at:
https://github.com/motern88/Allen/blob/main/docs



<a id="Appendix A"></a>

### A. Skills and Tools

**Skill** refers to all LLM-driven derived capabilities. The key distinction lies in their prompt variations - each specific derived capability emerges based on different prompt configurations.

**Tool** represents capabilities that the LLM inherently lacks, but achieves through interfaces with external Agent modules. Compared to skills, tools are more aligned with real-world interactions, enabling the acquisition or modification of elements outside the Agent system.



#### A1. Skills

All skills inherit common methods from the base executor class.

**Planning**

The Agent uses the Planning skill to organize task execution steps, generating a multi-step execution plan.

Planning requires the ability to manipulate `AgentStep` within the Agent. `AgentStep` serves as the Agent's execution step manager, responsible for maintaining the Agent's step sequence. We employ prompt engineering to constrain the LLM to return planned step information in a specific format. Rule-based code then parses this information and adds the corresponding steps to `AgentStep`.

**Reflection**

The Agent employs the Reflection skill to evaluate whether executed steps align with expectations. If adjustments are needed, it generates a new multi-step execution plan; otherwise, it appends a summarization step.

Reflection requires access to historical step execution data and the capability to append steps to `AgentStep`. We compile the results of past executions and phase objectives into a structured format for LLM processing. Through prompt constraints, the LLM returns reflection outcomes and planned step information in a predetermined format. Rule-based code subsequently parses this data and updates `AgentStep` accordingly.

Note: The Reflection skill cannot access stage information directly; phase objectives are obtained from Planning Step.

**Summary**

The Agent uses the Summary skill to conclude and finalize a stage, marking its completion. It consolidates all step information within that stage and synchronizes it in the stage state.

The Summary skill cannot be planned during Planning—it is only planned when Reflection determines the task should end. Summary is solely responsible for aggregating the Agent's execution steps, not for delivering stage results. For example, if the stage goal is to output a text segment, the actual delivery process (e.g., via a tool like `send_message`) should be handled by a dedicated delivery tool, not the Summary skill.

Summary requires access to historical step execution data. We compile the results of past executions and stage objectives into a structured format for LLM processing. Through prompt constraints, the LLM returns summarized outcomes in a predetermined format. Rule-based code then parses this data and synchronizes it to the Stage State.

Note: The Summary skill obtains stage information from the stage's initial step—the Planning step.

**Instruction Generation**

This step generates the actual tool invocation instructions for the next tool step. Instruction Generation retrieves information about the next tool step and can update its content.

We input the next tool step's prompt information and instruction generation prompts into the LLM in a specific format, then capture the LLM's formatted instruction output. Rule-based code parses this information and updates the next tool step's instruction content accordingly.

**Think**
The Agent utilizes the Think capability to handle text generation tasks requiring historical step information. This represents standard LLM-based text generation in the MAS that incorporates contextual data from previous steps.

**Quick Think**
The Agent employs Quick Think for rapid response to text generation tasks that don't require historical step context. This constitutes a straightforward, single-instance LLM call/text generation within the MAS framework.

**Send Message**

A unidirectional message sent by an Agent to another Agent instance within the MAS system.

Send Message first evaluates whether the current Agent's available information meets the message-sending criteria (i.e., whether the correct message content is known to the current Agent).

- Information Retrieval Branch (activated when insufficient information exists):
  If the Agent lacks required information to send the message (determined by the LLM), it enters this branch to transform Send Message into a long-tail skill. A Decision Step is inserted to acquire additional information.
- Direct Message Branch (activated when sufficient information exists):
  Send Message aggregates all historical step execution data from the current stage, processes it via LLM according to the message intent, and delivers the message to the target Agent.

Implementation Details:

1. Message Delivery Mechanism

   The message body is transmitted through the Executor's return result `execute_output` (used to guide SyncState for state synchronization). `SyncState.sync_state` places the message into the message processing queue of Task State. The MAS system's message processing module periodically scans this queue to execute message delivery tasks.

2. Agent Communication Protocol/Flow

   Messages are processed by the receiver through appended steps (Process Message/Send Message):

   - If the sender requires a reply: The receiver gets appended with a Send Message step directed to the sender.
   - If no reply is needed: The receiver gets appended with a Process Message step (which doesn't involve message delivery or replies to other entities).

   Thus:

   - One-way messages are completed via Send Message → Process Message.
   - Multi-turn dialogues are implemented through a series of Send Messages followed by one final Process Message.

3. Stage Affiliation Rules for Message Steps (Send Message/Process Message)

   - If message delivery is task-phase-critical: Belongs to a stage. 

     Ensures stage completion waits for message delivery.

   - If message delivery is not task-phase-critical: Should not belong to any stage

     `StepState.stage_id` should be "no_stage". Stage completion proceeds unaffected by message delivery status.

4. Message Waiting Mechanism & Agent Step Locking
   - When awaiting replies: Sender assigns unique wait IDs to all recipients (None if not waiting).
   - When waiting: The initiating Agent won't execute any steps until all wait IDs are collected.

Agent-initiated Send Messages are typically task-phase-critical, thus require explicit stage_id specification during sending.

**Process Message**

The Agent processes a unidirectional message from another Agent instance within the MAS system, where the message explicitly requires no reply.

Upon receiving the message, the Agent uses the Process Message Step to invoke the LLM for handling the non-instructional portion of the message (the instructional part is processed by `agent_base.process_message`). Typically, this means the message needs to be digested and organized by the LLM, though it may also simply serve as the conclusion of a multi-turn dialogue.

Process Message understands and processes message content that requires no reply, while retaining the capability to react to message content through environmental interactions when necessary:

- No Behavioral Response Required
  Digests and comprehends the message content, recording important parts into persistent memory.

- Behavioral Response Branch (Activated When Needed)
  The primary purpose of this branch is to enable Process Message to initiate environmental interaction behaviors. This is achieved by inserting and appending a Decision Step to plan short-term reactive behaviors.

  Workflow:

  1. The LLM autonomously determines whether interaction behaviors are needed and returns corresponding instructions.
  2. Based on the LLM's returned instructions, we append and insert a Decision Step with matching attributes into the current Agent's step list.

**Task Manager**

The Task Manager is a special skill (typically only available to manager-level Agents) that handles task management and scheduling.

The Task Manager uses its own historical step information (such as previously obtained task and stage details) to generate commands for managing task progress. The managing Agent then uses these commands to operate corresponding components in the MAS system, executing real actions. For example:

- Using SyncState to update task and stage states.
- Sending messages to notify relevant Agents.

**Agent Manager**

The Agent Manager is a special skill (usually restricted to manager-level Agents) that controls and coordinates other Agents.

The Agent Manager refers to its historical step data (such as previously gathered Agent information) to generate commands for directing other Agents. The managing Agent then uses these commands to operate the MAS system’s components, carrying out the required actions.

**Ask Info**

The Ask Info skill allows an Agent to retrieve system/task details or information about other Agents.

Ask Info gives an Agent the ability to access external information, including other Agents' profiles and statuses.

- SyncState helps collect higher-level data (e.g., stage state, task state).
- The retrieved information is sent back to the Agent via Message.

We use prompt engineering to guide the LLM to return specific commands in a structured format. These commands instruct SyncState to perform targeted queries, and the results are relayed back to the Agent through messages.

**Tool Decision**

The Tool Decision skill allows an Agent to process the results of a long-tail tool and decide whether to continue or terminate its execution.

This skill invokes an LLM to handle the tool’s returned results and determines the next step—either guiding further tool usage (via instruction generation) or ending the call. If the tool’s execution continues, this skill appends an Instruction Generation step and another tool step for the Agent.

A long-tail tool call occurs when the tool’s results require repeated LLM verification and multiple executions. In such cases, the LLM iteratively decides the direction of each tool usage step.

After execution, the long-tail tool sends its results via SyncState (as a message), prompting the Agent to append a Tool Decision step to determine whether to continue or stop. Thus, the Tool Decision skill cannot be actively triggered by the Agent during Planning/Reflection—it is only activated by the long-tail tool.

Structure of a Long-Tail Tool Call:

Starts with Instruction Generation, ends with Too lDecision, and may include multiple (Instruction Generation → Tool Execution) cycles:

```python
[I.G.] -> [Tool] -> [ToolDecision] -> [I.G.] -> [Tool] -> [ToolDecision] -> ...
```

- The triggering of Tool Decision follows a standard cycle in MAS. Before executing this skill:

  Step (specific Tool execution) -> SyncState (generates command message) -> MessageDispatcher (distributes message to target Agent) -> Agent (processes message via `receive_message`) -> Step (inserts a Tool Decision Step)

- After executing this skill, if Tool Decision continues the tool call:

  Step (Tool Decision skill confirms continuing tool call and appends subsequent steps) -> Step (Instruction Generation) -> Step (corresponding Tool execution)

- After executing this skill, if Tool Decision terminates the tool call:

  Step (Tool Decision skill terminates further tool calls)

- For MCP tool's long-tail calls, one key issue is how to pass the initially returned `capabilities_list_description` through Tool Decision to the next Instruction Generation.

  In `tool_decision_config.yaml` prompts, we specify in the tool step's `text_content`:

  ```markdown
  Detailed prompt text specifying the concrete objectives for the tool's next invocation. If you have obtained the capabilities_list_description returned by MCP Server, you should specify the exact invocation format of the MCP Server capability here (please write the complete dictionary of the returned description for the selected capability).
  ```

**Decision**

A more flexible, real-time decision-making skill. This skill is decoupled from Stage and does not rely on Stage state for decisions. Additionally, all steps planned by Decision are inserted (rather than appended at the end).

Key differences from other decision-making skills:

- Stage-independent: Decision does not rely on Stage state, enabling more flexible responses to non-task-related decisions (e.g., replying to unexpected messages).
- Insert-based planning: Steps are inserted at priority positions rather than appended, giving Decision higher execution precedence.



#### A2. Tools

All our tools strictly adhere to the Model Context Protocol (MCP) standard. This unified approach enables:

All our tools are implemented based on the Model Context Protocol (MCP) standard. Therefore, we only need to implement one tool executor—`MCPToolExecutor`—which inherits from the base `Executor` class. This eliminates the need to create a separate executor class for each MCP Server. However, for skills, we implement a dedicated `SkillExecutor` class for each type of skill.

Our tool implementation includes:

- MCP Client: Provides basic MCP client functionality.
- MCP Tool Executor: The executor responsible for invoking specific MCP Server capabilities in the MAS system.

With this structure, we enable efficient scaling of any tool by loading various third-party MCP Servers into the MCP Client.

**MCP Client Implementation**

We implement the MCP Client class to provide MCP-related functionalities to the Executor. In practice, we add additional caching and divide MCP connection management into four layers (where Layers 1, 3, and 4 are maintained by the `MCPClient` class, while Layer 2 corresponds to the actual tool permissions stored in the MAS `AgentState`).

- Layer 1: `MCPClient.server_config`
  Stores the startup configurations of all supported MCP Servers in the MAS.

- Layer 2: `AgentState.tools`
  Contains the permissions for external tools (MCP services) that the agent is allowed to call. The available MCP services in this layer are a subset of those in Layer 1.

- Layer 3: `MCPClient.server_sessions`
  Maintains active MCP Server connection instances, where the key is the MCP Server name and the value is a `requests.Session` instance. The `server_sessions` dynamically connect to the MCP Servers permitted in Layer 2, ensuring that all required MCP Servers (based on agent permissions) remain actively connected.

- Layer 4: `MCPClient.server_descriptions`
  To avoid redundant overhead when fetching tool descriptions repeatedly, we also cache tool metadata. This layer stores detailed descriptions of available tools from the MCP Servers, where the key is the tool name and the value is its description. The `server_descriptions` retrieves tool names, descriptions, and usage formats from the active sessions in Layer 3 and stores them.

  When an agent retrieves full tool and skill prompts, the `server_descriptions` provides the necessary metadata. Similarly, when an agent executes a specific Tool Step or assembles a Tool Step prompt, the `server_descriptions` supplies the relevant tool description and invocation format.

**MCP Tool Executor Implementation**

The MCP Tool Executor enables agents to invoke any MCP (Model Context Protocol) server endpoint. This tool ensures compatibility with MCP-based server implementations in the MAS (Multi-Agent System).

From the agent's perspective, the MCP Tool connects to multiple MCP servers. However, from the MCP Server's viewpoint, this tool acts as its client.

Tool Execution Workflow in MAS: 

1. Fetch MCP Server-Level Descriptions
   - The agent retrieves predefined prompt descriptions for each tool server through its decision-making Skill Executor.
   - Based on these descriptions, the agent decides whether to invoke the tool.
2. Fetch MCP Server Capability-Level Descriptions
   - The MCPTool Executor queries the MCPClient to obtain a list of all available capabilities supported by the target MCP Server.
   - The agent then selects which specific capability to invoke.
3. Execute the Selected MCP Server Capability
   - Based on the capability list from Step 2, the agent chooses a specific function to call.
   - The MCPTool Executor triggers execution via the MCPClient.execute() method, passing the capability name and input parameters, then returns the result.

During actual execution of the MCP Tool, both instruction generation and tool decision-making skills can access the basic MCP invocation prompts. It's important to note that while Agents already know how to invoke tools in MAS, they are not familiar with the MCP protocol.

The key purpose of these basic MCP invocation prompts is to provide Agents with visible interaction prompts related to MCP protocol execution, specifically:

1. How to generate specific instructions for retrieving MCP Server capability lists, and how to interpret the returned capability lists;
2. How to generate parameters for specific MCP Server capability calls, and how to understand the returned results from capability execution.

**Actual Invocation of MCP Client**

The MCP Client itself serves to manage connection sessions, and we intend to maintain only one globally unique MCP Client instance throughout the entire MAS. Given that our MAS architecture follows a multi-threaded parallel model with synchronous logic within each thread, we aim to enable concurrent execution of multiple MCP Client method calls within Agents (rather than sequential blocking). Our objectives are:

- Enable parallel MCP operations within the same Agent
- Allow multiple Agents to share the same MCP Client event loop

To achieve this, we need to implement a **synchronous wrapper** that internally uses `asyncio.run_coroutine_threadsafe` to submit tasks to the **global event loop thread**. This approach ensures:

- When an Agent calls MCPClient → The entire system won't hang (only blocks the calling Agent thread)
- When multiple Agents call MCPClient → Concurrent execution occurs (since MCPClient runs in the event loop thread with asynchronous scheduling)
- Even when an Agent wants to **initiate multiple concurrent MCP calls within a single Step**, this can be achieved via `asyncio.gather` in the MCPClient event loop

Consequently, we've separately implemented two key classes:

1. `AsyncLoopThread` Class:
   - Provides an asynchronous environment for the MultiAgentSystem
   - Implements an asynchronous event loop thread for running async tasks in multi-threaded environments
   - Enables Agents and Executors in MAS to submit async tasks to `AsyncLoopThread` without causing additional blocking
2. `MCPClientWrapper` Class:
   - Primarily used for invoking `MCPClient` methods within MAS
   - Responsible for submitting `MCPClient` calls to the asynchronous event loop thread (`AsyncLoopThread`)
   - As a result, instead of passing `MCPClient` instances directly, MAS provides each Agent and tool Executor with an `MCPClientWrapper`
   - Invoking `MCPClientWrapper` enables asynchronous calling of `MCPClient` methods within MAS



<a id="Appendix B"></a>

### B. Presistent Memory

In the Allen architecture's MAS, agent execution is divided into individual Steps. Each Step recomposes its prompts and does not share context with others. To address agents' long-term memory needs across Steps, Stages, and Tasks, we implemented the Persistent Memory mechanism.

**Format of Persistent Memory**

We initialize a dictionary in Agent State (`agent_state["persistent_memory"] = {}`). During each Step execution, new memory entries are added with: 

- Key: Timestamp (ISO format)
- Value: Memory content (natural language or structured data)

```python
{
	"20250613T103022":"I've done...",
    "20250613T103523":"I'm doing...",
    "20250613T104023":"Recording task information...",
}
```

**Persistent Memory Management**

We have independently implemented a prompt that teaches the Agent to understand and manage persistent memory. This is integrated into the base Executor class used in every step, which includes methods to parse persistent memory instructions from LLM outputs and apply corresponding operations.

The Agent is allowed to manage its persistent memory using the following commands:

- **Append new persistent memory**
  Use the `add` command with new memory content. Append new persistent memory by adding the following formatted text to the output results:

  ```python
  <persistent_memory>
  [{"add":"Persistent memory content to append"}]
  </persistent_memory>
  ```

- **Delete existing memory entries**
  Use the `delete` command with corresponding timestamps to remove specific memory entries. Delete/modify existing persistent memory by adding the following formatted text to the output results:

  ```python
  <persistent_memory>
  [{"delete":"Timestamps for permanent memory deletion"}]
  </persistent_memory>
  ```



<a id="Appendix C"></a>

### C. Communication Step Lock

In our MAS, agents communicate with other components or agents through Send Message and Process Message skills executed at the Step level. To prevent dependent Steps (those requiring responses from pending Send Message operations) from executing prematurely and causing failures, we introduce the StepLock mechanism. 

The StepLock mechanism can suspend an agent's Step execution while awaiting critical message responses. Execution only resumes after all StepLocks are released (i.e., when all required message responses are successfully received). This ensures the logical dependencies between communication-dependent Steps and other Steps remain intact.

The StepLock mechanism in communication scenarios involves three core components: message reception logic (`AgentBase.received`) and Agent State, Send Message, and system message protocol (`Message`). We will systematically examine our key design consideration and the StepLock operation within those components.

**Message**

As the standard message format for inter-agent communication in our MAS, the Message dictionary includes two dedicated fields for StepLock coordination:

1. `waiting (Optional[List[str]])`
   (Sender-specified) Contains unique wait IDs corresponding to each receiver in `List[str]`
   - When the sender requires response(s): Generates a unique wait ID per receiver
   - Blocks all subsequent Steps until all wait IDs are released
   - Default: `None` (no waiting required)
2. `return_waiting_id (Optional[str])`
   (Receiver-specified in response) Echoes the sender's original wait ID
   - Mandatory inclusion when responding to messages with `waiting` IDs
   - Enables sender to release the corresponding wait lock
   - Default: `None` (no ID to return)

**Send Message**

1. When the Send Message skill calls the LLM to generate a preliminary message body, the LLM only needs to determine whether to reply and whether to wait.

2. After the Send Message skill parses the LLM output, it will determine if the LLM considers the current message needs waiting.

   If waiting is required, it will automatically generate a unique waiting ID for each receiver in the preliminary message body, replacing the `["waiting"]` in the LLM-generated preliminary message body, and add the unique waiting ID to `agent_state["step_lock"]`.

   At this point, the `message["waiting"]` field value has changed from a boolean bool to an optional list containing unique waiting IDs for each receiver `optional[list[str]]`.

3. When the Send Message skill constructs the execute_output, it converts the LLM-generated preliminary message body into the MAS general message format Message:

   At this time, it constructs the `return_waiting_id` field value by attempting to extract it from `step_state.text_content`.

   (Generally, if an Agent receives a message with a `message["waiting"]` field value, when adding a reply step Send Message Step, it will extract the corresponding unique waiting ID that needs to be returned and place it at the end of the step's `text_content`.)









