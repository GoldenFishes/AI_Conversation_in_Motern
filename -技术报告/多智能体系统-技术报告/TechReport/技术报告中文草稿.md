







## Abstract







## 1. Introduction

Multi-Agent System 拥有单Agent所不具备的对复杂并行任务的适应能力，近年来受到大家的普遍关注。大家思考如何构建一个 Multi-Agent System 时往往会将其拆分成两个子问题：

- 1.如何构建Agent内部工作逻辑/模式
- 2.如何构建Agent和Agent之间协作执行任务的关系框架



对于第一个子问题——如何构建Agent内部工作逻辑/模式，24年一篇具有代表性的综述【[Agent Design Pattern Catalogue](https://arxiv.org/html/2405.10467v4)】总结了各个Agent架构。其被分为了18种不同的模式，并给出了不同场景下如何决策具体模式的指导。这些模式包含：提示/响应优化、检索增强生成、单/多路径规划、自我反思、基于投票/角色/辩论的多Agent合作等等。

时至今日，新的工作很难再在Agent行为模式上创新：提出一种新的模式，用于处理一种此前从未考虑到的具体场景。不过好消息是，我们认为当前的Agent的瓶颈不在于提出更多新的模式了，而是在于如何合理地决策使得Agent能够在不同场景下使用最合适的行为模式，具体工作逻辑或任务流程。

我们认为一个Agent工作逻辑/模式的能力不应当只实现某种单一的模式，而需要能够决策选择合适当前场景下的模式。我们定义该决策的程度，受整个系统中**决策自由度（Policy Autonomy）**的上限决定。即有的Agent系统只允许预先定义好一套工作流，在运行时只能严格遵从工作流的逻辑，系统的Policy Autonomy只在预定义好的工作流的几个的分支节点出现；有的系统允许预先定义多个不同的Agent，系统的Policy Autonomy体现在可以自主决策使用哪些Agent。

因此，我们重新描述我们的第一个目标——构建合理的Agent内部工作逻辑/模式为：

- 如何提高整个系统中的Policy Autonomy？



对于第二个子问题——如何构建Agent和Agent之间协作执行任务的关系框架。Google在25.2月的一篇文章【[ Multi-Agent Design](https://arxiv.org/abs/2502.02533)】中强调多Agent框架性能提升的核心是优化拓扑结构。我们通过在构建Agent内部逻辑时优化Agent内部的拓扑结构，通过在多Agent系统构建时赋予Agent来决策任务执行的能力（赋予Agent自主规划与其他Agent的通信时机、定义任务流程的能力）来获得在多Agent系统层面优化拓扑结构的潜力。

优化Multi-Agent System的拓扑结构可以带来多Agent的协同效率的提升，然而在实际使用中，我们往往还关注已用性的另外两个点：任务进度可监控 与 人类可干预。然而，复杂自由的拓扑结构往往与任务进度可监控、人类可干预程度相冲突。因此，我们也重新描述第二个目标——构建Agent间协作执行任务的框架为：

- Multi-Agent System 如何实现协同效率、进度监控与人类可干预之间的平衡？



我们通过重新定义Agent执行的最小单元，并同步实现task、stage、agent和step四种状态层级来实现以上两个目标。我们将我们的Multi-Agent System命名为Allen。具体而言，本文贡献如下：

- 我们提出一种新的视角“系统Policy Autonomy”来指导Agent系统的构建工作。

- 我们提出一种以Step为最小执行单位的视角来重构Agent执行逻辑/模式。该方法使得我们实现了当前最高的系统Policy Autonomy，它几乎可以执行任何一种Agent工作模式。
- 我们基于已实现的Agent执行逻辑，构筑了由四种状态层级区分的多Agent协同任务架构，完美平衡了协同效率、进度可监控 与 人类可干预。





## 2. Related Work

如果以 Policy Autonomy 的视角下审视不同的Agent架构，一种不严谨的横向比较方式如图所示：

![细粒度程度横向对比](./asset/细粒度程度横向对比.jpg)

- 图【1】注：我们从**决策自由度（Policy Autonomy）**的视角来衡量不同Agent框架。图中左侧和右侧代表着两个极端：**Token Wise** 以 token作为系统的最小单位，决策自由度最高；**Workflow Wise** 以workflow为系统的最小执行单位，决策自由度最低。其中我们的架构——Allen属于较靠近左侧的的step wise层级。

当今主流的用于实现Agent的框架（而非产品）均可以在图【1】中的坐标轴中表示。在坐标轴的最左边代表决策自由度最高，例如原始的LLM，实际上每个token对于llm来说都是一次自主决策。坐标轴的最右侧代表决策自由度最低，例如工作流级别的决策自由度，我们只能在不同工作流之间选择，并且需要为每个新环境新场景构建新的适配的完整工作流。

其中Langchain【[langchain](https://github.com/langchain-ai/langchain)】等框架的决策自由度是在workflow层面实现，这意味着我们需要为每个场景搭建属于自己的工作流。严格来说，这是一种实现workflow的工具。而AutoGen【[AutoGen](https://arxiv.org/pdf/2308.08155)】具备 agent wise 的决策自由度，其中我们只需要面对新场景时构建新的的Agent，在该框架中可以自主地选择有哪些Agent参与任务。

MetaGPT【[MetaGPT](https://arxiv.org/html/2308.00352v7)】做到了相比上述框架更高的决策自由度，其具体实现的action wise级别的决策自由度。该框架下的每个Agent都可以根据情况选择执行不同的预先定义好的action，此时的action就已经非常接近一个Agent的运行模式的概念了。其中Agent在运行时会执行think - act循环，且能够在该循环中每次都自主决策使用不同的action。这些action由候选技能和工具库中组装而成。因此MetaGPT【[MetaGPT](https://arxiv.org/html/2308.00352v7)】已经是一个相当灵活且具有很高决策自由度的Agent框架了。

然而我们仍然不希望在适配新任务时去实现一个个具体的action，我们认为由多种技能和工具组成的action仍然不是一个agent系统决策自由度的极限。我们试图寻找一个Agent的最小执行单元，我们只需要排列这些最小的执行单元，就能够在宏观上产生不同的Agent执行逻辑与模式。并且我们无需为新任务手工地适配工作逻辑，只要实现每个最小执行单元自然的相互过渡，就能够在宏观上实现由Agent自主地决定其具体工作逻辑。

我们将系统中的最小执行单元定义为一个个Step，因此最终我们 Allen 框架实现了一个 具备 step wise 决策自由度的系统。并且由于 token wise 的纯 llm system 往往不具备不同的Agent工作模式和严谨的任务判断，如果只是直接给LLM加上固定的输出指令检测则实际上会形成workflow wise的决策自由度。因此 Allen 是我们已知决策自由度最高的系统，它实现了Step wise 的决策自由度，即便Agent能够自主决定何时使用什么step，从而组合出一系列的具体行为模式action，故而每个Agent都能决定出自己在当前环境下的最佳行为模式action，而不需要我们手动预设。





> ChatGPT agent，Manus，Genspark，Comet，Fellou，Warmwind，NeuralOS
>
> 
>
> LangGraph，Llamalndex，FastGPT，LobeChat，SWE Agent
>
> 
>
> 多Agent框架：CAMEL，AgentScope
>



## 3. Agent‘s Internal Mechanisms

本章我们将介绍我们如何构建一个合理的Agent内部工作逻辑/模式。在第一章Introdouction部分，我们已经将这个目标转化为“如何提高一个单Agent系统的决策自由度（Policy Autonomy）”。

一个自然产生的问题是，如何将综述【[Agent Design Pattern Catalogue](https://arxiv.org/html/2405.10467v4)】中总结的各种Agent工作模式（例如反思、规划等）动态融合到一个Agent执行流程中；或者说，如何在这样一个Agent内部，有Agent自主决定何时反思、何时规划以及何时调用工具？我们认为它需要实现两个标志性的能力：

- Agent能够决定使用什么工具与技能
- Agent能够决定自身工作逻辑

从 Policy Autonomy 的角度思考，当整个系统的决策自由度越高，系统越容易实现上述两个标志性的能力。Agent能够决定使用什么工具与技能，该能力要求我们的Policy Autonomy在工具与技能层面。Agent能够决定自身工作逻辑，该能力要求我们的自身工作逻辑是动态的。一个较为自然的结合就是有Agent自主决策一个个的工具与技能从而形成一个完整动态的工作逻辑，从而实现Agent能够决定和改变自身工作逻辑。

因此这个问题缩小到了我们去实现一个在工具和技能层面决策的Agent执行机制。并且这个每次产生决策单元足够的小，从而可以通过每一次决策出的小单元组成一个个宏观的Agent内部工作模式。

我们定义了我们Agent执行的最小单元为一个Step，同时这也是我们系统的最小决策单元，一些step可以决定下一个step执行什么内容。这样，我们只需要尽可能地实现一些基础的Step，然后一切交给LLM去决策何时使用具体的Step，从而实现一个极易拓展地，能够适应任何任务的Agent动态工作逻辑。

从拓扑结构的角度看待我们的Step，会发现一些Step是相互关联的，例如Planning Step，Reflection Step，Decision Step等都具备为Agent添加其他Step的能力。所以在我们所有的Step中，可以认为上述的Step是指向其他Step的。Agent的执行可以从这些Step的执行后跳转去执行其他的Step，例如Planning Step规划了一些新的Step。但同时被规划的新的Step有时又可以重新规划一些已执行过，且具备决策和规划能力的Step。故而由所有Step组成的整个空间里，在这些可执行Step的指向关系中，存在多个环结构。从而确保Agent具备自主持续执行和运转下去的能力，而不需要人类时不时地“上发条”。



### 3.1 Execution Process of Step

现在我们介绍整个系统的最小执行单元——Step是如何被执行的。Step有两种类型，分别为技能和工具。我们将所有需要调用LLM的步骤统称为技能，所有不调用LLM的步骤统称为工具。我们技能和工具的实现见附录【】

一次Step的执行可能会进行一次技能调用也可能会执行一次工具调用。Step在实际执行时的具体流程如下图所示：

<img src="./asset/步骤Action.jpg" alt="步骤Action" style="zoom: 14%;" />

- 图【】注：Step的实际执行流程。StepState承载了Step的状态信息，当我们执行某一个Step时，Router会根据StepState中记录的信息调用具体的Executor，具体的skills/tools executor会根据Step State的内容执行具体交互行为，随后额外生成指令用于指导SyncState组件进行任务层面的状态同步。

在具体实现中，我们为每个要执行的具体Step都实例化了一个StepState用于承载Step的唯一标识、类型、步骤意图等详细的执行信息。在Agent的每次Action中，当前要被执行的Step会被处理。Agent会首先将StepState中记录的executor信息传递给Router，Router会将StepState分发给对应的executor实例。

如果是Skill Executor，则会在Executor内完成对Agent自身状态及StepState的更新；如果是Tool Executor，则会在Executor内完成对外部环境的实际交互与StepState的更新。而如果需要同步非自身状态例如任务信息或其他Agent信息，则通过全局的SyncState实现。Executor执行结束会返回用于指导SyncState进行全局状态更新的指令，SyncState会在Agent的一次Action中显示地调用作为该次Action的结束。





### 3.2 The Action of Agent











## 4. Inter-Agent Collaboration Mechanism



综述【[Agent Design Pattern Catalogue](https://arxiv.org/html/2405.10467v4)】提到的挑战：

- 由于整个生态系统中各种利益相关者，基于Foundation Model的Agent、非Agent AI Model 和 非AI软件应用程序之间的交互，问责过程非常复杂。高度自主的Agent可以委派甚至创建其他Agent或工具来执行某些任务。在这种情况下，责任和问责机制可能在多个实体之间交织在一起。











## 5. Disscussion





- 多Agent系统和单Agent系统

  从系统**决策自由度**的角度来说，当我们的决策自由度从workflow wise跨越至agent wise时，单Agent系统自然而然地演变成多Agent系统了。至此你期望能够根据不同的需要去选择不同的Agent（每个Agent背后代表了一条独特的工作流/工作逻辑）



- 系统易于迭代和优化

  我们的框架可以兼容任何Model/Context/Tool层面的优化和改进方法，正如25.7月综述【[A Survey of Self-Evolving Agents](https://arxiv.org/html/2507.21046v1)】所指出的迭代方向。我们的架构创新在于重新定义Multi-Agent System运行模式，而一切的model policy、model experience、context prompt、context memory等模块的改进措施均可以适配最新研究方法。





## 6. Conclusion





## References





## Appendix
