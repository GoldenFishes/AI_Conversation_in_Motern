## 1. 多Agent协作初步调研：



### 1.1 MetaGPT：The Multi-Agent Framework

多代理框架：为 GPT 分配不同的角色，以形成用于复杂任务的协作实体。

该项目 48.6k Star 和 5.8k Fork ：[geekan/MetaGPT: 🌟 The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming](https://github.com/geekan/MetaGPT?tab=readme-ov-file)

该团队公开的论文：

[MetaGPT: Meta Programming for a Multi-Agent Collaborative Framework](https://arxiv.org/html/2308.00352v7)

MetaGPT支持AFlow自动生成工作流框架

[AFlow: Automating Agentic Workflow Generation](https://arxiv.org/abs/2410.10762)

MetaGPT其他支持实现的功能：

[FACT](https://arxiv.org/abs/2410.21012)，[SELA](https://arxiv.org/abs/2410.17238)，[SPO](https://arxiv.org/pdf/2502.06855)，[AOT](https://arxiv.org/pdf/2502.12018)



MetaGPT项目的第一篇论文于23.8月公开，其被ICLR 2024接收，并在同期LLM-based Agent category工作中排名第一

------

![image-20250303143754521](./asset/MetaGPT1.png)

图一注： **MetaGPT 和现实世界的人类团队之间的软件开发 SOP。**在软件工程中，SOP 促进不同角色之间的协作。 MetaGPT 展示了它将复杂任务分解为分配给各种角色（例如，产品经理、架构师、工程师等）的特定可作程序的能力。

![image-20250303144423195](./asset/MetaGPT2.png)

图二注：通信协议示例（左）和带有可执行反馈的迭代编程示例（右）。**左**：代理使用共享消息池发布结构化消息。他们还可以根据自己的配置文件订阅相关消息。**右**：生成初始代码后，Engineer 代理运行并检查错误。如果发生错误，代理会检查存储在内存中的过去消息，并将其与 PRD、系统设计和代码文件进行比较。

#### 角色专业化

明确的角色专业化可以将复杂的工作分解为更小、更具体的任务。 解决复杂的任务或问题通常需要具有不同技能和专业知识的座席合作，每个座席都为特定问题提供量身定制的专业输出。

在 MetaGPT 中，我们指定代理的配置文件，其中包括他们的名称、配置文件、目标和每个角色的约束。 我们还为每个角色初始化特定的上下文和技能。例如，产品经理可以使用 Web 搜索工具，而工程师可以执行代码，如图 [2](https://arxiv.org/html/2308.00352v7#S3.F2) 所示。

**每个代理都会监控环境**（*即* MetaGPT 中的消息池）以发现重要的观察结果（*例如，*来自其他代理的消息）。这些消息可以直接触发作或帮助完成作业。

#### 跨代理的工作流

通过定义代理的角色和作技能，我们可以建立基本的工作流程。在我们的工作中，我们在软件开发中遵循 SOP，这使得所有代理都能按顺序工作。

具体来说，如图 [1](https://arxiv.org/html/2308.00352v7#S1.F1) 所示，在获得用户需求后，产品经理进行全面分析，制定详细的 PRD，其中包括 User Stories 和 Requirement Pool。这用作初步的功能分解。然后，结构化的 PRD 被传递给架构师，架构师将需求转换为系统设计组件，例如文件列表、数据结构和接口定义。一旦在系统设计中捕获，信息就会被直接发送给项目经理进行任务分配。工程师继续执行指定的类和函数，如图 2 所示（详见[图 2](https://arxiv.org/html/2308.00352v7#S3.F2)）。在接下来的阶段，QA 工程师制定测试用例以强制实施严格的代码质量。

![image-20250303144848874](./asset/MetaGPT3.png)

图三注：显示 MetaGPT 中软件开发过程的图表，强调其对 SOP 的严重依赖。

#### 结构化通信接口

当前基于 LLM 的多代理框架（Li 等人，[2023](https://arxiv.org/html/2308.00352v7#bib.bib28);Zhuge 等人，[2023](https://arxiv.org/html/2308.00352v7#bib.bib77);Zhang et al.，[2023 年一](https://arxiv.org/html/2308.00352v7#bib.bib71);Park 等人，[2023](https://arxiv.org/html/2308.00352v7#bib.bib42)) 利用不受约束的自然语言作为通信接口。

然而，尽管自然语言用途广泛，但一个问题出现了：纯自然语言交流是否足以解决复杂的任务？ 例如，在电话游戏中（或中文耳语）2，经过几轮沟通，原始信息可能会相当失真。 受人类社会结构的启发，我们建议使用结构化通信来构建代理的通信。我们为每个角色建立架构和格式，并要求个人根据其特定角色和背景提供必要的输出。

如图 [3](https://arxiv.org/html/2308.00352v7#S3.F3) 所示，Architect 代理生成两个输出：系统接口设计和序列流程图。这些包含系统模块设计和交互序列，它们是工程师的重要交付成果。 与 ChatDev 不同（Zhao 等人，[2023](https://arxiv.org/html/2308.00352v7#bib.bib73))，MetaGPT 中的代理通过文档和图表（结构化输出）而不是对话进行通信。这些文档包含所有必要的信息，防止不相关或缺失的内容。

#### 发布-订阅机制

共享信息在协作中至关重要。 例如，架构师和工程师经常需要引用 PRD。但是，正如以前的工作所表明的那样，每次都以一对一的方式传达此信息（Li 等人，[2023](https://arxiv.org/html/2308.00352v7#bib.bib28);Zhao 等人，[2023](https://arxiv.org/html/2308.00352v7#bib.bib73);Zhang et al.，[2023 年一](https://arxiv.org/html/2308.00352v7#bib.bib71))可能会使通信拓扑复杂化，从而导致效率低下。

为了应对这一挑战，一种可行的方法是将信息存储在全局*消息池中*。 如图 [2](https://arxiv.org/html/2308.00352v7#S3.F2) 所示（左），我们引入了一个共享消息池，它允许所有代理直接交换消息。这些代理不仅**在池中发布**其结构化消息，而且还透明地访问来自其他实体的消息。 任何代理都可以直接从共享池中检索所需信息，无需询问其他代理并等待他们的响应。这提高了通信效率。

与每个代理共享所有信息可能会导致信息过载。 在任务执行期间，代理通常更喜欢只接收与任务相关的信息，并避免因不相关的细节而分心。 这些信息的有效管理和传播起着至关重要的作用。 我们提供了一种简单有效的解决方案**订阅机制**（如图 [2](https://arxiv.org/html/2308.00352v7#S3.F2) （左）所示）。 代理不依赖对话，而是利用特定于角色的利益来提取相关信息。他们可以根据其角色配置文件选择要关注的信息。 在实际实现中，代理仅在收到其所有先决条件依赖项后才会激活其作。如图 [3](https://arxiv.org/html/2308.00352v7#S3.F3) 所示，架构师主要关注产品经理提供的 PRD，而来自 QA 工程师等角色的文档可能不太重要。





MetaGPT的后续论文AFlow于24.10月公开，其被ICLR 2025接收，并在同期LLM-based Agent category工作中排名第二

------

大型语言模型 （LLM） 在解决不同领域的复杂任务方面表现出了巨大的潜力，通常是通过采用遵循详细说明和作顺序的代理工作。但是，构建这些工作流需要大量的人力，从而限制了可扩展性和通用性。最近的研究试图自动生成和优化这些工作流程，但现有方法仍然依赖于初始人工设置，无法实现完全自动化和有效的工作流程生成。

为了应对这一挑战，我们将工作流优化重新表述为代码表示工作流上的搜索问题，其中 LLM 调用节点由边沿（edge）连接。我们介绍了 AFLOW，这是一个自动化框架，它使用 Monte Carlo Tree Search 有效地探索这一领域，通过代码修改、树状结构体验和执行反馈迭代优化工作流程。

![image-20250303151113697](./asset/AFlow1.png)

图一注：node、operator 和 edge 的示例。我们演示了 Node 的可选参数、一些 Operator 的结构以及 Edge 的常见表示形式。

#### 代理工作流

我们将代理工作流 W 定义为一系列由边沿连接的 LLM 调用节点，以定义执行顺序，表示为 N = {N1，N2,...,Ni ...}。每个节点 Ni 代表 LLM 执行的特定作，其特征如下。

- 模型 M：在节点 Ni 处调用的特定语言模型。
- 提示 P：在每个节点提供给模型的输入或任务说明。
- 温度 τ：控制 LLM 在节点 Ni 处输出随机性的参数。
- 输出格式 F：模型输出的结构格式 （例如，xml、json、markdown、raw）。工作流中的节点应提供不同的输出格式。

边沿 E 表示定义节点关系的摘要结构，控制执行顺序。边沿 E 可以通过各种结构表示，例如：

- Graph （Zhuge et al. 2024）：一种灵活的结构，表示节点之间的分层、顺序或同等等位关系，允许复杂的分支工作流程。
- Neural Network（Liu et al.， 2023）：一种可以表示节点之间复杂、非线性关系的结构，允许基于输入和反馈的自适应和可学习的工作流程。
- Code（胡 et al.， 2024）：一种全面的表示，可以表达线性序列、条件逻辑、循环，并结合图形或网络结构，为 LLM 的工作流执行提供最精确的控制

虽然图形结构可以表示工作流关系，但它们需要除基本 DAG 之外的复杂扩展（例如，Petri网、BPMN）才能自然地表达并行执行和条件逻辑。神经网络支持自适应过渡，但缺乏对工作流程执行的精确控制。相比之下，代码表示本身就通过标准 program-ming 构造支持所有这些关系。因此，我们采用代码作为主要的边沿结构，以最大限度地提高表现度。

#### 自动工作流优化

在给定任务 $T$ 和评估函数 $G$ 的情况下，工作流优化的目标是找到一个 工作流 $W$，使得 $G(W,T)$ 最大化。这可以形式化为一个搜索过程，其中算法 $A$ 在搜索空间 $S$ 中探索，以确定最优的工作流配置。

工作流优化问题的 搜索空间 $S$ 包含所有可能的 节点参数配置 和 边沿结构，其数学表示如下：
$$
S = \{ (N, E) \ | \ E \in \mathcal{E} \}
$$
其中：

$N = \{ N(M, \tau, P, F) \ | \ M \in \mathcal{M}, \tau \in [0,1], P \in \mathcal{P}, F \in \mathcal{F} \}$

- $\mathcal{M}$ —— 可能的**语言模型**集合
- $\mathcal{P}$ —— 可能的**提示（Prompt）**集合
- $\mathcal{F}$ —— 可能的**输出格式**集合
- $\mathcal{E}$ —— 可能的**边结构**集合

在上述定义下，工作流优化问题可以表述为：
$$
W = A(S, G, T)
$$
其中：

- $A$ 是用于搜索的**优化算法**，
- $S$ 是搜索空间，
- $G$ 是评估函数，
- $T$ 是给定的任务，
- $W$ 是搜索得到的工作流配置。

最终，我们希望找到最优的工作流 $W^*$，使得：
$$
W^* = \arg\max_{W \in S} G(W, T)
$$
即，我们要找到一个最优的工作流配置 $W^*$，使得其在任务 $T$ 下的评估函数 $G(W,T)$ 取得最大值。



![image-20250303164026006](./asset/AFlow2.png)

图二注：总体AFLOW框架：通过设置一个搜索空间由节点组成，其中只有 prompt 参数可修改，一个给定的运算符集（Operators set），以及一个代码表示的边沿集（Code Represented Edges），AFLOW 在此空间内执行基于 MCTS 的搜索。通过为工作流作计时设计的 MCTS 变体，AFLOW 迭代执行 Soft Mixed Probability Selection 的循环，基于 LLM 的扩展，Execution Evaluation 和 Experience Backpropagation，直到达到最大迭代次数或满足收敛条件。

#### AFLOW 概览

为了解决以前方法的局限性，我们提出了一种新颖的框架工作，该工作**利用 LLMs 作为蒙特卡洛树搜索（MCTS）的优化器来搜索最佳工作流**。正如上文讨论的，边集（edges）可以同时在图和代码中表示。为了确保 AFLOW 能够探索所有可能的智能体（Agentic）工作流，我们使用 代码 来表示 节点 $N$ 和 边 $E$。具体而言，如 图二 所示。

为了提高搜索效率，AFLOW 固定了一些关键参数，包括：模型$M$，温度 $\tau$，输出格式 $F$ 。这种简化使得 AFLOW 的搜索主要集中在代码表示的边 $E$ 和提示词（Prompt） 上

由于搜索空间仍然庞大，我们引入了 Operators（操作符）的概念。这些 Operators 封装了常见的智能体操作（如 集成（Ensemble）、审查（Review）、修改（Revise）），它们将 节点 $N$ 和边 $E$ 组合成统一的接口，从而提升 AFLOW 的搜索效率，并简化工作流的生成。

正式地，给定一组 Operators 集合 **$O$**，其中每个 Operator 代表预定义的节点组合，同时边 **$E$** 由代码表示，则 AFLOW 的优化问题可定义为：
$$
S_{\text{AFlow}} = \{ (P_1, ..., P_n, E, O_1, ..., O_n) \ | \ P_i \in \mathcal{P}, E \in \mathcal{E}, O_i \in \mathcal{O} \}
$$
AFLOW 通过优化搜索空间 **$S_{\text{AFlow}}$** 来找到最优的工作流 $W^*$：
$$
W^* = \text{AFLOW}(S_{\text{AFlow}}, G, T)
$$
其中：

- $S_{\text{AFlow}}$ 表示**AFLOW 的搜索空间**，
- $G$ 是评估函数，
- $T$ 是任务，
- $W^*$ 是优化后的最优工作流。

通过这种方法，AFLOW 高效探索搜索空间，生成**优化的智能体工作流**。

#### 任务范围于操作符

在本文中，我们专注于将 **AFLOW** 应用于**具有数值评估函数的推理任务**。我们从现有文献中提取了常见操作，并将其定义为**操作符集合 $O$** 的一部分。这些操作包括：

1. **生成（Generate）**
2. **格式化（Format）**
3. **审查与修改（Review and Revise）** *（Madaan et al., 2023）*
4. **集成（Ensemble）** *（Wang et al., 2022）*
5. **测试（Test）** *（Zhong et al., 2024a）*
6. **编程（Programmer）**
7. **自定义（Custom）**（作为基本节点构造的默认操作符）

操作符集合 $O$ 可轻松扩展，以提升不同任务的搜索效率。

即使没有任何预定义操作符，AFLOW 仍然可以使用 Custom 操作符 构建不同的工作流节点。

#### AFLOW设计细节

AFLOW 的核心理念是利用大语言模型（LLMs）作为优化器，结合蒙特卡洛树搜索（MCTS）变体来发现高效的工作流。在我们的 MCTS 结构中，每个树节点表示一个完整的工作流，而非单独调用 LLM 的节点。这种设计使得 AFLOW 能够发现适用于一类问题的通用解决方案。

搜索过程采用迭代循环，包括以下几个关键步骤：

1. **软混合概率选择（Soft Mixed Probability Selection）**
2. **LLM 进行优化扩展（LLM-based Optimization Expansion）**
3. **执行评估（Execution Evaluation）**
4. **经验回传（Experience Backpropagation）**

整个流程会持续进行，直至达到最大迭代次数或满足收敛条件。简化流程示意图如图 3 所示，详细算法流程和理论分析可见原文附录 A.6 和 G。



当前的工作流优化方法依赖于使用过去的工作流结构来提示 LLM 生成新结构。但由于信息在累积过程中丢失（输入 Token 数量增加导致），这一方法难以有效引导 LLM 优化特定性能指标。此外，代码的巨大搜索空间进一步降低了搜索效率。

AFLOW 采用MCTS 树结构，在Nmax 轮优化中保留基于工作流的探索经验：

- 当某个工作流被重新访问时，AFLOW 能精准复用过去的成功经验并避免失败路径，从而提升搜索效率并生成更优的工作流。
- 为防止陷入局部最优解，我们引入了一种特殊选择机制，允许在任何轮次从空白模板重新生成工作流。



![image-20250303172230432](./asset/AFlow3.png)



**1.初始化（Initialization）**

AFLOW 以一个模板工作流 $W_0$ 作为起点，该模板用于调用节点和操作符。

代码模板（详见附录 A.3）允许 LLM 通过补全函数调用来完成工作流。

在正式开始搜索之前，AFLOW 随机划分数据集：

- 验证集：20%
- 测试集：80%
- 固定随机种子为 42 以保证实验可复现性。

优化计算效率：

- AFLOW 先在验证集上运行空白模板 5 次，然后筛选分数方差较大的子集作为最终验证集。



**2.选择（Selection）**

初始工作流评估：

- 我们首先在验证集上评估一个空白工作流，作为基准。

软混合概率选择策略（Soft Mixed Probability Selection）：

- 结合均匀分布和基于分数的加权概率分布，从前 k 个最佳工作流以及初始工作流中进行选择。
- 保留初始工作流的目的是确保持续探索能力，避免陷入局部最优。

软混合概率 $P_{\text{mixed}}(i)$ 计算如下：
$$
P_{\text{mixed}}(i) = \lambda \cdot \frac{1}{n} + (1 - \lambda) \cdot \frac{\exp(\alpha \cdot (s_i - s_{\max}))}{\sum_{j=1}^{n} \exp(\alpha \cdot (s_j - s_{\max}))}
$$
其中：

- $n$ ：工作流总数
- $s_i$ ：第 $i$ 个工作流的得分
- $s_{\max}$ ：最高分工作流的得分
- $\alpha = 0.4$ ：控制分数的影响权重
- $\lambda = 0.2$ ：在探索（exploration）与开发（exploitation）之间进行平衡



**3.扩展（Expansion）**

在扩展阶段，我们使用 LLM 作为优化器来创建新工作流（优化提示示例见附录 A.1）。

优化器的核心思路：

- 利用已选工作流的经验生成新的提示，或
- 修改节点连接方式（更改代码）以形成新工作流。

最大化挖掘历史经验：

- 记录所有修改操作及其对应的改进或失败情况。
- 精确记录预测结果与预期输出，确保优化器能有效学习历史信息。



**4.评估（Evaluation）**

由于推理任务中具有显式的评估函数，AFLOW 通过直接执行工作流来获得反馈：

- 每个生成的工作流在验证集上测试 5 次，计算均值和标准差。
- 尽管每轮迭代的计算成本增加，但能提供更准确的反馈，提升优化器的搜索效率。
- 高精度反馈有助于减少总迭代次数，从而加速找到有效的解决方案。



**5.回传（Backpropagation）**

执行完成后，我们记录以下信息：

1. 工作流的性能。
2. 优化器对其父工作流的修改。
3. 相较于父工作流的优化成功与否。

这些信息会：

- 存入经验库并向父工作流回传。
- 工作流的性能分数会加入全局记录，用于后续选择。



**6.终止条件（Terminal Condition）**

为了减少不必要的计算成本，AFLOW 采用提前停止（Early Stopping）策略：

- 若前 k 个最佳工作流的平均得分在连续 n 轮内未提升，则提前终止。
- 若未提前终止，则最多运行 N 轮后停止。

详细算法流程见原文附录 A.6。





### 1.2 ChatDev：Communicative Agents for Software Development

用于软件开发的通信代理

该项目拥有 26.3k Star 和 3.3k Fork，地址：

https://github.com/OpenBMB/ChatDev

论文地址：[ChatDev: Communicative Agents for Software Development](https://arxiv.org/html/2307.07924v5)













### 1.3 AutoGen

































## 2. Muti-Agent-System 

为了实现一个功能齐全的Agent系统，我们需要从三大任务入手

- LLM 的迭代与推理优化：

  一个强大、快速并通过RLHF持续迭代的LLM

- 搭建多Agent协作框架：

  多Agent协同工作的流程闭环

- 完善 Agent 使用的外部工具库：

  检索向量数据库，联网搜索，计算器，访问办公软件文档等外部工具链



### 2.1 LLM迭代与推理优化



### 2.2 多智能体协作框架

[大模型多Agent协同工作：核心机制与交互流程 - 知乎](https://zhuanlan.zhihu.com/p/706511798)

一个多Agent协同工作核心机制与交互流程的闭环：

- 1.任务分配与初始化

  任务定义

  任务分配（评估Agent能力）

  任务初始化

  反馈调整（任务初始化后评估任务可行性，调整任务或Agent重新任务分配）

明确任务定义，评估Agent能力，实现任务与Agent的匹配。

初始化任务状态和Agent状态，为协同执行奠定基础。

- 2.多Agent协同执行

  Agent间通信（在任务初始化后建立通信渠道）

  任务协同执行（信息共享与协同）

  任务进度同步（在协同执行中同步任务进度）

  协同反馈（在每次任务进度同步后评估协同效率，通过调整协同策略影响任务协同执行）

Agent间通过通信共享信息，支持任务协同执行。

基于共享信息，Agent协同执行子任务，同步任务进度。

- 3.任务监控与调整

  任务执行监控（从任务进度同步中获取）

  任务调整（根据监控结果调整任务，执行至任务完成）

监控任务执行情况，根据需要进行任务调整与再分配。

- 4.任务完成与总结

  任务完成判定

  执行结果总结（总结执行经验）

  执行效果反馈（评估任务执行效果）

判定任务是否完成，总结经验教训，提升未来任务执行效率。



然而，在以上过程中，默认监管者是人类，执行者是Agent，监管者通过【任务监控】与【任务完成反馈】来介入Agent的行为流程。

我们需要Agent不再属于人类的附属层级，在一些子任务中，监管者甚至可以是Agent，执行者可以是Agent与人类。那么在【多Agent协同执行】过程中，我们还需要面对Agent与人类在执行层的消息共享。









### 2.3 Agent外部工具库