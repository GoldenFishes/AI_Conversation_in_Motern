# A. Diffusion



## 1. DDPM

DDPM解读（一）| 数学基础，扩散与逆扩散过程和训练推理方法 - 卡卡猡特的文章 - 知乎
https://zhuanlan.zhihu.com/p/530602852

《Denoising Diffusion Probabilistic Models》https://arxiv.org/abs/2006.11239

### 1.1 数学基础

#### 1.1.1 先验概率与后验概率

直观理解：

**先验概率 (Prior)**：在看到数据之前，你对某件事的**原本相信程度**。

**后验概率 (Posterior)**：在看到数据之后，你根据**数据更新后的相信程度**。

------

举个例子：

比如你丢一枚硬币，事先不知道是不是公平的。

- 你**先验地认为**，硬币正反面各 50%（也可能觉得偏某一边）。

后来你丢了 100 次，结果正面出来了 80 次，这个数据很不对劲。

- 根据数据，你**更新你的相信**，硬币可能是偏向正面的一枚。

这个从 "50%" 更新到 "更偏向正面" 的过程，就是：

> **先验 →（看见数据）→ 后验**

------

数学推导：

设

- 事件 $A$ 是我们关心的（比如，"硬币是偏的"）
- 数据 $B$ 是我们观察到的（比如，"丢了100次，正面出了80次"）

那么：
$$
\text{后验概率} = \frac{\text{似然} \times \text{先验概率}}{\text{证据}}
$$
公式写成：
$$
P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}
$$
其中：

- $P(A)$：**先验概率**，观察数据前对 $A$ 的主观相信
- $P(B|A)$：**似然（Likelihood）**，如果 $A$ 成立， $B$ 出现的可能性
- $P(B)$：**证据（Evidence）**，所有可能情况下数据 $B$ 出现的总体概率
- $P(A|B)$：**后验概率**，看过数据 $B$ 后，对 $A$ 的相信程度



| 名称       | 含义                                   |
| ---------- | -------------------------------------- |
| 先验概率   | 看到数据前的主观相信程度               |
| 似然       | 如果假设成立，观察到数据的可能性有多大 |
| 后验概率   | 看到数据后，新的相信程度               |
| 贝叶斯公式 | 后验 = 似然 × 先验 / 证据              |



> **似然函数和条件概率的区分**
>
> - 条件概率 是 “已知某个事件发生后，另一个事件发生的概率”；
>
> - 似然（Likelihood） 是 “在固定观察结果的情况下，不同参数值使这个结果发生的可能性有多大”。
>
> **似然函数是什么？**
>
> 似然看起来像概率，但语义不同。它是这样定义的：
> $$
> \mathcal{L}(θ∣x)=p_θ(x)
> $$
> 含义是：
>
> 已知数据 $x$，我们反过来看参数 $\theta$ 的“合理程度”有多大。
>
> - **概率**：固定参数，看数据出现的概率；
>
> - **似然**：固定数据，看哪个参数值更“合理”。
>
> 我们已知结果 $x$ ，但不知道参数 $\theta$ ，我们想通过这个结果估计 $\theta$ ，那么 $\mathcal{L}(θ∣x)$ 就是**似然函数**



#### 1.1.2 条件概率的一般形式

**定义**：
 如果你已经知道了事件 $B$ 发生，那么在这种条件下，事件 $A$ 发生的概率，叫做 **条件概率**。

数学上，记作：
$$
P(A|B)
$$
**公式是**：
$$
P(A|B) = \frac{P(A \cap B)}{P(B)}
\quad\quad \text{(前提是 } P(B) > 0\text{)}
$$

------

如果你有三个事件 $A$、$B$、$C$，那么：

1. **联合概率** $P(A, B, C)$ 表示
    → $A$、$B$、$C$ 三个**同时发生**的概率。
2. **条件概率的一般形式**可以写成：

$$
P(A, B, C) = P(A|B, C) \times P(B|C) \times P(C)
$$



也可以理解成：

> 联合概率可以被分解成一连串的条件概率相乘。



#### 1.1.3 马尔可夫链条件概率形式

> 马尔可夫链（**Markov Chain**）里，条件概率有个非常重要、特别简洁的形式。
> $$
> P(Xn+1∣Xn,Xn−1,…,X1)=P(Xn+1∣Xn)
> $$

马尔科夫链指当前状态的概率只与上一时刻有关，例如如满足马尔可夫关系 A→B→C ，ABC符合马尔可夫性质，那么我们可以用链式法则展开联合概 $P(A, B, C)$ :
$$
P(A,B,C)=P(A)⋅P(B∣A)⋅P(C∣B)
$$

> 马尔可夫链指当前状态的概率只与上一时刻有关，例如 $A \rightarrow B \rightarrow C$，那么有：
> $$
> P(C∣B,A)=P(C∣B)
> $$
> 马尔可夫性质。



#### 1.1.4 高斯分布的KL散度公式

设有两个一维高斯分布：

- $ p(x) = \mathcal{N}(\mu_p, \sigma_p^2) $

- $ q(x) = \mathcal{N}(\mu_q, \sigma_q^2) $

则 KL 散度 $ D_{\text{KL}}(p \,\|\, q) $ 的计算公式为：

$$
D_{\text{KL}}(p \,\|\, q) = \log\left( \frac{\sigma_q}{\sigma_p} \right) + \frac{\sigma_p^2 + (\mu_p - \mu_q)^2}{2\sigma_q^2} - \frac{1}{2}
$$
参数解释：

> 1. **第一项：**  $\log\left( \frac{\sigma_q}{\sigma_p} \right)$
>
>    反映两个分布在方差上的差异。
>
> 2. **第二项：**  $\frac{\sigma_p^2 + (\mu_p - \mu_q)^2}{2\sigma_q^2}$
>
>    包含：
>
>    - $\frac{\sigma_p^2}{2\sigma_q^2}$：分布宽度差异；
>    - $\frac{(\mu_p - \mu_q)^2}{2\sigma_q^2}$：均值之间的差异。
>
> 3. **第三项：**  $- \frac{1}{2}$
>
>    归一化常数，使散度为零时，代表两个分布完全相同。

特殊情况（均值相同）：

若 $mu_p = \mu_q$，KL 散度简化为：

$$
D_{\text{KL}}(p \,\|\, q) = \log\left( \frac{\sigma_q}{\sigma_p} \right) + \frac{\sigma_p^2}{2\sigma_q^2} - \frac{1}{2}
$$
注：

- KL 散度 $ D_{\text{KL}}(p \,\|\, q) \geq 0 $，当且仅当 $ p = q $ 时取到 0；

- KL 散度是非对称的：
  $$
  D_{\text{KL}}(p \,\|\, q) \neq D_{\text{KL}}(q \,\|\, p)
  $$



#### 1.1.5 参数重整化（重参数技巧）

我们希望从一个高斯分布中采样：
$$
x \sim \mathcal{N}(\mu, \sigma^2)
$$
但由于采样操作不可导，无法直接用于反向传播。为了解决这个问题，我们使用重参数化技巧，将随机性转移到一个独立于模型参数的随机变量中。



**重参数化形式**

我们引入标准正态变量：
$$
z \sim \mathcal{N}(0, 1)
$$
然后构造采样变量：
$$
x = \mu + \sigma \cdot z
$$
这样，$ x $ 的分布为：
$$
x \sim \mathcal{N}(\mu, \sigma^2)
$$


这么做的好处：
- 将不可导的采样操作转化为可导的仿射变换；
- 使得模型在训练过程中可以使用反向传播更新 $ \mu $ 和 $ \sigma $；
- 是变分推断中训练 VAE（Variational Autoencoder）的关键技术。



**注意事项**

- 为保证正值，通常使用 $\log \sigma^2$ 表示，训练过程中实际预测的是 $\log \sigma^2$，然后用 $\exp(\frac{1}{2} \log \sigma^2)$ 计算 $\sigma$；

- 重参数化技巧仅适用于可以重参数化的分布（如高斯分布），对于离散分布则较为困难。





### 1.2 DDPM模型

#### 1.2.1 模型总览

DDPM，全称 **Denoising Diffusion Probabilistic Model**，是一种基于**马尔可夫链的生成模型**。

![img](./asset/v2-c77c080d146c4e9d9edf17e264ebdb98_r.jpg)



DDPM模型主要分为两个过程：forward加噪过程（从右往左）和reverse去噪过程（从左往右）。

模型通过逐步添加噪声和反向去噪学习数据分布。



#### 1.2.2 Diffusion前向过程

**逐步加噪过程**

给定初始数据分布 $q(x_0)$（例如图像分布），我们定义一个前向扩散过程，在这个过程中逐步向数据中添加高斯噪声，使得原始数据在 $T$ 步之后几乎退化成各向同性高斯分布。

在这个持续 $T$ 次的加噪过程中，我们会产生一系列带噪声的图片 $x_1, ..., x_T$ 。在这个过程中，噪声的标准差/方差是以一个在区间 (0,1) 内的固定值 $β_T$ 来确定的，均值是以固定值 $β_T$ 和当前时刻的图片数据 $x_{t−1}$ 来确定的。



**加噪过程定义**

对于 $t = 1, 2, ..., T$，我们定义马尔可夫过程：

$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
$$
其中：

- $\beta_t \in (0, 1)$ 是一个预设的固定方差调度表（称为 noise schedule），通常线性或余弦方式递增；
- $\sqrt{1 - \beta_t}$ 是该步的缩放因子。



> **加噪过程的另一种表示**
>
> 每一步的加噪过程如下：
>
> $$
> q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
> $$
>
> $$
> \bar{\alpha}_t = \prod_{i=1}^T (1 - \alpha_i)
> $$
>
> $$
> \alpha_t = 1- \beta_t
> $$
>
> 
>
> - 这是一个高斯分布，其 **均值** 为 $\sqrt{\bar{\alpha}_t} x_0$，**方差** 为 $1 - \bar{\alpha}_t$；
> - 其中 $\bar{\alpha}_t = \prod_{i=1}^T (1 - \alpha_i)$ 是噪声衰减因子；
> - 因为 $\beta_t$ 是预定义的 schedule，所以 $\bar{\alpha}_t$ 也是固定的；
> - 因此，这个分布完全由 $x_0$ 和 $t$ 决定 —— 无需学习，**不是模型的一部分**。



**加噪结果**

随着 $t$ 的不断增大，最终原始数据 $x_0$ 会逐步失去它的特征。最终当 $T→∞$ 时， $x_T$ 趋近于一个各向独立的高斯分布。从视觉上来看，就是将原本一张完好的照片加噪很多步后，图片几乎变成了一张完全是噪声的图片。



**任意时刻数据 $X_t$ 的计算（参数重整化技巧）**

在前向扩散过程中，虽然 $x_t$ 是通过从 $x_{t-1}$ 不断加噪得到的，但我们其实可以跳过中间所有步骤，直接从 $x_0$ 和固定值序列 $\{β_T∈(0,1)\}_{t=1}^T $ 计算得到任意时刻 $x_t$ 

我们首先定义:
$$
\alpha_t = 1 - \beta_t
$$

$$
\bar{\alpha}_t = \prod_{i=1}^t \alpha_i = \prod_{i=1}^t (1 - \beta_i)
$$

我们可以直接通过下式采样得到某一时刻 $t$ 的带噪图像 $x_t$：
$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
$$
推导步骤：

> 我们希望从以下马尔可夫链定义的前向过程：
>
> $$
> q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{\alpha_t} x_{t-1}, (1 - \alpha_t) \mathbf{I})
> $$
>
> 推导出：
>
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 其中：
>
> - $\bar{\alpha}_t = \prod_{i=1}^t \alpha_i$
>
> 
>
> **推导过程**
>
> 首先，从一步扩散定义：
> $$
> x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1 - \alpha_t} \epsilon_t,\quad \epsilon_t \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 这表示 $x_t$ 是上一步 $x_{t-1}$ 的缩放加上独立高斯噪声的结果。
>
> 展开两步（将 $x_{t-1}$ 用 $x_{t-2}$ 表示）：
> $$
> x_{t-1} = \sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-1}
> $$
>
> 代入 $x_t$ 的公式中得到：
>
> $$
> x_t = \sqrt{\alpha_t} \left( \sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-1} \right) + \sqrt{1 - \alpha_t} \epsilon_t
> $$
>
> 继续展开并整理：
>
> $$
> x_t = \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1-\alpha_t \alpha_{t-1}} \bar\epsilon_{t-2}，\quad(*)
> $$
>
> 你可以看到，每次展开我们都得到一个 $x_0$ 的缩放加上一系列噪声项的线性组合。
>
> 
>
> > **关键技巧** $(*)$ :
> >
> > 这里使用了一个关键技巧，在 Diffusion 模型中常用于将**多步高斯噪声组合**成**一步标准高斯噪声**的形式，也叫**参数重整化**。
> >
> > 当我们合并两个均值都为 0，方差分别为 $\sigma_1^2$ 和 $\sigma_2^2$ 的高斯分布 $\mathcal{N}(0, \sigma_1^2 I)$ 和 $\mathcal{N}(0, \sigma_2^2 I)$ 时，我们得到的新的高斯分布为：
> > $$
> > \sqrt{\alpha_t - \alpha_t \alpha_{t-1}} z_{t-2} + \sqrt{1 - \alpha_t} z_{t-1}
> > $$
> > 因此可以通过参数重整化，变成只含一个随机变量 $z$ 构成的：
> > $$
> > \sqrt{1 - \bar{\alpha}_t} \cdot \bar{z}_t
> > $$
> > 的形式。
> >
> > 
> >
> > 这里使用了高斯变量的加法性质，假设我们有：
> > $$
> > z=aϵ_1+bϵ_2, \quad ϵ_1,ϵ_2∼N(0,I),独立
> > $$
> > 那么我们可以把它写成：
> > $$
> > z= \sqrt{a_2+b_2}⋅ϵ, \quad ϵ∼N(0,I)
> > $$
>
> 
>
> 继续递推 $t$ 次，可以得到一个形式：
>
> 继续这样递推下去 $t$ 次，可以得到一个形式：
>
> $$
> x_t = \sqrt{\prod_{i=1}^t \alpha_i} \cdot x_0 + \sum_{i=1}^t \text{噪声项}
> $$
>
> 通过定义：
>
> $$
> \bar{\alpha}_t = \prod_{i=1}^t \alpha_i
> $$
> 我们得到：
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 这里的 $\epsilon$ 是一系列高斯噪声线性组合后的结果。由于线性组合仍是高斯分布，它等价于一个新的标准正态随机变量。
>
> 
>
> **结论：**
>
> 最终我们推导出：
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 该公式允许我们跳过逐步采样过程，直接从 $x_0$ 构造出 $x_t$ 。这意味着我们**不需要一步一步模拟 $x_1 \to x_2 \to \dots \to x_t$ 的过程**，只需要用初始图像 $x_0$ 和随机噪声 $\epsilon$ 即可直接生成任意时间步的 $x_t$ 。
>
> 这一步是训练阶段的关键，它使得我们可以构造任意时间步的训练样本 $x_t$ 来训练一个模型预测 $\epsilon$ 。

因此，由公式：

$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
$$

可以看出，只要我们：

- 拥有初始图像或数据 \( x_0 \)；
- 知道固定的噪声调度表（即一组在区间 \( (0, 1) \) 内的预设值）：
  $$
  \{ \beta_t \}_{t=1}^T,\quad \alpha_t = 1 - \beta_t,\quad \bar{\alpha}_t = \prod_{i=1}^t \alpha_i
  $$
- 再从标准正态分布 $ \mathcal{N}(0, \mathbf{I}) $ 中采样一个噪声变量 $ \epsilon $；

就可以**直接计算出任意时间步 $ t $ 的加噪结果 $ x_t $**，而无需从 $ x_0 \to x_1 \to x_2 \to \dots \to x_t $ 一步步迭代。

这就是扩散模型中前向加噪过程的高效之处：虽然物理过程是马尔可夫链，但数值计算上我们可以跳步（skip steps），一步直接得出任意时刻的状态。



 **$β$ 序列与 $ᾱ$ 序列的单调性关系说明**

在扩散模型中，前向扩散过程采用高斯噪声不断扰动数据。在这一过程中，每一步的噪声强度由参数 $\beta_t$ 控制。

我们通常会选取一个单调递增的 $\beta_t$ 序列：

$$
0 < \beta_1 < \beta_2 < \cdots < \beta_T < 1
$$

- 这样设计的动机是：随着扩散步数 $t$ 的增大，图像中加入的噪声逐步增多，因此 $\beta_t$ 应该随时间增长，使得图像逐渐变为纯噪声。



我们定义：

$$
\alpha_t = 1 - \beta_t
$$

显然，$\alpha_t \in (0,1)$ 且也是单调递减的。

接着我们引入累积乘积项：

$$
\bar{\alpha}_t = \prod_{i=1}^t \alpha_i
$$

因为每个 $\alpha_i \in (0,1)$，所以 $\bar{\alpha}_t$ 会 随 $t$ 增大而逐渐减小：

$$
\bar{\alpha}_1 > \bar{\alpha}_2 > \cdots > \bar{\alpha}_T
$$


总结：

- $\beta_t$ 随时间增长，表示噪声比例增加；
- $\alpha_t = 1 - \beta_t$ 随时间减小；
- $\bar{\alpha}_t = \prod_{i=1}^t \alpha_i$ 也随时间单调减小。

这种设计保证了：
- 早期的图像保留更多原始信息；
- 后期的图像则接近完全高斯噪声。





#### 1.2.3 Reverse Diffusion逆向过程

##### a. 逆扩散过程近似模型 $p_θ$

如果我们能将上述过程转换方向，即从 $q(x_{t−1}|x_t)$ 中采样，那么我们就可以从一个随机的高斯分布 $N(0,I)$ 中重建出一个真实的原始样本，也就是从一个完全杂乱无章的噪声图片中得到一张真实图片。

但是，由于需要从完整数据集中找到数据分布，我们没办法很简单地预测 $q(x_{t−1}|x_t)$ ，因此我们需要学习一个模型 $p_θ$ 来近似模拟这个条件概率，从而运行逆扩散过程。



如果我们能学习逆过程：

$$
q(x_{t-1} \mid x_t)
$$

那么我们就可以从完全的噪声 $x_T \sim \mathcal{N}(0, \mathbf{I})$ 开始，通过一系列“去噪”步骤，逐步重建出原始的图像 $x_0$。

------

前向过程 $q(x_t \mid x_{t-1})$ 是已知的高斯扰动；

逆向过程 $q(x_{t-1} \mid x_t)$ 难以直接求解；

我们用神经网络 $p_\theta(x_{t-1} \mid x_t)$ 来近似它，从而实现从噪声到真实图像的生成建模。
$$
p_\theta(\mathbf{x}_{0:T}) = p(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)
$$

> **解释：**
>
> - $\mathbf{x}_{0:T}$ 表示从原始图像 $\mathbf{x}_0$ 到最终噪声图像 $\mathbf{x}_T$ 的整个序列。
> - $p(\mathbf{x}_T)$ 是在最终扩散步骤 $T$ 时，图像的先验分布，通常设为标准高斯分布 $\mathcal{N}(0, \mathbf{I})$。
> - $p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$ 是神经网络学习得到的近似逆过程的条件概率，表示如何从 $\mathbf{x}_t$ 还原出 $\mathbf{x}_{t-1}$。
> - 整个逆过程由 $T$ 个步骤组成，每一步都是一个高斯采样过程。

$$
p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}\left( \mathbf{x}_{t-1}; \mu_\theta(\mathbf{x}_t, t), \Sigma_\theta(\mathbf{x}_t, t) \right)
$$

> **解释：**
>
> - 我们假设从 $\mathbf{x}_t$ 到 $\mathbf{x}_{t-1}$ 的条件概率是一个高斯分布。
> - $\mu_\theta(\mathbf{x}_t, t)$ 是模型输出的均值，表示从 $\mathbf{x}_t$ 预测出的最可能的前一步图像。
> - $\Sigma_\theta(\mathbf{x}_t, t)$ 是预测的协方差矩阵，通常简化为对角阵，甚至是固定值（比如 $\sigma_t^2 \mathbf{I}$），代表预测不确定性。
> - 通过训练模型来尽可能地让这个条件分布 $p_\theta$ 逼近真实的后验分布 $q(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$。



##### b. 后验扩散条件概率 $q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$

在逆扩散过程中，如果我们给定了 $x_t$ 和 $x_0$ ,那么我们是可以计算出 $x_{t−1}$ 的，即后验扩散条件概率 $q(x_{t−1}|x_t,x_0)$ 是可以计算的。注意，这与直接用 $ q(x_{t-1} | x_t) $ 不同，因为我们无法在仅依赖于当前的噪声状态 $ x_t $ 就推断出 $q(x_{t−1}|x_t,x_0)$。



我们可以将后验扩散条件概率 $ q(x_{t-1} | x_t, x_0) $ 表达为以下的形式：
$$
q(x_{t-1} | x_t, x_0) = \mathcal{N}\left(x_{t-1} ; \tilde\mu_{t-1}(x_t, x_0), \tilde\beta_t \mathbf{I}\right)
$$

> **解释：**
>
> - $ q(x_{t-1} \mid x_t, x_0) $：表示在已知当前噪声状态 $ x_t $ 和原始图像 $ x_0 $ 的前提下，前一时刻状态 $ x_{t-1} $ 的**后验分布**。
> - 该分布是一个**高斯分布**，其：
>   - 均值为 $ \tilde\mu_{t-1}(x_t, x_0) $
>   - 协方差为 $ \tilde\beta_t \mathbf{I} $
>
> 这是一个**可解析的闭式解**，不需要模型学习，直接由前向过程的噪声调度参数推导而来
>
> 该高斯分布的均值和方差可以写作：
>
> $$
> \tilde\mu_{t-1}(x_t, x_0) = \frac{\sqrt{\bar\alpha_{t-1}} \beta_t}{1 - \bar\alpha_t} x_0 + \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t-1})}{1 - \bar\alpha_t} x_t
> $$
>
> $$
> \tilde\beta_t = \frac{1 - \bar\alpha_{t-1}}{1 - \bar\alpha_t} \beta_t
> $$
>
> 其中：
>
> - $ \alpha_t = 1 - \beta_t $
> - $ \bar\alpha_t = \prod_{s=1}^t \alpha_s $



使用贝叶斯公式可以得到：

在扩散模型中，已知当前状态 $ x_t $ 和原始图像 $ x_0 $，我们可以使用贝叶斯公式来推导出后验分布：

$$
q(x_{t-1} \mid x_t, x_0) = q(x_t \mid x_{t-1}) \cdot \frac{ q(x_{t-1} \mid x_0)}{q(x_t \mid x_0)}
$$

> 注意：上式在马尔可夫扩散模型中 $x_t$ **只依赖** $x_{t-1}$，与 $x_0$ 条件独立（因为前向过程是马尔可夫链）；
>
> 所以 $q(x_t \mid x_{t-1}, x_0) = q(x_t \mid x_{t-1})$



其中每一项都是一个高斯分布：

- $q(x_t \mid x_{t-1}) $：前向过程的一步高斯扰动：
  $$
  q(x_t \mid x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t \mathbf{I})
  $$

- $ q(x_{t-1} \mid x_0) $：前向过程的马尔可夫链的一部分，可以从 $ x_0 $ 直接采样出任意中间状态：
  $$
  q(x_{t-1} \mid x_0) = \mathcal{N}(x_{t-1}; \sqrt{\bar\alpha_{t-1}} x_0, (1 - \bar\alpha_{t-1}) \mathbf{I})
  $$

- $ q(x_t \mid x_0) $：类似地，可以从 $ x_0 $ 直接得到：
  $$
  q(x_t \mid x_0) = \mathcal{N}(x_t; \sqrt{\bar\alpha_t} x_0, (1 - \bar\alpha_t) \mathbf{I})
  $$

> 现在我们要计算：
> $$
> q(x_{t-1} \mid x_t, x_0) = q(x_t \mid x_{t-1}) \cdot \frac{ q(x_{t-1} \mid x_0)}{q(x_t \mid x_0)}
> $$
> 每一个高斯分布都可以写成如下形式：
> $$
> \mathcal{N}(x; \mu, \sigma^2 \mathbf{I}) = \frac{1}{Z} \exp\left(-\frac{1}{2\sigma^2} \|x - \mu\|^2\right)
> $$

我们将上面三个项都写成指数形式（写出三个项的负指数项，忽略常数）：

其中第一项 **$q(x_t \mid x_{t-1})$**:
$$
\exp\left( -\frac{1}{2\beta_t} \|x_t - \alpha_t x_{t-1} \|^2 \right)
$$
其中第二项 **$q(x_{t-1} \mid x_0)$**:

$$
\exp\left( -\frac{1}{2(1 - \bar{\alpha}_{t-1})} \|x_{t-1} - \bar{\alpha}_{t-1} x_0 \|^2 \right)
$$
其中第三项 **$q(x_t \mid x_0)$** （这是分母，带负号）:

$$
\exp\left( +\frac{1}{2(1 - \bar{\alpha}_t)} \|x_t - \bar{\alpha}_t x_0 \|^2 \right)
$$
现在，我们的目标是得到关于 $x_{t-1}$ 的分布，只有第1项和第2项中出现了 $x_{t-1}$ （第三项在后续推导中不会显示写出来，它是归一化常数，不影响高斯的形式）。根据贝叶斯规则（可看作条件高斯分布的推导）：
$$
q(x_{t-1} \mid x_t, x_0) \propto q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0)
$$


> 其中我们把右边的乘积 $q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0)$ 被当成一个**未归一化的概率密度函数**，然后通过归一化使其总和为1，这样就变成了一个合法的概率分布。
> 
>
> > **为什么 $q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0)$ 被当成一个未归一化的概率密度函数？**
> >
> > 它是两个高斯密度函数的乘积，关于 $x_{t-1}$ 的函数。
> >
> > - 这个乘积不一定积分为1（可能大于或小于1），所以它不是合法概率密度函数（缺少归一化）；
> > - 但它的函数形式依然是一个**关于 $x_{t-1}$ 的高斯函数的形式（未归一化）**；
> > - 为了让它成为合法的概率密度函数，我们除以归一化常数 $q(x_t \mid x_0)$，让积分变成1
> >
> > (乘积给了我们**后验的“形状”**，归一化常数保证它是个真正的概率分布)
>
> 
>
> 而归一化的常数正好就是 $q(x_t \mid x_0)$，即：
> $$
> q(x_t ∣x_0)=∫q(x_t∣x_{t−1})⋅q(x_{t−1}∣x_0)dx_{t−1}
> $$
> 所以：
> $$
> q(x_{t-1} \mid x_t, x_0) = \frac{
>     q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0)
> }{
>     q(x_t \mid x_0)
> }
> = \frac{
>     q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0)
> }{
>     \int q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0) \, dx_{t-1}
> }
> = \text{归一化的乘积}
> $$
> 
>
> > **为什么 $q(x_t \mid x_0)$ 是归一化常数？**
> >
> > 上式分母：
> >
> > $$
> > q(x_t \mid x_0) = \int q(x_t \mid x_{t-1}) \, q(x_{t-1} \mid x_0) \, dx_{t-1}
> > $$
> >
> > 是对所有可能的 $ x_{t-1} $ 积分得到的，保证右边的分布对 $ x_{t-1} $ 归一化（即积分为1）。
> >
> > 换句话说，分母是一个 **标量值**，不依赖于 $ x_{t-1} $，它负责保证分子所定义的函数（关于 $ x_{t-1} $）是个合法的概率密度函数。
>
> 
>
> 而当我们推导具体形式（比如均值和方差）时：
>
> 由于高斯的乘积结果形式 **不依赖归一化常数**，我们就只计算了：
> $$
> 一个关于 x_{t−1} 的未归一化高斯密度函数 ∝ exp(−Q(x_{t−1}))
> $$
> 
>
> > **为什么归一化常数不影响高斯形式？**
> >
> > 高斯分布的概率密度函数形式是：
> >
> > $$
> > \mathcal{N}(x; \mu, \Sigma) = \frac{1}{(2\pi)^{d/2} |\Sigma|^{1/2}} \exp\left( -\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu) \right)
> > $$
> >
> > - 归一化常数是开头的那部分（包含 $ (2\pi)^d $ 和 $ |\Sigma| $）；
> > - 指数部分控制了高斯的“形状”，即均值 $ \mu $ 和协方差矩阵 $ \Sigma $；
> >
> > ---
> >
> > 在推导后验时，我们先只关注**指数部分**，把它写成关于 $ x_{t-1} $ 的二次函数，然后通过配方（完成平方）得到新的均值和协方差矩阵。
> >
> > 归一化常数只是调整整体的“高度”，不会改变这个指数的结构，因而不会影响“是哪个均值、哪个方差的高斯”。
>
> 
>
> 并直接得到结果是一个新的高斯分布。
>
> 所以我们只用乘积那两项就可以**正确恢复一个高斯分布的形式**，而**第三项只是归一化常数，可以省略不写**。


我们带入第1项和第2项两个高斯分布后，得到：
$$
q(x_{t-1} \mid x_t, x_0) \propto 
\exp\left(
- \frac{1}{2\beta_t} \left\| x_t - \sqrt{\alpha_t} x_{t-1} \right\|^2
\right)
\cdot
\exp\left(
- \frac{1}{2(1 - \bar{\alpha}_{t-1})} \left\| x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_0 \right\|^2
\right)
$$
合并两个指数项：
$$
q(x_{t-1} \mid x_t, x_0) \propto 
\exp\left(
- \frac{1}{2\beta_t} \left\| x_t - \sqrt{\alpha_t} x_{t-1} \right\|^2
- \frac{1}{2(1 - \bar{\alpha}_{t-1})} \left\| x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_0 \right\|^2
\right)
$$
这是一个关于 $x_{t-1}$ 的二次函数指数项，所以它仍然是一个**高斯分布**！
现在我们将其合并成一个高斯（两高斯乘法）：

> 高斯乘积公式：
>
> - 协方差：
> $$
> \tilde{\Sigma} = \left( \Sigma_1^{-1} + \Sigma_2^{-1} \right)^{-1}
> $$
>
> - 均值：
>
> $$
> \tilde{\mu} = \tilde{\Sigma} \left( \Sigma_1^{-1} \mu_1 + \Sigma_2^{-1} \mu_2 \right)
> $$
>

那么两个高斯分布，记：

- $Σ_1=β_tI$, $\mu_1 = \frac{x_t}{\sqrt{\alpha_t}}$

- $Σ_2=(1−αˉ_{t−1})I$, $\mu_2 = \sqrt{\bar\alpha_{t-1}} x_0$

根据高斯分布乘法的协方差推导公式，我们可以得到：

$$
\tilde{\beta}_t 
= \left( \frac{1}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}} \right)^{-1}
= \frac{(1 - \bar{\alpha}_{t-1}) \beta_t}{(1 - \bar{\alpha}_{t-1}) + \beta_t}
\approx \frac{(1 - \bar{\alpha}_{t-1}) \beta_t}{1 - \bar{\alpha}_t}
$$

> 其中近似是因为：
>
> $$
> \bar{\alpha}_t = \alpha_t \cdot \bar{\alpha}_{t-1}
> \Rightarrow 1 - \bar{\alpha}_t = 1 - \alpha_t \bar{\alpha}_{t-1} \approx 1 - \bar{\alpha}_{t-1} + \beta_t
> $$
>
> 则：
>
> $$
> \frac{(1 - \bar{\alpha}_{t-1}) \beta_t}{(1 - \bar{\alpha}_{t-1}) + \beta_t}
> \approx \frac{(1 - \bar{\alpha}_{t-1}) \beta_t}{1 - \bar{\alpha}_t}
> $$



因此，最终我们可以推导得到：
$$
q(x_{t-1} \mid x_t, x_0) = \mathcal{N}\left(x_{t-1}; \tilde\mu_{t}(x_t, x_0), \tilde\beta_t \mathbf{I} \right)
$$

$$
\tilde\mu_{t}(x_t, x_0) = \frac{\sqrt{\bar\alpha_{t-1}} \beta_t}{1 - \bar\alpha_t} x_0 + \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t-1})}{1 - \bar\alpha_t} x_t
$$

$$
\tilde\beta_t = \frac{1 - \bar\alpha_{t-1}}{1 - \bar\alpha_t} \beta_t
$$



> 其中：
>
> - 均值 $ \tilde\mu_{t}(x_t, x_0) $
>
> - 方差 $\tilde\beta_t$
>
>
> 该公式说明：
>
> - 后验分布 $ q(x_{t-1} \mid x_t, x_0) $ 是一个已知参数的高斯分布；
> - 可由贝叶斯公式结合前向过程的联合概率推导得到；
> - 是训练过程中用于监督模型预测的核心工具。

由前面Forward前向过程我们推导得到的 $x_0$ 和 $x_t$ 的关系，我们有：
$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
$$

$$
x_0 = \frac{1}{ \sqrt{\bar{\alpha}_t} }(x_t - \sqrt{1-\bar{\alpha}_t}) \, \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
$$

由上式后验均值：
$$
\tilde\mu_{t}(x_t, x_0) = \frac{\sqrt{\bar\alpha_{t-1}} \beta_t}{1 - \bar\alpha_t} x_0 + \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t-1})}{1 - \bar\alpha_t} x_t
$$
代入 $x_0$ 得到：
$$
\tilde\mu_{t}(x_t, \epsilon) = \frac{\sqrt{\bar\alpha_{t-1}} \beta_t}{1 - \bar\alpha_t} \cdot \frac{1}{\sqrt{\bar{\alpha}_t}} \left(x_t - \sqrt{1-\bar{\alpha}_t} \epsilon \right) + \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t-1})}{1 - \bar\alpha_t} x_t
$$
合并得到：
$$
\tilde{\mu}_{t}(x_t, \epsilon) =\left( \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{(1 - \bar{\alpha}_t) \sqrt{\bar{\alpha}_t}} + \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \right) x_t 
 - \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \sqrt{1 - \bar{\alpha}_t}}{(1 - \bar{\alpha}_t) \sqrt{\bar{\alpha}_t}} \epsilon
$$

> 上式推导 $\tilde{\mu}_t(x_t, \epsilon)$ 的简洁形式
>
> 将 $\sqrt{\alpha_t} = \dfrac{\sqrt{\bar{\alpha}_t}}{\sqrt{\bar{\alpha}_{t-1}}}$ 代入第二项：
> $$
> = \left( \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}} + \frac{ \frac{\sqrt{\bar{\alpha}_t}}{\sqrt{\bar{\alpha}_{t-1}}}(1 - \bar{\alpha}_{t-1}) }{1 - \bar{\alpha}_t} \right) x_t 
> - \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \sqrt{1 - \bar{\alpha}_t}}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}} \epsilon
> $$
> 通分并合并 $x_t$ 系数项，得到：
> $$
> = \left(
> \frac{ \beta_t \bar{\alpha}_{t-1} + \bar{\alpha}_t(1 - \bar{\alpha}_{t-1}) }{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}\sqrt{\bar{\alpha}_{t-1}}}
> \right) x_t
> - \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \sqrt{1 - \bar{\alpha}_t}}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}} \epsilon
> $$
> 注意 $\bar{\alpha}_t = \bar{\alpha}_{t-1}(1 - \beta_t)$，因此：
> $$
> \beta_t \bar{\alpha}_{t-1} + \bar{\alpha}_t(1 - \bar{\alpha}_{t-1})
> = \bar{\alpha}_{t-1} \beta_t + \bar{\alpha}_{t-1}(1 - \beta_t)(1 - \bar{\alpha}_{t-1})
> $$
> 展开化简得：
> $$
> = \bar{\alpha}_{t-1} - \bar{\alpha}_t
> $$
> 代入回去：
> $$
> \tilde{\mu}_t(x_t, \epsilon)
> = \frac{\bar{\alpha}_{t-1} - \bar{\alpha}_t}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}\sqrt{\bar{\alpha}_{t-1}}} x_t 
> - \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \sqrt{1 - \bar{\alpha}_t}}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}} \epsilon
> $$
> 又因为：
> $$
> \bar{\alpha}_{t-1} - \bar{\alpha}_t = \bar{\alpha}_{t-1} \beta_t
> $$
> 因此：
> $$
> \tilde{\mu}_t(x_t, \epsilon)
> = \frac{ \sqrt{\bar{\alpha}_{t-1}} \beta_t }{ (1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t} } x_t 
> - \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \sqrt{1 - \bar{\alpha}_t}}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}} \epsilon
> $$
> 提取公共因子：
> $$
> = \frac{ \sqrt{\bar{\alpha}_{t-1}} \beta_t }{ (1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t} }
> \left( x_t - \sqrt{1 - \bar{\alpha}_t} \epsilon \right)
> $$
> 注意：
> $$
> \frac{ \sqrt{\bar{\alpha}_{t-1}} \beta_t }{ (1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t} } = \frac{1}{\sqrt{\bar{\alpha}_t}}
> $$
> 最终可得：
> $$
> \boxed{
> \tilde{\mu}_t(x_t, \epsilon) = \frac{1}{\sqrt{\bar{\alpha}_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon \right)
> }
> $$

由上式子可最终推导为：
$$
\tilde\mu_{t} = 

\frac{1}{ \sqrt{\bar{\alpha}_t} }(x_t -\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon)
$$


##### c. 目标数据分布的似然函数

假设数据的真实分布为 $ q(x_0) $，模型的联合分布为 $ p_\theta(x_{0:T}) $，其中 $ x_0 $ 是观测数据，$ x_{1:T} $ 是潜变量（如扩散模型中的中间状态）。

这里与VAE很类似，我们可以使用VAE中推导变分下界（Variational Lower Bound, 简称 ELBO）的方式来优化负对数似然函数。

> 变分下界，本质是**一个对难以直接优化的目标函数的下界逼近，用于可行的训练和优化**。
>
> **直观理解**
>
> 很多生成模型的目标是最大化对观测数据 $x$ 的对数似然：
> $$
> \log p_θ(x)
> $$
> 但这个量通常涉及对高维潜变量 $z$（或 $x_{1:T}$）的积分，计算上是不可解的。
>
> 所以我们引入一个 **近似分布 $q(z|x)$**，用它来辅助估计 $\log p_\theta(x)$。
>
> 这时，就可以推导出下面这个著名的不等式：
> $$
> \log p_\theta(x) \geq \mathbb{E}_{q(z|x)} \left[ \log \frac{p_\theta(x, z)}{q(z|x)} \right] \triangleq \mathcal{L}_{\text{VLB}}(x)
> $$
> 这右边的量，就是所谓的 **变分下界（VLB）**，也称为 **ELBO（Evidence Lower Bound）**。
>
> > **为什么叫“下界”？**
> >
> > 因为它是对 $\log p_\theta(x)$ 的一个下界估计：
> >
> > - $\log p_θ(x)$ 是我们想最大化的目标；
> > - 但我们优化不了它（积分太复杂）；
> > - 所以退而求其次，最大化一个它的下界（VLB）；
> > - 最大化 VLB 会间接推动 $\log p_\theta(x)$ 的增大。
>
> 

在这里，我们也看到了一种将难以直接优化的负对数似然 $-\log p_θ(x_0)$ 转化为更容易优化的下界 $𝓛_{VLB}$ 的技巧。

> **为什么是 负对数似然（Negative Log-Likelihood, NLL）？**
>
> 我们通常使用 最大似然估计（MLE） 来训练模型，也就是：
> $$
> 最大化 \log p_θ(x)
> $$
> 而在实际优化中，我们通常 **最小化损失函数**，所以把最大化问题改写为一个最小化问题：
> $$
> \min_\theta \, -\log p_\theta(x)
> $$
> **为什么要取对数？**
>
> 1. 数值稳定性：
>
>    概率密度值通常很小（比如 $10^{-10}$，甚至更小），直接乘积容易下溢，取对数变加法，避免数值问题。
>
> 2. 简化梯度计算：
>
>    对数可以把连乘变成连加，更容易计算梯度、优化，比如：
>    $$
>    \log \prod_i p_\theta(x_i) = \sum_i \log p_\theta(x_i)
>    $$
>    所以对于多个样本（或时间步骤）时非常方便。
>
> **总结：**
>
> 最小化负对数似然（NLL） = 最大化对数似然 = 最大化似然

我们从负对数似然函数出发。在构造变分下界（ELBO）时，我们是通过人为引入 KL 散度的非负性来得到一个可优化的下界：
$$
-\log p_\theta(x_0)
\leq -\log p_\theta(x_0) + D_{\mathrm{KL}}(q(x_{1:T}|x_0) \,\|\, p_\theta(x_{1:T}|x_0)) \\
= -\log p_\theta(x_0) + \mathbb{E}_{x_{1:T} \sim q(x_{1:T}|x_0)} \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{1:T}|x_0)} \right]
$$

> **如何理解人为引入 KL 散度的非负性来得到一个可优化的下界？**
>
> 一、我们要解决的问题：最大化似然
>
> 我们想训练一个模型，使得它最大化训练样本 $x_0$ 的对数似然，也就是：
> $$
> \max_\theta \, \log p_\theta(x)
> $$
> 但由于模型是通过某种复杂的 **隐变量过程（如扩散过程中的 $x_{1:T}$）**定义的，直接求这个对数似然非常困难，甚至无法直接计算。
>
> 二、引入后验的挑战：对数似然不好计算
>
> 根据概率的边缘化：
> $$
> p_\theta(x_0) = \int p_\theta(x_{1:T}, x_0) \, dx_{1:T} 
> = \int p_\theta(x_0 \mid x_{1:T}) p_\theta(x_{1:T}) \, dx_{1:T}
> $$
> 但由于这个积分过于复杂，**我们无法精确计算** $\log p_\theta(x_0)$，也就无法直接最大化它。
>
> 三、人为引入变分分布 $q(x_{1:T}|x_0)$
>
> 于是，我们**“人为地”引入一个辅助分布**（叫变分分布）$q(x_{1:T}|x_0)$，来代替模型的后验 $p_\theta(x_{1:T}|x_0)$，这是变分推断的核心策略。
>
> 然后我们引入 **KL 散度**（总是非负）：
> $$
> D_{\mathrm{KL}}\big(q(x_{1:T}|x_0) \,\|\, p_\theta(x_{1:T}|x_0)\big) \geq 0
> $$
> 把它加到目标函数上（注意是**“加”一个非负项，所以变成了一个下界**）：
> $$
> -\log p_\theta(x_0) \leq -\log p_\theta(x_0) + D_{\mathrm{KL}}(q \| p_\theta)
> $$
> 四、总结这句话的含义
>
> > “通过人为引入 KL 散度的非负性来得到一个可优化的下界”，分解如下：
>
> - “人为引入”：我们不是自然地得到这个 KL 项，而是**人为设计一个变分分布 $q(x_{1:T}|x_0)$** 来构造 KL。
>
> - “KL 散度的非负性”：KL 总是 ≥ 0，因此加到目标中不会违反数学原理。
>
> - “得到一个下界”：因为我们加了 KL 散度，我们对原始的 log-likelihood 得到一个**下界（ELBO）**。
>
> - “可优化”：这个下界可以被计算并用于梯度下降优化训练模型。
>
> 五、一个简单的比喻
>
> 你有一个山洞（log-likelihood），里面藏着黄金（最优模型参数），但你进不去（无法精确计算 log-likelihood）。于是你画了一个地图（变分分布），虽然不是最真实的地形（后验），但你通过地图可以知道自己最起码可以挖到哪里（ELBO）。然后你不断改进地图（优化 q 和模型），直到找到一个能尽量逼近山洞真实地形的路线。

> 个人理解：原始目标不可计算，因此自然无法使用自动微分计算梯度，导致无法直接做优化。通过引入变分分布 $q(x_{1:T}|x_0)$，我们把难算的积分变成了在 $q$ 下的**期望**。从而获得一个关于 $\theta$ 和 $q$ 参数的期望的ELBO，自动微分能无障碍计算梯度，从而进行梯度下降。
>
> > **为什么我通过估计一个变分下界就能够近似原始目标呢？**
> >
> > 个人理解：
> >
> > 一方面是ELBO是对数似然的下界，通过优化ELBO，间接最大化 $\log p_θ(x0)$ ；
> >
> > 另一方面是我引入的这个KL散度本身就直接衡量了代理值（变分下界ELBO）和真实对数似然之间的差距
> > $$
> > \log p_θ (x_0)−\text{ELBO}=D_{\mathrm{KL}}(q(x_{1:T}|x_0) \,\|\, p_\theta(x_{1:T}|x_0)) 
> > $$
> >
> > - KL 散度的值越小，说明 $q$ 越接近真实的后验 $p_\theta(x_{1:T}|x_0)$，
> > - 也就是说，**ELBO 越接近 $\log p_\theta(x_0)$，我们的代理目标就越准确。**
> >
> > 那么此时的优化目标就已经包含了对原始目标的近似了。

利用贝叶斯公式展开 $p_\theta(x_{1:T}|x_0)$：
$$
= -\log p_\theta(x_0) + \mathbb{E}_q \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T}) / p_\theta(x_0)} \right] \\
= -\log p_\theta(x_0) + \mathbb{E}_q \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} + \log p_\theta(x_0) \right]
$$
将 $\log p_\theta(x_0)$ 抵消后得到：
$$
= \mathbb{E}_q \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} \right]
$$
我们将其定义为变分下界（Variational Lower Bound, VLB）：
$$
\mathcal{L}_{\text{VLB}} = \mathbb{E}_{q(x_{0:T})} \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} \right] \geq -\mathbb{E}_q \log p_\theta(x_0)
$$
这说明我们可以通过最大化 $\mathcal{L}_{\text{VLB}}$ 来最小化负对数似然，即优化生成模型的目标。



------

使用 Jensen 不等式也很容易得到相同的结果。假设数据的真实分布为 $ q(x_0) $，模型的联合分布为 $ p_\theta(x_{0:T}) $，其中 $ x_0 $ 是观测数据，$ x_{1:T} $ 是潜变量（如扩散模型中的中间状态）。

我们想最小化交叉熵作为学习目标：
$$
\mathcal{L}_{\text{CE}} = -\mathbb{E}_{q(x_0)} \log p_\theta(x_0)
$$
其中 $p_\theta(x_0)$ 是模型给出的边缘概率。

> 模型定义了一个联合分布：
> $$
> p_\theta(x_{0:T}) = p_\theta(x_0, x_1, \dots, x_T)
> $$
> 这里，
>
> - $x_0$ 是我们真正关心的观测数据（例如一张真实图片），
> - $x_{1:T}$ 是模型中的潜变量（latent variables），比如扩散模型中的多个中间状态。

第一步：边缘概率难以直接计算，需要对潜变量积分

模型的边缘概率  $ p_\theta(x_0) $ 是对联合分布 $ p_\theta(x_{0:T}) $ 在潜变量上的积分：
$$
p_\theta(x_0) = \int p_\theta(x_{0:T}) \, dx_{1:T}
$$

> **边缘概率 $p_\theta(x_0)$** 是从联合分布中“忽略”潜变量 $ x_{1:T} $，只关心 $x_0$ 的概率：
> $$
> p_\theta(x_0) = \int p_\theta(x_0, x_1, \dots, x_T) \, dx_1 \cdots dx_T
> $$
> 也就是说，边缘概率就是把潜变量“积分掉”后，模型对观测数据 $x_0$ 的整体概率分布。

所以交叉熵可写为：
$$
\mathcal{L}_{\text{CE}} = -\mathbb{E}_{q(x_0)} \log \left( \int p_\theta(x_{0:T}) \, dx_{1:T} \right)
$$
第二步：引入变分分布 $ q(x_{1:T} | x_0) $ 把积分写成期望

这是变分推断的关键技巧，我们在积分中乘除上相同的量：
$$
\int p_\theta(x_{0:T}) \, dx_{1:T} = \int q(x_{1:T}|x_0) \cdot \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \, dx_{1:T}
$$
所以可以写成期望形式：
$$
\mathcal{L}_{\text{CE}} = -\mathbb{E}_{q(x_0)} \log \left( \mathbb{E}_{q(x_{1:T}|x_0)} \left[ \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \right] \right)
$$
第三步：使用 Jensen 不等式

因为 $\log$ 是 concave 函数，我们可以使用 Jensen 不等式将 $\log$ 移入期望：

> Jensen 不等式利用对数的凹性，将对数期望变成期望对数，得到下界

$$
\log \mathbb{E}[X] \geq \mathbb{E}[\log X] \quad \Rightarrow \quad -\log \mathbb{E}[X] \leq - \mathbb{E}[\log X]
$$

应用公式中就是：
$$
\mathcal{L}_{\text{CE}} = -\mathbb{E}_{q(x_0)} \log \left( \mathbb{E}_{q(x_{1:T}|x_0)} \left[ \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \right] \right) 
\leq -\mathbb{E}_{q(x_0)} \mathbb{E}_{q(x_{1:T}|x_0)} \log \left( \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \right)
$$
换顺序（合并期望）：
$$
= \mathbb{E}_{q(x_{0:T})} \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} \right]
$$
最后我们得到了变分下界：
$$
\mathcal{L}_{\text{VLB}} = \mathbb{E}_{q(x_{0:T})} \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} \right]
$$
也就是交叉熵的上界（因为 Jensen 是反向的）：
$$
\mathcal{L}_{\text{CE}} \leq \mathcal{L}_{\text{VLB}}
$$

> 总结：
>
> - 目标是最小化 $ -\log p_\theta(x_0) $，但 $ p_\theta(x_0) $ 需要积分，难以直接计算。
> - 引入变分分布 $ q(x_{1:T}|x_0) $，把积分写成一个期望。
> - 利用 Jensen 不等式，把 $\log$ 外面的期望换成 $\log$ 内的期望，从而形成可 tractable 的表达式。
> - 得到的是一个可优化的上界：变分下界（VLB），作为训练目标。

这个过程是变分推断和扩散模型训练中的核心技巧。训练时优化的实际上是这个变分下界 $\mathcal{L}_{\text{VLB}}$，它是交叉熵的上界，也是 ELBO（Evidence Lower Bound）的负值形式

> **变分下界的物理意义**
>
> - $q(x_{1:T}|x_0)$ 是对潜变量的近似后验。通过选择合适的 $q$，使得变分下界尽可能接近真实的对数边缘似然。
> - 优化 $\mathcal{L}_{\text{VLB}}$ 意味着同时让模型分布 $p_\theta$ 和变分分布 $q$ 之间的 KL 散度尽可能小，从而提升模型对观测数据的拟合能力。

------

为了将变分下界方程中的每一项都转换使其可分析计算，可以将目标进一步重写为几个 KL 散度和熵项的组合:

$$
L_{\text{VLB}} = \mathbb{E}_{q(x_{0:T})} \left[ \log \frac{q(x_{1:T} | x_0)}{p_\theta(x_{0:T})} \right]
$$

> 注意这里：
>
> - $q(x_{0:T}) = q(x_0) q(x_{1:T} | x_0)$
> - 由于 $x_0 \sim q(x_0)$ 是已知的真实样本，所以只需要考虑 $x_{1:T} | x_0$

展开联合分布形式：
$$
= \mathbb{E}_q \left[ \log \frac{ \prod_{t=1}^T q(x_t | x_{t-1}) }{ p_\theta(x_T) \prod_{t=1}^T p_\theta(x_{t-1} | x_t) } \right]
$$
将分子分母拆开对数：
$$
= \mathbb{E}_q \left[ - \log p_\theta(x_T) + \sum_{t=1}^T \log \frac{q(x_t | x_{t-1})}{p_\theta(x_{t-1} | x_t)} \right]
$$
我们可以将第一项和第二项拆开来看：

- 对 $ t = 1 $ 时：
  $$
  \log \frac{q(x_1 | x_0)}{p_\theta(x_0 | x_1)} + \log \frac{1}{p_\theta(x_T)} = \log \frac{q(x_1 | x_0)}{p_\theta(x_0 | x_1)} + \log \frac{1}{p_\theta(x_T)}
  $$

- 对 $ t \geq 2 $ 时：
  $$
  \sum_{t=2}^{T} \log \frac{q(x_t | x_{t-1})}{p_\theta(x_{t-1} | x_t)}
  $$

但我们没有 $q(x_{t-1}|x_t)$，因为正向模型是 $q(x_t|x_{t-1})$，不是反向的条件概率。

我们引入真实后验 $ q(x_{t-1}|x_t, x_0) $ 来帮助计算 KL 散度，并重写为：
$$
= \mathbb{E}_q \left[ -\log p_\theta(x_T) + \sum_{t=2}^{T} \log \frac{q(x_{t-1}|x_t, x_0)}{p_\theta(x_{t-1} | x_t)} + \log \frac{q(x_t | x_{t-1})}{q(x_{t-1}|x_t, x_0)} + \log \frac{q(x_1 | x_0)}{p_\theta(x_0 | x_1)} \right]
$$

> 注意这个变换并没有改变原式的值，因为：
> $$
> \log \frac{a}{b} = \log \frac{c}{b} + \log \frac{a}{c}
> $$
> 这种技巧可以把一项分解成**一个 KL 散度 + 一项我们可以消掉的交叉项**。

其中：

- 使用了 $ \frac{q(x_t|x_{t-1})}{q(x_{t-1}|x_t,x_0)} $ 的变换，使 KL 更易处理
- 最后一项变为重建项 $ -\log p_\theta(x_0|x_1) $

最终我们得到如下组合形式：
$$
L_{\text{VLB}} = \underbrace{ \mathbb{E}_q \left[ D_{\text{KL}}(q(x_T|x_0) \| p_\theta(x_T)) \right] }_{L_T}
+ \sum_{t=2}^{T} \underbrace{ \mathbb{E}_q \left[ D_{\text{KL}}(q(x_{t-1}|x_t, x_0) \| p_\theta(x_{t-1}|x_t)) \right] }_{L_{t-1}}
- \underbrace{ \mathbb{E}_q \left[ \log p_\theta(x_0 | x_1) \right] }_{L_0}
$$
我们分别标记变分下界损失中的每个分量（写为若干项的加和）：
$$
L_{\text{VLB}} = L_T + L_{T-1} + \cdots + L_0
$$
其中各项定义如下：

- 终止项（Prior 约束项）：
  $$
  L_T = D_{\text{KL}}(q(\mathbf{x}_T | \mathbf{x}_0) \;\| \; p_\theta(\mathbf{x}_T))
  $$
  该项衡量的是数据终点在先验分布下的拟合程度。

- 中间项（时间步 KL 项）（对于 $1 \leq t \leq T-1$）：
  $$
  L_t = D_{\text{KL}}(q(\mathbf{x}_t | \mathbf{x}_{t+1}, \mathbf{x}_0) \;\| \; p_\theta(\mathbf{x}_t | \mathbf{x}_{t+1}))
  $$
  此项用于约束每个中间时间步的推理分布与模型的逆扩散过程匹配。

- 重建项（Likelihood 项）：
  $$
  L_0 = - \log p_\theta(\mathbf{x}_0 | \mathbf{x}_1)
  $$
  该项衡量的是模型还原出原始数据 $\mathbf{x}_0$ 的能力。



将上述每一项代入主公式，即构成了完整的 VLB 损失：
$$
L_{\text{VLB}} = D_{\text{KL}}(q(\mathbf{x}_T | \mathbf{x}_0) \;\| \; p_\theta(\mathbf{x}_T)) + \sum_{t=1}^{T-1} D_{\text{KL}}(q(\mathbf{x}_t | \mathbf{x}_{t+1}, \mathbf{x}_0) \;\| \; p_\theta(\mathbf{x}_t | \mathbf{x}_{t+1})) - \log p_\theta(\mathbf{x}_0 | \mathbf{x}_1)
$$
在变分下界 $L_{\text{VLB}}$ 中，除了 $L_0$ 以外的每一个 KL 项都比较了两个高斯分布，因此它们可以使用封闭形式（closed-form）进行计算。

其中：

- $L_T$ 是一个常数项，可以在训练过程中忽略，因为：
  - 它不依赖于可学习的参数；
  - $\mathbf{x}_T$ 是从一个固定的高斯噪声分布中采样得到的。

> 参考文献 [Ho et al., 2020](https://arxiv.org/abs/2006.11239) 提出：
>
> 使用一个从 $\mathcal{N}(\mathbf{x}_0; \boldsymbol{\mu}_\theta(\mathbf{x}_1, 1), \boldsymbol{\Sigma}_\theta(\mathbf{x}_1, 1))$ 推导出的独立的离散解码器（discrete decoder）来模拟 $L_0$。

这种处理方式使得模型训练更稳定，并将 $L_0$ 看作一种重建损失（reconstruction loss）。

 



#### 1.2.4 DDPM的训练

##### a. 训练损失 $L_t$ 的参数化

回忆一下，我们之前说到需要学习一个神经网络来近似模拟在逆扩散过程中的条件概率分布 $p_θ(x_{t−1}∣x_t)=N(x_{t−1};μ_θ(x_t,t),∑_θ(x_t,t))$ 。我们希望 $μ_θ$ 来预测 $μ~t=1αt(xt−βt1−α¯tzt)$ .因为我们已经有了 $xt$ 作为训练时的输入，我们可以将高斯噪声项进行参数化，从而在时刻 $t$ 从 $x_t$ 来预测 $z_t$ 。

 $\mu_\theta(\mathbf{x}_t, t)$ 的表达式：
$$
\mu_\theta(\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_\theta(\mathbf{x}_t, t) \right)
$$

> 其中：
>
> - $\alpha_t$, $\bar{\alpha}_t$：是时间步 $t$ 的调度参数（noise schedule）；
> - $\beta_t = 1 - \frac{\alpha_t}{\alpha_{t-1}}$：是每步添加的噪声比例；
> - $\mathbf{z}_\theta(\mathbf{x}_t, t)$：神经网络预测的噪声；
> - $\mu_\theta$：目标高斯分布的均值

从逆扩散分布中采样的方式：
$$
\mathbf{x}_{t-1} \sim \mathcal{N}\left(\mu_\theta(\mathbf{x}_t, t), \Sigma_\theta(\mathbf{x}_t, t)\right)
$$
展开写就是：
$$
\mathbf{x}_{t-1} \sim \mathcal{N}\left( \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_\theta(\mathbf{x}_t, t) \right), \Sigma_\theta(\mathbf{x}_t, t) \right)
$$
损失项 $L_t$ 被参数化，从而最小化它与 $\tilde{μ}_t$ 的差距。

我们希望学习的模型均值 $\mu_\theta(\mathbf{x}_t, t)$ 趋近于真实均值 $\tilde{\mu}_t(\mathbf{x}_t, \mathbf{x}_0)$，于是损失定义为：
$$
L_t = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \left[ \frac{1}{2 \| \Sigma_\theta(\mathbf{x}_t, t) \|_2^2} \left\| \tilde{\mu}_t(\mathbf{x}_t, \mathbf{x}_0) - \mu_\theta(\mathbf{x}_t, t) \right\|_2^2 \right]
$$
将两者的表达式带入：

- $\tilde{\mu}_t = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_t \right)$
- $\mu_\theta = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_\theta(\mathbf{x}_t, t) \right)$

两者相减后，消去公共项 $\frac{1}{\sqrt{\alpha_t}} \mathbf{x}_t$，得到的是对噪声项差异的度量：
$$
L_t = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \left[ \frac{\beta_t^2}{2 \alpha_t (1 - \bar{\alpha}_t) \| \Sigma_\theta \|_2^2} \left\| \mathbf{z}_t - \mathbf{z}_\theta(\mathbf{x}_t, t) \right\|_2^2 \right]
$$
最后用到了前向过程中的表达式：
$$
\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \mathbf{z}_t
$$
所以我们可以将 $\mathbf{x}_t$ 替换掉，只用 $\mathbf{x}_0$ 和 $\mathbf{z}_t$ 表达模型输入：
$$
L_t = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \left[ C_t \cdot \left\| \mathbf{z}_t - \mathbf{z}_\theta(\sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \mathbf{z}_t, t) \right\|_2^2 \right]
$$

$$
C_t = \frac{\beta_t^2}{2 \alpha_t (1 - \bar{\alpha}_t) \| \Sigma_\theta \|_2^2}
$$

根据经验，[Ho et al. (2020)](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2006.11239) 发现，在忽略加权项的简化目标函数下，扩散模型可以训练得效果更好：
$$
L_t^{\text{simple}} = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}, t} \left[ \left\| \mathbf{z}_t - \mathbf{z}_\theta\left( \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \mathbf{z}_t, t \right) \right\|_2^2 \right]
$$

> **为什么这种简化有效？**
>
> 在原始推导中我们知道，训练目标是最小化预测均值的误差，即：
> $$
> \| \tilde{\mu}_t - \mu_\theta \|^2
> $$
> 但由于真实均值依赖于真实数据 $\mathbf{x}_0$，而预测均值依赖于网络参数，因此通过变量替换可以转换成对**高斯噪声 $\mathbf{z}$**的预测。
>
> **更稳定**：去掉了动态的加权系数 $\frac{\beta_t^2}{2\alpha_t(1 - \bar{\alpha}_t)}$，训练更加平滑。
>
> **直接学习噪声**：模型 $\mathbf{z}_\theta$ 直接学习去噪，从而可以反推出 $\mathbf{x}_0$，简化采样过程。



因此最终简化后得目标函数为：
$$
L_{\text{simple}} = L_t^{\text{simple}} + C_t
$$
其中， $C_t$ 是一个与 $θ$ 无关的常量。



##### b. 训练与推理过程伪代码

> **训练伪代码**
>
> - $\textbf{repeat}$
>
>   - $x_0 \sim q(x_0)$ 
>
>     从真实数据分布采样
>
>   - $t \sim \text{Uniform}(\{1, \ldots, T\})$
>
>     随机选择时间步
>
>   - $\epsilon \sim \mathcal{N}(0, I)$ 
>
>     生成高斯噪声
>
>   - $x_t = \sqrt{\alpha_t} x_0 + \sqrt{1 - \alpha_t} \epsilon$ 
>
>     构造带噪样本
>
>   - 梯度下降更新：$\nabla_\theta \left\| \epsilon - z_\theta(x_t, t) \right\|^2$
>
> - $\textbf{until}$ 收敛

> **采样伪代码**
>
> - $x_T \sim \mathcal{N}(0, I)$ 
>
>   初始化标准高斯噪声
>
> - $\textbf{for}$  $x_T \sim \mathcal{N}(0, I)$  $\textbf{do}$
>
>   - $z \sim \mathcal{N}(0, I)$  $\textbf{if}$  $t > 1$  $\textbf{else}$  $z = 0$
>   - $x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \Big( x_t - \frac{1-\alpha_t}{\sqrt{1-\alpha_t}} z_\theta(x_t, t) \Big) + \sigma_t z$
>
> - $\textbf{end for}$
>
> - $\textbf{return}$ $x_0$
>
>   生成最终样本





## 2. DDIM

DDIM: Denoising Diffusion Implicit Models | DaNing的博客
https://adaning.github.io/posts/40650.html

《Denoising Diffusion Implicit Models》https://arxiv.org/abs/2010.02502



在DDPM中我们提到, 其前向过程和反向过程都是在**一阶马尔科夫链**下定义的。但是依赖马尔科夫链的DDPM生成速度非常慢, 有没有什么办法来加速采样, 实现更高效率的生成呢?

要是能在这个基础上和DDPM的前向过程兼容, 只改变反向过程, 以此达到复用训练好的DDPM模型权重的目的就更好了。



### 2.1 Non-Markovian 前向过程的变分推断

> **我们有DDPM训练目标：**
> $$
> L_t = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \left[ C_t \cdot \left\| \mathbf{z}_t - \mathbf{z}_\theta(\sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \mathbf{z}_t, t) \right\|_2^2 \right]
> $$
>
> $$
> C_t = \frac{\beta_t^2}{2 \alpha_t (1 - \bar{\alpha}_t) \| \Sigma_\theta \|_2^2}
> $$
>

通过对DDPM的训练目标 $L_t$ 的观察, 发现 $L_t$ 实际上只取决于边缘分布$q(x_t∣x_0)$ , 而不是取决于联合分布 $q(x_{1:T}∣x_0)$ 。 因此可以考虑将 $q(x_t∣x_0)$ 推导过程中的遵循马尔科夫假设的 $q(x_t∣x_{t−1})$ 剥离, 建立一个非马尔科夫前向过程, 从而得到一个新的反向过程与生成过程.

> 因此这个观察也给我们一个启发, 只要任何满足DDPM条件, 且能保证模型具有等价目标函数的前向过程设计都是可行的.



#### 2.1.1 Non-Markovian 前向过程

我们不考虑马尔科夫性依赖时，可以将前向过程写成一组由方差 $σ$ 控制的分布：

$$
q_σ(\mathbf{x}_{1:T} \mid \mathbf{x}_0) := q_σ(\mathbf{x}_T \mid \mathbf{x}_0) \prod_{t=2}^T q_σ(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)
$$
由于DDPM的定义，所以需要满足 $t>1$ 时，$q_σ(\mathbf{x}_T \mid \mathbf{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha}_T} \mathbf{x}_0, (1 - \bar{\alpha}_T) \mathbf{I})$ ，即 $q_σ(\mathbf{x}_T \mid \mathbf{x}_0)$ 已知。

> 其中：
>
> - $\mathbf{x}_0$ 为原始图像或数据（通常来自真实数据分布 $q(\mathbf{x}_0)$）
> - $\mathbf{x}_t$ 为第 $t$ 步的中间状态，是逐步添加噪声后的图像或数据
> - $T$ 为前向过程的总步数
> - $q_σ(\cdot)$ 为前向过程的联合概率分布，受方差控制
> - $q_σ(\mathbf{x}_{1:T} \mid \mathbf{x}_0)$ 为给定原始数据 $\mathbf{x}_0$，整个噪声过程从 1 到 $T$ 步的联合分布
>
> - $q_σ(\mathbf{x}_T \mid \mathbf{x}_0)$ 为给定原始数据 $\mathbf{x}_0$，直接跳到第 $T$ 步的分布
> - $q_σ(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$ 为给定第 $t$ 步状态和原始数据的条件概率，描述 **从 $\mathbf{x}_{t}$ 到 $\mathbf{x}_{t-1}$ 的反向推理**
>
> - $\bar{\alpha}_T$ 为从时间 1 到 $T$ 的累计噪声衰减系数
> - $\mathbf{I}$ 为单位矩阵，代表各维度独立、协方差为单位值
>
> 而这里我们讨论的非马尔可夫性前向过程，意味着每一步的状态不仅依赖于前一状态，还可依赖原始状态 $\mathbf{x}_0$（这是合理的，因为我们可以显式知道 $q(\mathbf{x}_t \mid \mathbf{x}_0)$ 为高斯分布）。因此该表示形式允许我们构建一个 **完全基于 $\mathbf{x}_0$ 的分布族**，从 $\mathbf{x}*0$ 推出 $\mathbf{x}_{T}$，然后通过条件分布逐步重建前面的状态（如 $\mathbf{x}_{T-1}$、$\mathbf{x}_{T-2}$ 等）。

以上是 DDPM 中对完整前向过程联合分布的定义。

DDPM中出现的 $q_σ(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$ 被使用一阶马尔可夫链替换成 $q_σ(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$ 。若想拜托对马尔可夫链的依赖，这里肯定就不能再把它替换成 $q_σ(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$ 了，需要直接定义分布 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$：
$$
q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N} \left( 
\sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \cdot \frac{\mathbf{x}_t - \sqrt{\bar{\alpha}_t} \mathbf{x}_0}{\sqrt{1 - \bar{\alpha}_t}}, \ \sigma_t^2 \mathbf{I}
\right)
$$

> 解释如下：
> - 这项直接指定均值和方差，而不使用马尔科夫链的递归结构。
> - 该公式允许在 $\sigma_t \to 0$ 时实现确定性生成（DDIM 模式），或在 $\sigma_t$ 较大时引入随机性（DDPM 模式）。

当然，为了保证与DDPM兼容，能够共用相同的前向过程，我们需要确保 $\sigma_t = \sqrt{1 - \bar{\alpha}_t / \bar{\alpha}_{t-1}}$，此时：

$$
q_\sigma(\mathbf{x}_t \mid \mathbf{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t) \mathbf{I})
$$
有了 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$ 和 $q(\mathbf{x}_t \mid \mathbf{x}_0)$ 后，可以根据贝叶斯公式，写出：

$$
q_\sigma(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}, \mathbf{x}_0) = \frac{q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) q_\sigma(\mathbf{x}_t \mid \mathbf{x}_0)}{q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_0)}
$$

> - 在 DDPM 中，每一步都是条件高斯采样，因此是**马尔科夫链结构**；
> - 在 DDIM 中，直接对 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$ 建模，不再依赖马尔科夫性；
> - $\sigma_t$ 控制生成过程的**随机程度**，$\sigma_t = 0$ 时为确定性（DDIM），$\sigma_t = \text{DDPM 标准}$ 时为随机采样。

它仍然是一个高斯分布。但是与 DDPM 的前向过程不同，这里的前向过程不再是一个马尔科夫链，因为每个步骤的分布 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$ 不仅依赖于 $\mathbf{x}_{t-1}$，还依赖于 $\mathbf{x}_0$ 

$\sigma_t$ 决定了前向过程的随机程度。当 $\sigma \to 0$ 时，有一个极端情况，即已知 $\mathbf{x}_0$ 和 $\mathbf{x}_t$ 时，那么 $\mathbf{x}_{t-1}$ 将是确定的，不再具有任何随机性。


##### Proof 证明

分布 $q_σ(x_{t−1}∣x_t,x_0)$ 的形式是怎么得到的呢?

------

##### a. Reverse Proof 反向证明

逆向证明仅需证明作者构造的 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$ 能使得 DDPM 的前向过程的设计 $q_\sigma(\mathbf{x}_t \mid \mathbf{x}_0) = \mathcal{N}(\alpha_t \mathbf{x}_0, (1 - \alpha_t)\mathbf{I})$ 对于所有的时间 $t \leq T$ 都能够被满足。

显然我们只需要验证中间过程是否满足 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_0) = \mathcal{N}(\alpha_{t-1} \mathbf{x}_0, (1 - \alpha_{t-1}) \mathbf{I})$ .

根据边缘分布的定义，我们可以通过对 $\mathbf{x}_t$ 的积分来计算 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_0)$：

$$
q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_0) := \int_{\mathbf{x}_t} q_\sigma(\mathbf{x}_t \mid \mathbf{x}_0) \cdot q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \, d\mathbf{x}_t
$$

> **边缘分布计算公式（Marginalization）**
>
> 从联合概率出发，如果你知道条件概率 $p(a \mid b)$ 和 $p(b)$，那么你可以得到边缘分布：
> $$
> p(a) = \int p(a \mid b) \cdot p(b) \, db
> $$
> 因此我们可以：
> $$
> q(\mathbf{x}_{t-1} \mid \mathbf{x}_0) = \int q(\mathbf{x}_{t}, \mathbf{x}_{t-1} \mid \mathbf{x}_0) \, d\mathbf{x}_t
> = \int q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0) \cdot q(\mathbf{x}_t \mid \mathbf{x}_0) \, d\mathbf{x}_t
> $$

这个积分是两个高斯分布的卷积运算，因此 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_0)$ 仍然是一个高斯分布。设其形式为：
$$
q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_0) = \mathcal{N}(\boldsymbol{\mu}_{t-1}, \boldsymbol{\Sigma}_{t-1})
$$

> **概率论中高斯分布的卷积性质**
>
> - 积分的本质：边缘化
>
>   我们在算的积分是 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_0) = \int q_\sigma(\mathbf{x}_t \mid \mathbf{x}_0) \cdot q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \, d\mathbf{x}_t$ .这是将 $\mathbf{x}_t$ “积分掉”，目的是得到 $\mathbf{x}_{t-1}$ 在已知 $\mathbf{x}_0$ 下的边缘分布。
>
> - 两个高斯分布的加权积分（卷积）会得到一个高斯分布。
>
>   如果你从一个高斯 $\mathbf{x}_t \sim \mathcal{N}(\boldsymbol{\mu}_t, \boldsymbol{\Sigma}_t)$ 采样；
>   然后将这个变量通过一个高斯噪声过程生成 $\mathbf{x}_{t-1} \sim \mathcal{N}(A\mathbf{x}_t + b, \boldsymbol{\Sigma}')$；
>   那么边缘分布 $\mathbf{x}_{t-1} \mid \mathbf{x}_0$ 仍然是一个高斯分布！
>
>   这个结论来源于高斯分布在**仿射变换和加性噪声下的闭合性（closure property）**
>
> 因此从数学角度，这个积分形式：
> $$
> q(\mathbf{x}_{t-1}) = \int \mathcal{N}(\mathbf{x}_t; \boldsymbol{\mu}_t, \boldsymbol{\Sigma}_t) \cdot \mathcal{N}(\mathbf{x}_{t-1}; A \mathbf{x}_t + b, \boldsymbol{\Sigma}') \, d\mathbf{x}_t
> $$
> 是一个高斯卷积（convolution of Gaussians）。它的结果是：
> $$
> q(\mathbf{x}_{t-1}) = \mathcal{N}(A \boldsymbol{\mu}_t + b, A \boldsymbol{\Sigma}_t A^\top + \boldsymbol{\Sigma}')
> $$
> 也就是说，**两个高斯的组合积分得到的仍是高斯**，只需要根据公式计算新的均值和协方差。
>
> 这也是 DDPM 的 forward 过程设计中很关键的一点：**所有中间变量始终保持高斯分布形式，推导简单、采样容易、训练方便。**

我们代入已知条件：

- $q_\sigma(\mathbf{x}_t \mid \mathbf{x}_0) = \mathcal{N}(\alpha_t \mathbf{x}_0, (1 - \alpha_t)\mathbf{I})$
- $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}\left(
\sqrt{\alpha_{t-1}} \mathbf{x}_0 + \sqrt{1 - \alpha_{t-1} - \sigma_t^2} \cdot \frac{\mathbf{x}_t - \sqrt{\alpha_t} \mathbf{x}_0}{\sqrt{1 - \alpha_t}}, \, \sigma_t^2 \mathbf{I} \right)$

从中可以计算得到 $\boldsymbol{\mu}_{t-1}$ 和 $\boldsymbol{\Sigma}_{t-1}$：

- 均值部分：

  $$
  \boldsymbol{\mu}_{t-1} = \sqrt{\alpha_{t-1}} \mathbf{x}_0 + \sqrt{\frac{1 - \alpha_{t-1} - \sigma_t^2}{1 - \alpha_t}} \cdot (\sqrt{\alpha_t} \mathbf{x}_0 - \sqrt{\alpha_t} \mathbf{x}_0) = \sqrt{\alpha_{t-1}} \mathbf{x}_0
  $$

- 方差部分（使用方差分解公式）：

  $$
  \boldsymbol{\Sigma}_{t-1} = \sigma_t^2 \mathbf{I} +  \frac{1 - \alpha_{t-1} - \sigma_t^2}{1 - \alpha_t}  \cdot (1 - \alpha_t) \mathbf{I} = (1 - \alpha_{t-1}) \mathbf{I}
  $$

因此我们最终得到：

$$
q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_0) = \mathcal{N}(\alpha_{t-1} \mathbf{x}_0, (1 - \alpha_{t-1}) \mathbf{I})
$$

这表明：通过递推的方式，我们可以证明对于所有 $t \leq T$，都有：

$$
q_\sigma(\mathbf{x}_t \mid \mathbf{x}_0) = \mathcal{N}(\alpha_t \mathbf{x}_0, (1 - \alpha_t) \mathbf{I})
$$

因此，作者所构造的 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$ 能够完美复现 DDPM 前向过程的设计目标。

------

##### b. Forward Proof 前向证明

当然, 一个更合理的视角是用**待定系数法**正着推, 思路来自[生成扩散模型漫谈（四）：DDIM = 高观点DDPM - 科学空间|Scientific Spaces](https://spaces.ac.cn/archives/9181).

在 DDPM 中，我们知道 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$ 本身是一个高斯分布，因此我们可以更一般地假设其形式为 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \sim \mathcal{N}(k\mathbf{x}_0 + m\mathbf{x}_t, \sigma^2 \mathbf{I})$ 因此我们可以写成：

$$
\mathbf{x}_{t-1} = k\mathbf{x}_0 + m\mathbf{x}_t + \sigma \boldsymbol{\epsilon}, \quad \boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})
$$

在 DDPM 中我们有：

$$
\mathbf{x}_t = \alpha_t \mathbf{x}_0 + \sqrt{1 - \alpha_t} \boldsymbol{\epsilon}' , \quad \boldsymbol{\epsilon}' \sim \mathcal{N}(0, \mathbf{I})
$$

$\mathbf{x}_{t-1}$ 中有 $\mathbf{x}_{t}$ ，将 $\mathbf{x}_{t}$ 其代入 $\mathbf{x}_{t-1}$ 得：

$$
\begin{aligned}
\mathbf{x}_{t-1} 
&= k\mathbf{x}_0 + m\mathbf{x}_t + \sigma \boldsymbol{\epsilon} \\
&= k\mathbf{x}_0 + m(\sqrt{\alpha_t} \mathbf{x}_0 + \sqrt{1 - \alpha_t} \boldsymbol{\epsilon}') + \sigma \boldsymbol{\epsilon} \\
&= (k + m\sqrt{\alpha_t})\mathbf{x}_0 + m\sqrt{1 - \alpha_t} \boldsymbol{\epsilon}' + \sigma \boldsymbol{\epsilon}
\end{aligned}
$$

注意此处 $\boldsymbol{\epsilon}, \boldsymbol{\epsilon}'$ 是两个独立的标准正态分布。两个正态分布的和的方差为二者方差之和。

根据 DDPM 的前向过程定义：

$$
\mathbf{x}_{t-1} = \sqrt{\alpha_{t-1}} \mathbf{x}_0 + \sqrt{1 - \alpha_{t-1}} \boldsymbol{\epsilon}, \quad \boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})
$$

由此我们可以采用待定系数法，匹配两边：

$$
\begin{cases}
k + m\sqrt{\alpha_t} = \sqrt{\alpha_{t-1}} \\
m^2 (1 - \alpha_t) + \sigma^2 = 1 - \alpha_{t-1}
\end{cases}
$$

从第一个方程可得 $k$：

$$
k = \sqrt{\alpha_{t-1}} - m\sqrt{\alpha_t}
$$

从第二个方程可得 $m^2$ ：

$$
m^2 (1 - \alpha_t) + \sigma^2 = 1 - \alpha_{t-1}
\Rightarrow
m^2 = \frac{1 - \alpha_{t-1} - \sigma^2}{1 - \alpha_t}
$$

因此第二个方程 $m$ ：

$$
m = \sqrt{\frac{1 - \alpha_{t-1} - \sigma^2}{1 - \alpha_t}}
$$

代入 $k$ 的表达式中：

$$
k = \sqrt{\alpha_{t-1}} - \sqrt{\alpha_t} \cdot \sqrt{\frac{1 - \alpha_{t-1} - \sigma^2}{1 - \alpha_t}}
$$

将 $m, k$ 代入到原公式：

$$
\mathbf{x}_{t-1} = k \mathbf{x}_0 + m \mathbf{x}_t + \sigma \boldsymbol{\epsilon}
$$

即可得到 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(k \mathbf{x}_0 + m \mathbf{x}_t, \sigma^2 \mathbf{I})$ ，得证。

------



#### 2.1.2 Generative Process

扩散模型的生成过程 $p_\theta(x_{0:T})$ 是一个逐步去噪的马尔可夫链，其每一步都需要使用刚才定义的 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$：

$$
p_\theta(x_{0:T}) = p(x_T) \prod_{t=1}^{T} p_\theta(x_{t-1} \mid x_t)
$$

其中 $p(x_T) = \mathcal{N}(x_T; 0, I)$ 表示从初始高斯噪声开始的采样。

在前向过程（Forward Process）中，我们有：

$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)
$$

我们想要在生成过程中构建 $p_\theta(x_{t-1} \mid x_t)$，使用已知的 $q_\sigma(x_{t-1} \mid x_t, x_0)$。但由于在推理过程中我们无法直接获得 $x_0$，需要通过模型在已知 $x_t$ 的情况下用 $f_\theta^{(t)}(x_t)$ 将 $x_0$ 估计出来。

通过将前向过程公式 $x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon$ 变形得到：

$$
x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}} \left( x_t - \sqrt{1 - \bar{\alpha}_t} \, \epsilon \right)
$$

其中的 $\epsilon$ 可以有模型 $\epsilon_\theta^{(t)}(x_t)$ 预测得到，因此在 $x_t$ 出对 $x_0$ 的估计 $f_\theta^{(t)}(x_t)$ 可以写成：

$$
f_\theta^{(t)}(x_t) := \frac{1}{\sqrt{\bar{\alpha}_t}} \left( x_t - \sqrt{1 - \bar{\alpha}_t} \cdot \epsilon_\theta^{(t)}(x_t) \right)
$$

接着就可以定义生成过程 $p_\theta(x_{0:T})$ ，同时将我们的估计值 $f_\theta^{(t)}(x_t)$ 代入原有的后验分布 $q_\sigma(x_{t-1} \mid x_t, x_0)$ 的 $x_0$ 中，定义生成过程每一步为：

$$
p_\theta^{(t)}(x_{t-1} \mid x_t) =
\begin{cases}
\mathcal{N}\left(f_\theta^{(1)}(x_1), \sigma_1^2 I\right) & \text{if } t = 1 \\
q_\sigma\left(x_{t-1} \mid x_t, f_\theta^{(t)}(x_t)\right) & \text{otherwise}
\end{cases}
$$

$$
p_\theta(x_{T}) = \mathcal{N}(0, I)
$$

综上，完整的生成过程定义为：
$$
p_\theta(x_{0:T}) = p(x_T) \prod_{t=1}^{T} p_\theta^{(t)}(x_{t-1} \mid x_t)
$$


### 2.2 从广义生成过程中采样

前面说过, DDPM中的训练目标 $L_1$ 只取决于 $q(x_t∣x_0)$ 。

> DDPM 的训练目标函数是：
> $$
> L_1 := \mathbb{E}_{x_0, \epsilon, t} \left[ \| \epsilon - \epsilon_\theta(x_t, t) \|^2 \right]
> $$
> 其中 $x_t$ 是通过前向过程加噪得到的：
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, I)
> $$
> 你会发现，训练目标 $L_1$ 的**全部建模逻辑都基于 $q(x_t \mid x_0)$**，也就是说：
>
> - 并**没有用到 $q(x_{t-1} \mid x_t, x_0)$**，也没有限制后验的结构。
> - 更不依赖生成过程的马尔科夫性。

由于上面定义的 $q_σ(x_{t−1}∣x_t,x_0)$ 满足 $q_σ(x_t∣x_0) = N(\sqrt{α_t} x_0,(1−α_t)I)$ 的假设，

> DDPM 和 DDIM 可能使用不同形式的 $q_\sigma(x_{t-1} \mid x_t, x_0)$，但只要它们**都保证最终的边缘分布 $q(x_t \mid x_0)$ 相同**，那么它们就可以使用相同的训练数据和损失。
>
> 这是因为：
>
> - 训练目标依赖的是 $x_t$ 和 $x_0$ 的联合分布。
> - 如果这两个版本的扩散过程（DDPM 和 DDIM）都能从 $x_0$ 生成出相同分布的 $x_t$，那么训练目标就完全一样！

所以 DDPM 和 DDIM 的 $q_σ(x_t∣x_0)$ 是相同的，因此 DDPM 和 DDIM 的目标函数就是**等价**的。

> 如上所述，**两者的 $q(x_t \mid x_0)$ 是一样的**，训练目标是基于它定义的，所以：
> $$
> L_1^{\text{DDPM}} = L_1^{\text{DDIM}}
> $$
> 也就是说，你**只训练一次模型 $\epsilon_\theta$（通常在 DDPM 框架下训练）**，它就可以同时用于：
>
> - DDPM 的马尔科夫采样（每一步采样 $x_{t-1} \sim \mathcal{N}(\mu, \sigma^2 I)$）
> - DDIM 的确定性采样（无随机性，采样速度快）



所以, 实际上在 DDPM 用 $L_1$ 作为目标函数的同时, **不光训练了基于马尔科夫链的前向过程对应的生成过程**, **还顺手训练了我们引入 $σ$ 参数化的非马尔科夫的前向过程对应的生成过程**。如此一来就不用重新训 DDPM ，这么一看 DDPM 真是个大善人。

> - **DDPM 的训练目标并没有“锁死”只能用于马尔科夫的反向采样链。**
> - 你可以设计一个不同的采样方式（比如 DDIM 的确定性采样），只要它在训练时遵守相同的 $q(x_t \mid x_0)$ 分布即可。
> - 所以**DDIM 的非马尔科夫采样方式也能复用 DDPM 的模型参数**，而无需重新训练。
>
> 这就像你写了一个网络去预测 $\epsilon_\theta(x_t, t)$，然后可以**插上不同的“采样引擎”**（马尔科夫、非马尔科夫、随机的、确定的……），全都能跑！



#### 2.2.1 Denoising Diffusion Implict Models

写出生成过程 $p_\theta(x_{1:T})$ 中基于非马尔科夫推导的 $q_\sigma(x_{t-1} \mid x_t, f_\theta^{(t)}(x_t))$，得到通过 $x_t$ 得到 $x_{t-1}$ 的最终表达式：

$$
x_{t-1} = \underbrace{\sqrt{\alpha_{t-1}} \left( \frac{x_t - \sqrt{1 - \alpha_t} \epsilon_\theta^{(t)}(x_t)}{\sqrt{\alpha_t}} \right)}_{\text{predicted } x_0}
+ \underbrace{\sqrt{1 - \alpha_{t-1} - \sigma_t^2} \cdot \epsilon_\theta^{(t)}(x_t)}_{\text{direction pointing to } x_t}
+ \underbrace{\sigma_t \cdot \epsilon_t}_{\text{random noise}}
$$

其中定义 $\alpha_0 := 1$，$\epsilon_t \sim \mathcal{N}(0, I)$ 为与 $x_t$ 无关的标准正态分布噪声。不同的 $\sigma$ 可以决定不同的生成过程。$\epsilon_\theta$ 是由 DDPM 训练时候得到的，所以在推理时采样可以不用对模型重新训练，只需调整 $\sigma$ 即可。

这个式子由三项组成，逐一观察：

- 前面一项 ：

  就是 $f_\theta^{(t)}(x_t)$ 前面乘了个 $\sqrt{\alpha_{t-1}}$，整体作用是对 $x_0$ 的一个估计值（Predicted $x_0$）。

  显然，在生成过程的起始阶段（$t$ 较大时），由于 $x_t$ 相距 $x_0$ 还比较远，$x_t$ 已经被大量噪声污染，在 $t$ 时刻预测的 $x_0$ 很有可能不太准，所以这个过程需要多次迭代来实现对 $x_0$ 相对准确的估计。

  

- 中间一项：

  $\epsilon_\theta^{(t)}$ 是在 $t$ 时刻模型预测出的噪声。对于 $x_{t-1}$ 来说，$x_t$ 是对 $x_{t-1}$ 添加噪声得到的，所以这一项指示了 $x_t$ 的方向（Direction Pointing to $x_t$）。

  上面提到过，对 $\hat{x}_0$ 的估计并不够准确，因此这一项可以看成是在 $\hat{x}_0$ 的基础上引入对 $x_t$ 方向的修正，使得生成过程满足对前向过程中 $x_{t-1} \rightarrow x_t$ 条件的保证，防止得到的 $x_{t-1}$ 偏离 $x_{t-1} \rightarrow x_t$ 的路径。

  其中的 $\sqrt{1 - \alpha_{t-1} - \sigma_t^2}$ 是对 $\epsilon_\theta^{(t)}$ 的修正系数。$\epsilon_\theta^{(t)}$ 与 $\sigma_t$ 负相关。

  > $\sigma_t$ 越小，$\epsilon_\theta^{(t)}$ 的作用越大，模型预测的“去噪方向”更可信；
  >
  > $\sigma_t$ 越大，噪声占比越重，模型预测的“去噪方向”占比减少，更多依赖随机重采样。

  

- 最后一项：

  为了保证 $x_{t-1}$ 为概率分布而做的重采样，即在 $t$ 时刻添加的随机噪声 $\sigma_t \epsilon_t$。

  它是与 $\sigma_t$ 正相关的，总的噪声 $\epsilon_\theta^{(t)} + \epsilon_t$ 恰好可以在后两项得到平衡。

  >
  > 由于前向是概率过程，**反向也必须是一个概率过程**，否则就不能复现前向过程中引入的不确定性。
  >
  > 所以我们使用一个带噪声的分布来建模 $p_\theta(x_{t-1} | x_t)$，通常写作：
  > $$
  > p_\theta(x_{t-1} \mid x_t) = \mathcal{N}(\mu_\theta(x_t, t), \sigma_t^2 I)
  > $$
  > 这里的 $\sigma_t$ 是人为设定或计算出来的方差。
  >
  > **为什么要加 $\sigma_t \epsilon_t$？**
  >
  > 我们从上面的高斯分布采样时，实际执行的就是：
  > $$
  > x_{t-1} = \mu_\theta(x_t, t) + \sigma_t \epsilon_t,\quad \epsilon_t \sim \mathcal{N}(0, I)
  > $$
  > **噪声平衡是指什么**
  >
  > - $\epsilon_\theta^{(t)}(x_t)$ 是模型预测出来的，表示“**估计出的噪声方向**”
  >
  > - $\epsilon_t$ 是从标准正态分布中随机采样得到的，表示“**随机扰动方向**”。
  >
  > 在生成公式中：
  > $$
  > x_{t-1} = \underbrace{\text{predicted } x_0}_{\text{从 }\epsilon_\theta\text{得到}} + \underbrace{\text{修正方向（也包含 }\epsilon_\theta\text{）}} + \underbrace{\sigma_t \epsilon_t}_{\text{随机扰动}}
  > $$
  >
  > - 前两项（合起来）大体确定一个方向，是模型通过预测 $\epsilon_\theta$ 估计出的“退噪方向”；
  > - 第三项是随机性来源，**随着 $\sigma_t$ 越大，它的权重越大**，让生成多样性增加。
  >
  > 所以“噪声平衡”描述的是 **模型预测噪声 vs. 随机噪声** 的相对比例。你可以理解为：
  > $$
  > \text{总噪声} = \text{模型引导的噪声} + \text{采样带来的不确定性}
  > $$
  > 当 $\sigma_t$ 趋近于 0，就退化为 **确定性生成**（即 DDIM）

- 



当然，$\sigma_t$ 是可以任意选取的，有两种特殊情况：

- 当有 $\sigma_t = \sqrt{\frac{(1 - \alpha_{t-1})}{(1 - \alpha_t)}} \cdot {\sqrt{\frac{1 - \alpha_t}{\alpha_{t-1}}}}$ 时，前向过程是马尔科夫链，生成过程恰好是 DDPM。

- 当有 $\sigma_t = 0$ 时，在给定 $x_{t-1}, x_0$ 情况下，除去 $t=1$ 外，前向过程会变成一个**完全确定性**的过程，随机噪声 $\epsilon_t$ 也就为 0 了。第二项的修正系数恰好为 $1 - \alpha_{t-1}$，有
$$
x_{t-1} = \sqrt{\alpha_{t-1}} f_\theta^{(t)}(x_t) + \sqrt{1 - \alpha_{t-1}} \epsilon_\theta^{(t)}(x_t)
$$

虽然 $\sigma_t$ 可以任意取，但对于 DDIM，一般指 $\sigma_t = 0$ 的情况，生成的结果不再具有随机性。所以说它是一种具有 DDPM 训练目标的**隐式概率模型**，因而被称为 DDIM (Denoising Diffusion Implicit Model)。



#### 2.2.2 Accelerated Generation Processes 加速生成

正如上文所述，DDPM 的训练目标 $$\mathcal{L}_1$$ 与前向过程的形式无关，当 $$q_\sigma(x_t \mid x_0)$$ 固定时就是确定的。所以只要满足 $q_\sigma(x_t \mid x_0) = \mathcal{N}(\sqrt{\alpha_t} x_0, (1 - \alpha_t) \mathbf{I})$ 即可，怎么取前向过程都没问题。

分析一下 DDIM 的两个优势：

- 有了定义在非马尔科夫链上的 $$q_\sigma(x_{t-1} \mid x_t, x_0)$$，这就使得 $$x_{t-1}$$ 可以依赖对 $$x_0$$ 的估计，而不单取决于 $$x_t$$。

  不过注意，在 DDPM 中，$$t-1, t$$ 都来自于连续的时间序列 $$t \in [1, \dots, T]$$，所以 $$t-1, t$$ 都是连续的。但在 DDIM 中由于非马尔科夫性，这里的 $$t-1, t$$ **不再是一个连续序列中的两个时间步**。

  觉得别扭的话可以将它们换个字母，比如在一个新的不连续子序列 $$s \in [1, \dots, s_{i-1}, s_i, \dots, T]$$ 中，$$s_{i-1}$$ 可以对应 DDPM 里的 $$t = 900$$，$$s_i$$ 可以对应 $$t = 800$$。

- $$\sigma_t = 0$$ 的确定性采样带来了一条确定性轨迹，消除了随机性。这个性质使我们在已知 $$x_t$$ 的情况下可以估计到更远的地方，并具有更高的准确性，即**允许我们跳过更多的步骤采样**。

综上，甚至可以考虑定义长度远小于 $$T$$ 的前向过程来**加速采样过程**。

例如，可以考虑定义在一个 $$x_{1:T}$$ 的子集 $$\{x_{\tau_1}, \dots, x_{\tau_S}\}$$ 上的前向过程，$$\tau$$ 为长度为 $$S$$ 的递增子序列 $[1, \dots, T] = [\tau_1, \dots, \tau_S]$

该前向过程需要满足：

$$
q(x_{\tau_i} \mid x_0) = \mathcal{N}(\sqrt{\alpha_{\tau_i}} x_0, (1 - \alpha_{\tau_i}) \mathbf{I})
$$

相对应的，此时的生成过程是定义在这个子序列 $$\tau$$ 的逆序列 $$\text{reversed}(\tau)$$ 上的采样过程。此时的生成过程中 $$x_{\tau_{i-1}}$$ 为：

$$
x_{\tau_{i-1}} = \sqrt{\alpha_{\tau_{i-1}}} \left( \frac{x_{\tau_i} - \sqrt{1 - \alpha_{\tau_i}} \cdot \epsilon_\theta^{(\tau_i)}(x_{\tau_i})}{\sqrt{\alpha_{\tau_i}}} \right) + \sqrt{1 - \alpha_{\tau_{i-1}} - \sigma_{\tau_i}^2} \cdot \epsilon_\theta^{(\tau_i)}(x_{\tau_i}) + \sigma_{\tau_i} \cdot \epsilon
$$

由于子序列长度 $$S$$ 远远小于原序列长度 $$T$$，所以推理速度可以实现显著提升，即“**跳步采样**”。例如 $$\tau = [1, 3]$$ 时有：

![img](./asset/ddim2.png)



##### Proof 证明

由于 $$\mathcal{L}_1$$ 与前向过程的形式无关，所以在加速过程中，可将前向过程分解为：

$$
q_{\sigma, \tau}(x_{1:T} \mid x_0) = q_{\sigma, \tau}(x_{\tau_S} \mid x_0) \prod_{i=1}^S q_{\sigma, \tau}(x_{\tau_{i-1}} \mid x_{\tau_i}, x_0) \prod_{t \in \bar{\tau}} q_{\sigma, \tau}(x_t \mid x_0)
$$

其中 $$\tau$$ 为长度为 $$S$$ 的子序列 $$[1, \dots, T]$$，且 $$\tau_S = T$$，同时令 $$\bar{\tau} := \{1, \dots, T\} \setminus \tau$$ 为 $$\tau$$ 的补集。第一项与第二项来自子序列 $$\tau$$，第三项来自于补集 $$\bar{\tau}$$。

> 基于子序列 $\tau$ 和对应的噪声方差参数 $\sigma$，构造出来的新前向过程：
> $$
> q_{\sigma, \tau}(x_{1:T} \mid x_0) = 
> \underbrace{q_{\sigma, \tau}(x_{\tau_S} \mid x_0)}_{\text{从 $x_0$ 直接加噪得到 $x_{\tau_S}$}} 
> \cdot \underbrace{\prod_{i=1}^S q_{\sigma, \tau}(x_{\tau_{i-1}} \mid x_{\tau_i}, x_0)}_{\text{非马尔科夫跳步扩散}} 
> \cdot \underbrace{\prod_{t \in \bar{\tau}} q_{\sigma, \tau}(x_t \mid x_0)}_{\text{补全所有未在 $\tau$ 中的时间步}}
> $$
> 第一项：我们最终仍然要生成 $x_{\tau_S}$，通常 $\tau_S = T$，也就是我们把整个噪声注入过程终止在 $T$ 时刻（虽然中间跳步了），但我们仍需保证这一步满足 $q(x_T \mid x_0)$ 的定义。
>
> 第二项：构建跳步链（DDIM 的核心），每个 $x_{\tau_{i-1}}$ 是从 $x_{\tau_i}$ 和 $x_0$ 推导出来的，不再是标准马尔科夫条件下的 $x_{\tau_{i-1}} \sim q(x_{\tau_{i-1}} \mid x_{\tau_i})$，而是依赖于 $x_0$ 的非马尔科夫链。
>
> 第三项：由于 $\tau$ 是一个子集（例如只取了 $[1, 10, 20, 30]$），剩下的那些时间步 $\bar{\tau}$（如 $2, 3, 4, 5,\dots$）我们不需要建链，但在变分下界（training loss）中仍然要计算 KL（作为 regularizer）。

接着，仿照在推导非马尔科夫的前向过程，给出定义：

$$
q_{\sigma, \tau}(x_t \mid x_0) = \mathcal{N}(\sqrt{\alpha_t} x_0, (1 - \alpha_t) \mathbf{I}), \quad \forall t \in \bar{\tau} \cup \{T\}
$$

$$
q_{\sigma, \tau}(x_{\tau_{i-1}} \mid x_{\tau_i}, x_0) = \mathcal{N} \left( \sqrt{\alpha_{\tau_{i-1}}} x_0 + \sqrt{1 - \alpha_{\tau_{i-1}} - \sigma_{\tau_i}^2} \cdot \frac{x_{\tau_i} - \sqrt{\alpha_{\tau_i}} x_0}{\sqrt{1 - \alpha_{\tau_i}}}, \sigma_{\tau_i}^2 \mathbf{I} \right), \quad \forall i \in [S]
$$

> - 对于补集 $\bar{\tau} \cup {T}$ 中的时间步 $q_{\sigma, \tau}(x_t \mid x_0)$：
>
>   和 DDPM 中的标准定义一致，表示在这些时间步，**直接从 $x_0$ 加噪声得到 $x_t$**，是一个「一步式」的加噪。
>
> - 对于子序列 $\tau = {\tau_1, \dots, \tau_S}$ 中的连接 $q_{\sigma, \tau}(x_{\tau_{i-1}} \mid x_{\tau_i}, x_0)$：
>
>   是一个非马尔科夫条件分布，也就是说虽然从 $x_{\tau_i}$ 采样 $x_{\tau_{i-1}}$，但这个分布显式依赖于 $x_0$；
>
>   这个设计的目标是：**即使我们跳过了一些中间时间步，只走了子序列，也能保证每个 $x_{\tau_i}$ 的边缘分布仍然是标准的高斯加噪结果**。

使得子序列 $$\tau$$ 对应的前向过程满足条件：
$$
q(x_{\tau_i} \mid x_0) = \mathcal{N}(\sqrt{\alpha_{\tau_i}} x_0, (1 - \alpha_{\tau_i}) \mathbf{I}), \quad \forall i \in [S]
$$

则对应的生成过程定义为：

$$
p_\theta(x_{0:T}) := p_\theta(x_T) \underbrace{\prod_{i=1}^S p_\theta^{(\tau_i)}(x_{\tau_{i-1}} \mid x_{\tau_i})}_{\text{use to produce samples}} \times \underbrace{\prod_{t \in \bar{\tau}} p_\theta^{(t)}(x_0 \mid x_t)}_{\text{in variational objective}}
$$

> **采样阶段（use to produce samples）只走子序列的路径：**
> $$
> x_T \rightarrow x_{\tau_{S-1}} \rightarrow \cdots \rightarrow x_0
> $$
> **训练阶段（in variational objective）**，仍然需要对所有时间步 $t \in \{1, \dots, T\}$ 有 KL loss，即便这些时间步不参与采样，所以我们对补集时间步 $\bar{\tau}$ 定义：
> $$
> p_\theta^{(t)}(x_0 \mid x_t)
> $$
> 来用于训练中的变分下界（ELBO）计算。

发现仅部分模型用于生成样本。条件分布为：
$$
p_\theta^{(\tau_i)}(x_{\tau_{i-1}} \mid x_{\tau_i}) = q_{\sigma, \tau}(x_{\tau_{i-1}} \mid x_{\tau_i}, f_\theta^{(\tau_i)}(x_{\tau_{i-1}})), \quad \text{if } i \in [S], i > 1
$$

$$
p_\theta^{(t)}(x_0 \mid x_t) = \mathcal{N}(f_\theta^{(t)}(x_t), \sigma_t^2 \mathbf{I}), \quad \text{otherwise}
$$

> 对于子序列中的时间步，其生成过程模型为：
> $$
> p_\theta^{(\tau_i)}(x_{\tau_{i-1}} \mid x_{\tau_i})
> $$
> 这些是训练得到的神经网络模型，用于采样；
>
> 而对于被跳过的时间步（$\bar{\tau}$），我们只定义：
> $$
> p_\theta^{(t)}(x_0 \mid x_t)
> $$
> 用于训练中变分下界中的 KL loss 计算，而不是采样



因此，采用子序列 $$\tau$$ 进行生成过程来得到 $$x_0$$ 是可行的。

> **虽然我们跳过了一些中间时间步，只走了子序列的反向路径，但仍然能够得到一个合理的样本 $x_0$**，因为：
>
> - 每一个 $x_{\tau_i} \mid x_0$ 的边缘分布仍然是标准加噪结果；
> - 因此只要我们训练好 $p_\theta^{(\tau_i)}(x_{\tau_{i-1}} \mid x_{\tau_i})$，就能正确、合理地生成 $x_0$。



#### 2.2.3 与 Neural ODEs 的相关性

首先我们从DDIM推导差分方程。

> 差分方程（**difference equation**）是**描述离散变量之间关系**的一类数学方程，它是微分方程在离散时间上的对应形式。
>
> 差分方程是一种用**当前值和之前若干时刻的值**来描述变量变化规律的方程。
>
> 最简单的一阶差分方程形式如 $x_{t+1} = f(x_t)$ ，这表示下一时刻的变量 $x_{t+1}$ 是当前时刻 $x_t$ 的函数。
>
> 或者更具体： $x_{t+1} - x_t = \Delta x_t = f(t, x_t)$ ，这就像微分方程中的 $\frac{dx}{dt} = f(t, x(t))$，只不过差分方程是“时间离散”的。
>
> ------
>
> **举些例子**
>
> - 等差数列（线性差分方程）
>
> $$
> x_{t+1} = x_t + d
> $$
>
> 这个差分方程表示每一步都增加一个常数 $d$，对应解是：
> $$
> x_t = x_0 + td
> $$
>
> - 斐波那契数列（递推型差分方程）
>
> $$
> x_{t+1} = x_t + x_{t-1}, \quad x_0 = 0, x_1 = 1
> $$
>
> 它告诉你每一项等于前两项之和。



在 $\sigma_t = 0$ 时，DDIM 的生成是确定性的，可以将 DDIM 重写为一个 Neural ODE：
$$
\frac{x_{t - \Delta t}}{\sqrt{\alpha_{t - \Delta t}}} = \frac{x_t}{\sqrt{\alpha_t}} + \left(\sqrt{ \frac{1 - \alpha_{t - \Delta t}}{\alpha_{t - \Delta t}} } - \sqrt{ \frac{1 - \alpha_t}{\alpha_t} } \right) \epsilon_\theta^{(t)}(x_t)
$$

> 这里将 $t - 1$ 推广到 $t - \Delta t$，$\alpha_t$ 推广到 $\alpha_{t - \Delta t}$，并令 $\sigma = 0$，代入即可得到。

记 $\sigma = \frac{\sqrt{1 - \alpha}}{\sqrt{\alpha}}$，$\bar{x} = \frac{x}{\sqrt{\alpha}}$。在连续条件下，$\sigma, x$ 都为 $t$ 的函数，上式可重写为：

$$
\bar{x}(t - \Delta t) = \bar{x}(t) + [\sigma(t - \Delta t) - \sigma(t)] \cdot \epsilon_\theta^{(t)}(x(t))
$$

> 我们记：
>
> - $\bar{x}(t) := \dfrac{x_t}{\sqrt{\alpha_t}}$：这是“标准化”后的图像。
> - $\sigma(t) := \sqrt{\dfrac{1 - \alpha_t}{\alpha_t}}$：表示当前时刻的“噪声水平”。

整理一下得到差分形式：
$$
\bar{x}(t) - \bar{x}(t - \Delta t) = [\sigma(t) - \sigma(t - \Delta t)] \cdot \epsilon_\theta^{(t)}(x(t))
$$

> 上述就是一个差分方程，表示“在离散时间上，变量 $\bar{x}(t)$ 是如何随着 $\sigma(t)$ 变化的”。然后取极限 $\Delta t \to 0$，就变成了微分方程。

当 $\Delta t \to 0$ 时，差分变为微分：
$$
d\bar{x}(t) = \epsilon_\theta^{(t)}(x_t) \, d\sigma(t)
$$

> $$
> \frac{d\bar{x}(t)}{d\sigma(t)} = \epsilon_\theta^{(t)}(x_t)
> $$

将 $x_t$ 用 $\bar{x}(t), \sigma(t)$ 表示，有：
$$
x_t = \sqrt{\alpha} \cdot \bar{x}(t), \quad \alpha = \frac{1}{\sqrt{\sigma^2(t) + 1}} \quad \Rightarrow \quad x_t = \frac{\bar{x}(t)}{\sqrt{\sigma^2(t) + 1}}
$$

> 我们想让右边只包含 $\bar{x}(t)$ 和 $\sigma(t)$，所以需要将 $x_t$ 表达出来。
>
> 回忆：
> $$
> \bar{x}(t) = \frac{x_t}{\sqrt{\alpha_t}} \quad \Rightarrow \quad x_t = \sqrt{\alpha_t} \cdot \bar{x}(t)
> $$
> 又因为：
> $$
> \sigma(t) = \sqrt{\frac{1 - \alpha_t}{\alpha_t}} \Rightarrow \alpha_t = \frac{1}{\sigma^2(t) + 1}
> $$
> 代入：
> $$
> x_t = \sqrt{ \frac{1}{\sigma^2(t) + 1} } \cdot \bar{x}(t) = \frac{\bar{x}(t)}{\sqrt{\sigma^2(t) + 1}}
> $$
> 所以我们将 $x_t$ 完全用 $\bar{x}(t)$ 和 $\sigma(t)$ 表示出来了。

代入微分方程得到最终ODE：
$$
d\bar{x}(t) = \epsilon_\theta^{(t)}\left(\frac{\bar{x}(t)}{\sqrt{\sigma^2 + 1}} \right) \, d\sigma(t)
$$

因此，DDIM 的迭代去噪过程可以被写成一个 **Neural ODE**。它对应着一个**向量场**，这意味着在这个场中任意粒子的运动轨迹都是**确定**与**可逆**的。

> 这是一个 **确定性的微分方程**，描述了在 DDIM 退噪过程中的连续状态演化，可以看作一个 Neural ODE，其中：
>
> - $\bar{x}(t)$：是归一化的生成状态（中间图像）
> - $\sigma(t)$：是与 $\alpha(t)$ 有关的参数
> - $\epsilon_\theta^{(t)}(\cdot)$：是神经网络预测的噪声估计
> - 所以这就像一个 ODE 向量场 $f(\bar{x}, t)$
>
> 微分方程的解在合理条件下是**唯一确定**的——即：
>
> - 给定初始条件 $\bar{x}(T)$，ODE 的解是唯一的
> - 如果 ODE 没有奇点，就可以反过来从 $\bar{x}(0)$ 推回 $\bar{x}(T)$

初始条件为 $x(T) \sim \mathcal{N}(0, \sigma(T))$，其中 $\sigma(T)$ 是一个非常大的值，这对应着 $\alpha \approx 0$ 的情况。这意味着只要离散步足够多、离散近似连续，在这个 Neural ODE 中是可以沿着生成过程的逆向轨迹将 $x_0$ 转换为 $x_T$ 的。

在某些需要 Latent Variable 的下游任务中，这一性质可能是有用的。

> 不过注意，DDIM 的跳步步长肯定是不能选得太大。一方面是步长太大会导致对 $x_0$ 的估计不准确，多步误差累积会特别严重；另一方面是，如果**步长选得太大**，**DDIM 就不能被视作 ODE**，从而不再具备可逆性。





# B. Flow Matching

通俗易懂的Flow Matching原理解读（附核心公式推导和源代码） - 知乎
https://zhuanlan.zhihu.com/p/4116861550























# C. Diffusion VS Flow Matching

https://diffusionflow.github.io/#closing-takeaways
