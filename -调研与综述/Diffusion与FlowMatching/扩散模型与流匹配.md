# 1. Diffusion

DDPM解读（一）| 数学基础，扩散与逆扩散过程和训练推理方法 - 卡卡猡特的文章 - 知乎
https://zhuanlan.zhihu.com/p/530602852

## 2. DDPM

《Denoising Diffusion Probabilistic Models》[[2006.11239\] Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)

### 2.1 数学基础

#### 2.1.1 先验概率与后验概率

直观理解：

**先验概率 (Prior)**：在看到数据之前，你对某件事的**原本相信程度**。

**后验概率 (Posterior)**：在看到数据之后，你根据**数据更新后的相信程度**。

------

举个例子：

比如你丢一枚硬币，事先不知道是不是公平的。

- 你**先验地认为**，硬币正反面各 50%（也可能觉得偏某一边）。

后来你丢了 100 次，结果正面出来了 80 次，这个数据很不对劲。

- 根据数据，你**更新你的相信**，硬币可能是偏向正面的一枚。

这个从 "50%" 更新到 "更偏向正面" 的过程，就是：

> **先验 →（看见数据）→ 后验**

------

数学推导：

设

- 事件 $A$ 是我们关心的（比如，"硬币是偏的"）
- 数据 $B$ 是我们观察到的（比如，"丢了100次，正面出了80次"）

那么：
$$
\text{后验概率} = \frac{\text{似然} \times \text{先验概率}}{\text{证据}}
$$
公式写成：
$$
P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}
$$
其中：

- $P(A)$：**先验概率**，观察数据前对 $A$ 的主观相信
- $P(B|A)$：**似然（Likelihood）**，如果 $A$ 成立，数据 $B$ 出现的概率
- $P(B)$：**证据（Evidence）**，所有可能情况下数据 $B$ 出现的总体概率
- $P(A|B)$：**后验概率**，看过数据 $B$ 后，对 $A$ 的相信程度



| 名称       | 含义                                   |
| ---------- | -------------------------------------- |
| 先验概率   | 看到数据前的主观相信程度               |
| 似然函数   | 如果假设成立，观察到数据的可能性有多大 |
| 后验概率   | 看到数据后，新的相信程度               |
| 贝叶斯公式 | 后验 = 似然 × 先验 / 证据              |



#### 2.1.2 条件概率的一般形式

**定义**：
 如果你已经知道了事件 $B$ 发生，那么在这种条件下，事件 $A$ 发生的概率，叫做 **条件概率**。

数学上，记作：
$$
P(A|B)
$$
**公式是**：
$$
P(A|B) = \frac{P(A \cap B)}{P(B)}
\quad\quad \text{(前提是 } P(B) > 0\text{)}
$$

------

如果你有三个事件 $A$、$B$、$C$，那么：

1. **联合概率** $P(A, B, C)$ 表示
    → $A$、$B$、$C$ 三个**同时发生**的概率。
2. **条件概率的一般形式**可以写成：

$$
P(A, B, C) = P(A|B, C) \times P(B|C) \times P(C)
$$



也可以理解成：

> 联合概率可以被分解成一连串的条件概率相乘。



#### 2.1.3 马尔可夫链条件概率形式

> 马尔可夫链（**Markov Chain**）里，条件概率有个非常重要、特别简洁的形式。
> $$
> P(Xn+1∣Xn,Xn−1,…,X1)=P(Xn+1∣Xn)
> $$

马尔科夫链指当前状态的概率只与上一时刻有关，例如如满足马尔可夫关系 A→B→C ，ABC符合马尔可夫性质，那么我们可以用链式法则展开联合概 $P(A, B, C)$ :
$$
P(A,B,C)=P(A)⋅P(B∣A)⋅P(C∣B)
$$

> 马尔可夫链指当前状态的概率只与上一时刻有关，例如 $A \rightarrow B \rightarrow C$，那么有：
> $$
> P(C∣B,A)=P(C∣B)
> $$
> 马尔可夫性质。



#### 2.1.4 高斯分布的KL散度公式

设有两个一维高斯分布：

- $ p(x) = \mathcal{N}(\mu_p, \sigma_p^2) $

- $ q(x) = \mathcal{N}(\mu_q, \sigma_q^2) $

则 KL 散度 $ D_{\text{KL}}(p \,\|\, q) $ 的计算公式为：

$$
D_{\text{KL}}(p \,\|\, q) = \log\left( \frac{\sigma_q}{\sigma_p} \right) + \frac{\sigma_p^2 + (\mu_p - \mu_q)^2}{2\sigma_q^2} - \frac{1}{2}
$$
参数解释：

> 1. **第一项：**  $\log\left( \frac{\sigma_q}{\sigma_p} \right)$
>
>    反映两个分布在方差上的差异。
>
> 2. **第二项：**  $\frac{\sigma_p^2 + (\mu_p - \mu_q)^2}{2\sigma_q^2}$
>
>    包含：
>
>    - $\frac{\sigma_p^2}{2\sigma_q^2}$：分布宽度差异；
>    - $\frac{(\mu_p - \mu_q)^2}{2\sigma_q^2}$：均值之间的差异。
>
> 3. **第三项：**  $- \frac{1}{2}$
>
>    归一化常数，使散度为零时，代表两个分布完全相同。

特殊情况（均值相同）：

若 $mu_p = \mu_q$，KL 散度简化为：

$$
D_{\text{KL}}(p \,\|\, q) = \log\left( \frac{\sigma_q}{\sigma_p} \right) + \frac{\sigma_p^2}{2\sigma_q^2} - \frac{1}{2}
$$
注：

- KL 散度 $ D_{\text{KL}}(p \,\|\, q) \geq 0 $，当且仅当 $ p = q $ 时取到 0；

- KL 散度是非对称的：
  $$
  D_{\text{KL}}(p \,\|\, q) \neq D_{\text{KL}}(q \,\|\, p)
  $$



#### 2.1.5 参数重整化（重参数技巧）

我们希望从一个高斯分布中采样：
$$
x \sim \mathcal{N}(\mu, \sigma^2)
$$
但由于采样操作不可导，无法直接用于反向传播。为了解决这个问题，我们使用重参数化技巧，将随机性转移到一个独立于模型参数的随机变量中。



**重参数化形式**

我们引入标准正态变量：
$$
z \sim \mathcal{N}(0, 1)
$$
然后构造采样变量：
$$
x = \mu + \sigma \cdot z
$$
这样，$ x $ 的分布为：
$$
x \sim \mathcal{N}(\mu, \sigma^2)
$$


这么做的好处：
- 将不可导的采样操作转化为可导的仿射变换；
- 使得模型在训练过程中可以使用反向传播更新 $ \mu $ 和 $ \sigma $；
- 是变分推断中训练 VAE（Variational Autoencoder）的关键技术。



**注意事项**

- 为保证正值，通常使用 $\log \sigma^2$ 表示，训练过程中实际预测的是 $\log \sigma^2$，然后用 $\exp(\frac{1}{2} \log \sigma^2)$ 计算 $\sigma$；

- 重参数化技巧仅适用于可以重参数化的分布（如高斯分布），对于离散分布则较为困难。





### 2.2 DDPM模型

#### 2.2.1 模型总览

DDPM，全称 **Denoising Diffusion Probabilistic Model**，是一种基于**马尔可夫链的生成模型**。

![img](./asset/v2-c77c080d146c4e9d9edf17e264ebdb98_r.jpg)



DDPM模型主要分为两个过程：forward加噪过程（从右往左）和reverse去噪过程（从左往右）。

模型通过逐步添加噪声和反向去噪学习数据分布。



#### 2.2.2 Diffusion前向过程

**逐步加噪过程**

给定初始数据分布 $q(x_0)$（例如图像分布），我们定义一个前向扩散过程，在这个过程中逐步向数据中添加高斯噪声，使得原始数据在 $T$ 步之后几乎退化成各向同性高斯分布。

在这个持续 $T$ 次的加噪过程中，我们会产生一系列带噪声的图片 $x_1, ..., x_T$ 。在这个过程中，噪声的标准差/方差是以一个在区间 (0,1) 内的固定值 $β_T$ 来确定的，均值是以固定值 $β_T$ 和当前时刻的图片数据 $x_{t−1}$ 来确定的。



**加噪过程定义**

对于 $t = 1, 2, ..., T$，我们定义马尔可夫过程：

$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
$$
其中：

- $\beta_t \in (0, 1)$ 是一个预设的固定方差调度表（称为 noise schedule），通常线性或余弦方式递增；
- $\sqrt{1 - \beta_t}$ 是该步的缩放因子。



> **加噪过程的另一种表示**
>
> 每一步的加噪过程如下：
>
> $$
> q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
> $$
>
> $$
> \bar{\alpha}_t = \prod_{i=1}^T (1 - \alpha_i)
> $$
>
> $$
> \alpha_t = 1- \beta_t
> $$
>
> 
>
> - 这是一个高斯分布，其 **均值** 为 $\sqrt{\bar{\alpha}_t} x_0$，**方差** 为 $1 - \bar{\alpha}_t$；
> - 其中 $\bar{\alpha}_t = \prod_{i=1}^T (1 - \alpha_i)$ 是噪声衰减因子；
> - 因为 $\beta_t$ 是预定义的 schedule，所以 $\bar{\alpha}_t$ 也是固定的；
> - 因此，这个分布完全由 $x_0$ 和 $t$ 决定 —— 无需学习，**不是模型的一部分**。



**加噪结果**

随着 $t$ 的不断增大，最终原始数据 $x_0$ 会逐步失去它的特征。最终当 $T→∞$ 时， $x_T$ 趋近于一个各向独立的高斯分布。从视觉上来看，就是将原本一张完好的照片加噪很多步后，图片几乎变成了一张完全是噪声的图片。



**任意时刻数据 $X_t$ 的计算（参数重整化技巧）**

在前向扩散过程中，虽然 $x_t$ 是通过从 $x_{t-1}$ 不断加噪得到的，但我们其实可以跳过中间所有步骤，直接从 $x_0$ 和固定值序列 $\{β_T∈(0,1)\}_{t=1}^T $ 计算得到任意时刻 $x_t$ 

我们首先定义:
$$
\alpha_t = 1 - \beta_t
$$

$$
\bar{\alpha}_t = \prod_{i=1}^t \alpha_i = \prod_{i=1}^t (1 - \beta_i)
$$

我们可以直接通过下式采样得到某一时刻 $t$ 的带噪图像 $x_t$：
$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
$$
推导步骤：

> 我们希望从以下马尔可夫链定义的前向过程：
>
> $$
> q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{\alpha_t} x_{t-1}, (1 - \alpha_t) \mathbf{I})
> $$
>
> 推导出：
>
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 其中：
>
> - $\bar{\alpha}_t = \prod_{i=1}^t \alpha_i$
>
> 
>
> **推导过程**
>
> 首先，从一步扩散定义：
> $$
> x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1 - \alpha_t} \epsilon_t,\quad \epsilon_t \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 这表示 $x_t$ 是上一步 $x_{t-1}$ 的缩放加上独立高斯噪声的结果。
>
> 展开两步（将 $x_{t-1}$ 用 $x_{t-2}$ 表示）：
> $$
> x_{t-1} = \sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-1}
> $$
>
> 代入 $x_t$ 的公式中得到：
>
> $$
> x_t = \sqrt{\alpha_t} \left( \sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-1} \right) + \sqrt{1 - \alpha_t} \epsilon_t
> $$
>
> 继续展开并整理：
>
> $$
> x_t = \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1-\alpha_t \alpha_{t-1}} \bar\epsilon_{t-2}，\quad(*)
> $$
>
> 你可以看到，每次展开我们都得到一个 $x_0$ 的缩放加上一系列噪声项的线性组合。
>
> 
>
> > **关键技巧** $(*)$ :
> >
> > 这里使用了一个关键技巧，在 Diffusion 模型中常用于将**多步高斯噪声组合**成**一步标准高斯噪声**的形式，也叫**参数重整化**。
> >
> > 当我们合并两个均值都为 0，方差分别为 $\sigma_1^2$ 和 $\sigma_2^2$ 的高斯分布 $\mathcal{N}(0, \sigma_1^2 I)$ 和 $\mathcal{N}(0, \sigma_2^2 I)$ 时，我们得到的新的高斯分布为：
> > $$
> > \sqrt{\alpha_t - \alpha_t \alpha_{t-1}} z_{t-2} + \sqrt{1 - \alpha_t} z_{t-1}
> > $$
> > 因此可以通过参数重整化，变成只含一个随机变量 $z$ 构成的：
> > $$
> > \sqrt{1 - \bar{\alpha}_t} \cdot \bar{z}_t
> > $$
> > 的形式。
> >
> > 
> >
> > 这里使用了高斯变量的加法性质，假设我们有：
> > $$
> > z=aϵ_1+bϵ_2, \quad ϵ_1,ϵ_2∼N(0,I),独立
> > $$
> > 那么我们可以把它写成：
> > $$
> > z= \sqrt{a_2+b_2}⋅ϵ, \quad ϵ∼N(0,I)
> > $$
>
> 
>
> 继续递推 $t$ 次，可以得到一个形式：
>
> 继续这样递推下去 $t$ 次，可以得到一个形式：
>
> $$
> x_t = \sqrt{\prod_{i=1}^t \alpha_i} \cdot x_0 + \sum_{i=1}^t \text{噪声项}
> $$
>
> 通过定义：
>
> $$
> \bar{\alpha}_t = \prod_{i=1}^t \alpha_i
> $$
> 我们得到：
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 这里的 $\epsilon$ 是一系列高斯噪声线性组合后的结果。由于线性组合仍是高斯分布，它等价于一个新的标准正态随机变量。
>
> 
>
> **结论：**
>
> 最终我们推导出：
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 该公式允许我们跳过逐步采样过程，直接从 $x_0$ 构造出 $x_t$ 。这意味着我们**不需要一步一步模拟 $x_1 \to x_2 \to \dots \to x_t$ 的过程**，只需要用初始图像 $x_0$ 和随机噪声 $\epsilon$ 即可直接生成任意时间步的 $x_t$ 。
>
> 这一步是训练阶段的关键，它使得我们可以构造任意时间步的训练样本 $x_t$ 来训练一个模型预测 $\epsilon$ 。

因此，由公式：

$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
$$

可以看出，只要我们：

- 拥有初始图像或数据 \( x_0 \)；
- 知道固定的噪声调度表（即一组在区间 \( (0, 1) \) 内的预设值）：
  $$
  \{ \beta_t \}_{t=1}^T,\quad \alpha_t = 1 - \beta_t,\quad \bar{\alpha}_t = \prod_{i=1}^t \alpha_i
  $$
- 再从标准正态分布 $ \mathcal{N}(0, \mathbf{I}) $ 中采样一个噪声变量 $ \epsilon $；

就可以**直接计算出任意时间步 $ t $ 的加噪结果 $ x_t $**，而无需从 $ x_0 \to x_1 \to x_2 \to \dots \to x_t $ 一步步迭代。

这就是扩散模型中前向加噪过程的高效之处：虽然物理过程是马尔可夫链，但数值计算上我们可以跳步（skip steps），一步直接得出任意时刻的状态。



 **$β$ 序列与 $ᾱ$ 序列的单调性关系说明**

在扩散模型中，前向扩散过程采用高斯噪声不断扰动数据。在这一过程中，每一步的噪声强度由参数 $\beta_t$ 控制。

我们通常会选取一个单调递增的 $\beta_t$ 序列：

$$
0 < \beta_1 < \beta_2 < \cdots < \beta_T < 1
$$

- 这样设计的动机是：随着扩散步数 $t$ 的增大，图像中加入的噪声逐步增多，因此 $\beta_t$ 应该随时间增长，使得图像逐渐变为纯噪声。



我们定义：

$$
\alpha_t = 1 - \beta_t
$$

显然，$\alpha_t \in (0,1)$ 且也是单调递减的。

接着我们引入累积乘积项：

$$
\bar{\alpha}_t = \prod_{i=1}^t \alpha_i
$$

因为每个 $\alpha_i \in (0,1)$，所以 $\bar{\alpha}_t$ 会 随 $t$ 增大而逐渐减小：

$$
\bar{\alpha}_1 > \bar{\alpha}_2 > \cdots > \bar{\alpha}_T
$$


总结：

- $\beta_t$ 随时间增长，表示噪声比例增加；
- $\alpha_t = 1 - \beta_t$ 随时间减小；
- $\bar{\alpha}_t = \prod_{i=1}^t \alpha_i$ 也随时间单调减小。

这种设计保证了：
- 早期的图像保留更多原始信息；
- 后期的图像则接近完全高斯噪声。





#### 2.2.3 Reverse Diffusion逆向过程

**逆扩散过程近似模型 $p_θ$**

如果我们能将上述过程转换方向，即从 $q(x_{t−1}|x_t)$ 中采样，那么我们就可以从一个随机的高斯分布 $N(0,I)$ 中重建出一个真实的原始样本，也就是从一个完全杂乱无章的噪声图片中得到一张真实图片。

但是，由于需要从完整数据集中找到数据分布，我们没办法很简单地预测 $q(x_{t−1}|x_t)$ ，因此我们需要学习一个模型 $p_θ$ 来近似模拟这个条件概率，从而运行逆扩散过程。



如果我们能学习逆过程：

$$
q(x_{t-1} \mid x_t)
$$

那么我们就可以从完全的噪声 $x_T \sim \mathcal{N}(0, \mathbf{I})$ 开始，通过一系列“去噪”步骤，逐步重建出原始的图像 $x_0$。

------

前向过程 $q(x_t \mid x_{t-1})$ 是已知的高斯扰动；

逆向过程 $q(x_{t-1} \mid x_t)$ 难以直接求解；

我们用神经网络 $p_\theta(x_{t-1} \mid x_t)$ 来近似它，从而实现从噪声到真实图像的生成建模。
$$
p_\theta(\mathbf{x}_{0:T}) = p(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)
$$

> **解释：**
>
> - $\mathbf{x}_{0:T}$ 表示从原始图像 $\mathbf{x}_0$ 到最终噪声图像 $\mathbf{x}_T$ 的整个序列。
> - $p(\mathbf{x}_T)$ 是在最终扩散步骤 $T$ 时，图像的先验分布，通常设为标准高斯分布 $\mathcal{N}(0, \mathbf{I})$。
> - $p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$ 是神经网络学习得到的近似逆过程的条件概率，表示如何从 $\mathbf{x}_t$ 还原出 $\mathbf{x}_{t-1}$。
> - 整个逆过程由 $T$ 个步骤组成，每一步都是一个高斯采样过程。

$$
p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}\left( \mathbf{x}_{t-1}; \mu_\theta(\mathbf{x}_t, t), \Sigma_\theta(\mathbf{x}_t, t) \right)
$$

> **解释：**
>
> - 我们假设从 $\mathbf{x}_t$ 到 $\mathbf{x}_{t-1}$ 的条件概率是一个高斯分布。
> - $\mu_\theta(\mathbf{x}_t, t)$ 是模型输出的均值，表示从 $\mathbf{x}_t$ 预测出的最可能的前一步图像。
> - $\Sigma_\theta(\mathbf{x}_t, t)$ 是预测的协方差矩阵，通常简化为对角阵，甚至是固定值（比如 $\sigma_t^2 \mathbf{I}$），代表预测不确定性。
> - 通过训练模型来尽可能地让这个条件分布 $p_\theta$ 逼近真实的后验分布 $q(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$。



**后验扩散条件概率 $q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$**

在逆扩散过程中，如果我们给定了 $x_t$ 和 $x_0$ ,那么我们是可以计算出 $x_{t−1}$ 的，即后验扩散条件概率 $q(x_{t−1}|x_t,x_0)$ 是可以计算的。注意，这与直接用 $ q(x_{t-1} | x_t) $ 不同，因为我们无法在仅依赖于当前的噪声状态 $ x_t $ 就推断出 $q(x_{t−1}|x_t,x_0)$。



我们可以将后验扩散条件概率 $ q(x_{t-1} | x_t, x_0) $ 表达为以下的形式：
$$
q(x_{t-1} | x_t, x_0) = \mathcal{N}\left(x_{t-1} ; \tilde\mu_{t-1}(x_t, x_0), \tilde\beta_t \mathbf{I}\right)
$$

> **解释：**
>
> - $ q(x_{t-1} \mid x_t, x_0) $：表示在已知当前噪声状态 $ x_t $ 和原始图像 $ x_0 $ 的前提下，前一时刻状态 $ x_{t-1} $ 的**后验分布**。
> - 该分布是一个**高斯分布**，其：
>   - 均值为 $ \tilde\mu_{t-1}(x_t, x_0) $
>   - 协方差为 $ \tilde\beta_t \mathbf{I} $
>
> 这是一个**可解析的闭式解**，不需要模型学习，直接由前向过程的噪声调度参数推导而来
>
> 该高斯分布的均值和方差可以写作：
>
> $$
> \tilde\mu_{t-1}(x_t, x_0) = \frac{\sqrt{\bar\alpha_{t-1}} \beta_t}{1 - \bar\alpha_t} x_0 + \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t-1})}{1 - \bar\alpha_t} x_t
> $$
>
> $$
> \tilde\beta_t = \frac{1 - \bar\alpha_{t-1}}{1 - \bar\alpha_t} \beta_t
> $$
>
> 其中：
>
> - $ \alpha_t = 1 - \beta_t $
> - $ \bar\alpha_t = \prod_{s=1}^t \alpha_s $



使用贝叶斯公式可以得到：







#### 2.2.4 DDPM的训练











# 2. Flow Matching

























# 3. Diffusion VS Flow Matching

https://diffusionflow.github.io/#closing-takeaways
