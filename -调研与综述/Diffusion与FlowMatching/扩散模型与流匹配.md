# 1. Diffusion

DDPM解读（一）| 数学基础，扩散与逆扩散过程和训练推理方法 - 卡卡猡特的文章 - 知乎
https://zhuanlan.zhihu.com/p/530602852

## 2. DDPM

《Denoising Diffusion Probabilistic Models》[[2006.11239\] Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)

### 2.1 数学基础

#### 2.1.1 先验概率与后验概率

直观理解：

**先验概率 (Prior)**：在看到数据之前，你对某件事的**原本相信程度**。

**后验概率 (Posterior)**：在看到数据之后，你根据**数据更新后的相信程度**。

------

举个例子：

比如你丢一枚硬币，事先不知道是不是公平的。

- 你**先验地认为**，硬币正反面各 50%（也可能觉得偏某一边）。

后来你丢了 100 次，结果正面出来了 80 次，这个数据很不对劲。

- 根据数据，你**更新你的相信**，硬币可能是偏向正面的一枚。

这个从 "50%" 更新到 "更偏向正面" 的过程，就是：

> **先验 →（看见数据）→ 后验**

------

数学推导：

设

- 事件 $A$ 是我们关心的（比如，"硬币是偏的"）
- 数据 $B$ 是我们观察到的（比如，"丢了100次，正面出了80次"）

那么：
$$
\text{后验概率} = \frac{\text{似然} \times \text{先验概率}}{\text{证据}}
$$
公式写成：
$$
P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}
$$
其中：

- $P(A)$：**先验概率**，观察数据前对 $A$ 的主观相信
- $P(B|A)$：**似然（Likelihood）**，如果 $A$ 成立，数据 $B$ 出现的概率
- $P(B)$：**证据（Evidence）**，所有可能情况下数据 $B$ 出现的总体概率
- $P(A|B)$：**后验概率**，看过数据 $B$ 后，对 $A$ 的相信程度



| 名称       | 含义                                   |
| ---------- | -------------------------------------- |
| 先验概率   | 看到数据前的主观相信程度               |
| 似然函数   | 如果假设成立，观察到数据的可能性有多大 |
| 后验概率   | 看到数据后，新的相信程度               |
| 贝叶斯公式 | 后验 = 似然 × 先验 / 证据              |



#### 2.1.2 条件概率的一般形式

**定义**：
 如果你已经知道了事件 $B$ 发生，那么在这种条件下，事件 $A$ 发生的概率，叫做 **条件概率**。

数学上，记作：
$$
P(A|B)
$$
**公式是**：
$$
P(A|B) = \frac{P(A \cap B)}{P(B)}
\quad\quad \text{(前提是 } P(B) > 0\text{)}
$$

------

如果你有三个事件 $A$、$B$、$C$，那么：

1. **联合概率** $P(A, B, C)$ 表示
    → $A$、$B$、$C$ 三个**同时发生**的概率。
2. **条件概率的一般形式**可以写成：

$$
P(A, B, C) = P(A|B, C) \times P(B|C) \times P(C)
$$



也可以理解成：

> 联合概率可以被分解成一连串的条件概率相乘。



#### 2.1.3 马尔可夫链条件概率形式

> 马尔可夫链（**Markov Chain**）里，条件概率有个非常重要、特别简洁的形式。





















# 2. Flow Matching

























# 3. Diffusion VS Flow Matching

https://diffusionflow.github.io/#closing-takeaways
