# A. Diffusion



## 1. DDPM

DDPM解读（一）| 数学基础，扩散与逆扩散过程和训练推理方法 - 卡卡猡特的文章 - 知乎
https://zhuanlan.zhihu.com/p/530602852

《Denoising Diffusion Probabilistic Models》https://arxiv.org/abs/2006.11239

### 1.1 数学基础

#### 1.1.1 先验概率与后验概率

直观理解：

**先验概率 (Prior)**：在看到数据之前，你对某件事的**原本相信程度**。

**后验概率 (Posterior)**：在看到数据之后，你根据**数据更新后的相信程度**。

------

举个例子：

比如你丢一枚硬币，事先不知道是不是公平的。

- 你**先验地认为**，硬币正反面各 50%（也可能觉得偏某一边）。

后来你丢了 100 次，结果正面出来了 80 次，这个数据很不对劲。

- 根据数据，你**更新你的相信**，硬币可能是偏向正面的一枚。

这个从 "50%" 更新到 "更偏向正面" 的过程，就是：

> **先验 →（看见数据）→ 后验**

------

数学推导：

设

- 事件 $A$ 是我们关心的（比如，"硬币是偏的"）
- 数据 $B$ 是我们观察到的（比如，"丢了100次，正面出了80次"）

那么：
$$
\text{后验概率} = \frac{\text{似然} \times \text{先验概率}}{\text{证据}}
$$
公式写成：
$$
P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}
$$
其中：

- $P(A)$：**先验概率**，观察数据前对 $A$ 的主观相信
- $P(B|A)$：**似然（Likelihood）**，如果 $A$ 成立， $B$ 出现的可能性
- $P(B)$：**证据（Evidence）**，所有可能情况下数据 $B$ 出现的总体概率
- $P(A|B)$：**后验概率**，看过数据 $B$ 后，对 $A$ 的相信程度



| 名称       | 含义                                   |
| ---------- | -------------------------------------- |
| 先验概率   | 看到数据前的主观相信程度               |
| 似然       | 如果假设成立，观察到数据的可能性有多大 |
| 后验概率   | 看到数据后，新的相信程度               |
| 贝叶斯公式 | 后验 = 似然 × 先验 / 证据              |



> **似然函数和条件概率的区分**
>
> - 条件概率 是 “已知某个事件发生后，另一个事件发生的概率”；
>
> - 似然（Likelihood） 是 “在固定观察结果的情况下，不同参数值使这个结果发生的可能性有多大”。
>
> **似然函数是什么？**
>
> 似然看起来像概率，但语义不同。它是这样定义的：
> $$
> \mathcal{L}(θ∣x)=p_θ(x)
> $$
> 含义是：
>
> 已知数据 $x$，我们反过来看参数 $\theta$ 的“合理程度”有多大。
>
> - **概率**：固定参数，看数据出现的概率；
>
> - **似然**：固定数据，看哪个参数值更“合理”。
>
> 我们已知结果 $x$ ，但不知道参数 $\theta$ ，我们想通过这个结果估计 $\theta$ ，那么 $\mathcal{L}(θ∣x)$ 就是**似然函数**



#### 1.1.2 条件概率的一般形式

**定义**：
 如果你已经知道了事件 $B$ 发生，那么在这种条件下，事件 $A$ 发生的概率，叫做 **条件概率**。

数学上，记作：
$$
P(A|B)
$$
**公式是**：
$$
P(A|B) = \frac{P(A \cap B)}{P(B)}
\quad\quad \text{(前提是 } P(B) > 0\text{)}
$$

------

如果你有三个事件 $A$、$B$、$C$，那么：

1. **联合概率** $P(A, B, C)$ 表示
    → $A$、$B$、$C$ 三个**同时发生**的概率。
2. **条件概率的一般形式**可以写成：

$$
P(A, B, C) = P(A|B, C) \times P(B|C) \times P(C)
$$



也可以理解成：

> 联合概率可以被分解成一连串的条件概率相乘。



#### 1.1.3 马尔可夫链条件概率形式

> 马尔可夫链（**Markov Chain**）里，条件概率有个非常重要、特别简洁的形式。
> $$
> P(Xn+1∣Xn,Xn−1,…,X1)=P(Xn+1∣Xn)
> $$

马尔科夫链指当前状态的概率只与上一时刻有关，例如如满足马尔可夫关系 A→B→C ，ABC符合马尔可夫性质，那么我们可以用链式法则展开联合概 $P(A, B, C)$ :
$$
P(A,B,C)=P(A)⋅P(B∣A)⋅P(C∣B)
$$

> 马尔可夫链指当前状态的概率只与上一时刻有关，例如 $A \rightarrow B \rightarrow C$，那么有：
> $$
> P(C∣B,A)=P(C∣B)
> $$
> 马尔可夫性质。



#### 1.1.4 高斯分布的KL散度公式

设有两个一维高斯分布：

- $ p(x) = \mathcal{N}(\mu_p, \sigma_p^2) $

- $ q(x) = \mathcal{N}(\mu_q, \sigma_q^2) $

则 KL 散度 $ D_{\text{KL}}(p \,\|\, q) $ 的计算公式为：

$$
D_{\text{KL}}(p \,\|\, q) = \log\left( \frac{\sigma_q}{\sigma_p} \right) + \frac{\sigma_p^2 + (\mu_p - \mu_q)^2}{2\sigma_q^2} - \frac{1}{2}
$$
参数解释：

> 1. **第一项：**  $\log\left( \frac{\sigma_q}{\sigma_p} \right)$
>
>    反映两个分布在方差上的差异。
>
> 2. **第二项：**  $\frac{\sigma_p^2 + (\mu_p - \mu_q)^2}{2\sigma_q^2}$
>
>    包含：
>
>    - $\frac{\sigma_p^2}{2\sigma_q^2}$：分布宽度差异；
>    - $\frac{(\mu_p - \mu_q)^2}{2\sigma_q^2}$：均值之间的差异。
>
> 3. **第三项：**  $- \frac{1}{2}$
>
>    归一化常数，使散度为零时，代表两个分布完全相同。

特殊情况（均值相同）：

若 $mu_p = \mu_q$，KL 散度简化为：

$$
D_{\text{KL}}(p \,\|\, q) = \log\left( \frac{\sigma_q}{\sigma_p} \right) + \frac{\sigma_p^2}{2\sigma_q^2} - \frac{1}{2}
$$
注：

- KL 散度 $ D_{\text{KL}}(p \,\|\, q) \geq 0 $，当且仅当 $ p = q $ 时取到 0；

- KL 散度是非对称的：
  $$
  D_{\text{KL}}(p \,\|\, q) \neq D_{\text{KL}}(q \,\|\, p)
  $$



#### 1.1.5 参数重整化（重参数技巧）

我们希望从一个高斯分布中采样：
$$
x \sim \mathcal{N}(\mu, \sigma^2)
$$
但由于采样操作不可导，无法直接用于反向传播。为了解决这个问题，我们使用重参数化技巧，将随机性转移到一个独立于模型参数的随机变量中。



**重参数化形式**

我们引入标准正态变量：
$$
z \sim \mathcal{N}(0, 1)
$$
然后构造采样变量：
$$
x = \mu + \sigma \cdot z
$$
这样，$ x $ 的分布为：
$$
x \sim \mathcal{N}(\mu, \sigma^2)
$$


这么做的好处：
- 将不可导的采样操作转化为可导的仿射变换；
- 使得模型在训练过程中可以使用反向传播更新 $ \mu $ 和 $ \sigma $；
- 是变分推断中训练 VAE（Variational Autoencoder）的关键技术。



**注意事项**

- 为保证正值，通常使用 $\log \sigma^2$ 表示，训练过程中实际预测的是 $\log \sigma^2$，然后用 $\exp(\frac{1}{2} \log \sigma^2)$ 计算 $\sigma$；

- 重参数化技巧仅适用于可以重参数化的分布（如高斯分布），对于离散分布则较为困难。





### 1.2 DDPM模型

#### 1.2.1 模型总览

DDPM，全称 **Denoising Diffusion Probabilistic Model**，是一种基于**马尔可夫链的生成模型**。

![img](./asset/v2-c77c080d146c4e9d9edf17e264ebdb98_r.jpg)



DDPM模型主要分为两个过程：forward加噪过程（从右往左）和reverse去噪过程（从左往右）。

模型通过逐步添加噪声和反向去噪学习数据分布。



#### 1.2.2 Diffusion前向过程

**逐步加噪过程**

给定初始数据分布 $q(x_0)$（例如图像分布），我们定义一个前向扩散过程，在这个过程中逐步向数据中添加高斯噪声，使得原始数据在 $T$ 步之后几乎退化成各向同性高斯分布。

在这个持续 $T$ 次的加噪过程中，我们会产生一系列带噪声的图片 $x_1, ..., x_T$ 。在这个过程中，噪声的标准差/方差是以一个在区间 (0,1) 内的固定值 $β_T$ 来确定的，均值是以固定值 $β_T$ 和当前时刻的图片数据 $x_{t−1}$ 来确定的。



**加噪过程定义**

对于 $t = 1, 2, ..., T$，我们定义马尔可夫过程：

$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
$$
其中：

- $\beta_t \in (0, 1)$ 是一个预设的固定方差调度表（称为 noise schedule），通常线性或余弦方式递增；
- $\sqrt{1 - \beta_t}$ 是该步的缩放因子。



> **加噪过程的另一种表示**
>
> 每一步的加噪过程如下：
>
> $$
> q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
> $$
>
> $$
> \bar{\alpha}_t = \prod_{i=1}^T (1 - \alpha_i)
> $$
>
> $$
> \alpha_t = 1- \beta_t
> $$
>
> 
>
> - 这是一个高斯分布，其 **均值** 为 $\sqrt{\bar{\alpha}_t} x_0$，**方差** 为 $1 - \bar{\alpha}_t$；
> - 其中 $\bar{\alpha}_t = \prod_{i=1}^T (1 - \alpha_i)$ 是噪声衰减因子；
> - 因为 $\beta_t$ 是预定义的 schedule，所以 $\bar{\alpha}_t$ 也是固定的；
> - 因此，这个分布完全由 $x_0$ 和 $t$ 决定 —— 无需学习，**不是模型的一部分**。



**加噪结果**

随着 $t$ 的不断增大，最终原始数据 $x_0$ 会逐步失去它的特征。最终当 $T→∞$ 时， $x_T$ 趋近于一个各向独立的高斯分布。从视觉上来看，就是将原本一张完好的照片加噪很多步后，图片几乎变成了一张完全是噪声的图片。



**任意时刻数据 $X_t$ 的计算（参数重整化技巧）**

在前向扩散过程中，虽然 $x_t$ 是通过从 $x_{t-1}$ 不断加噪得到的，但我们其实可以跳过中间所有步骤，直接从 $x_0$ 和固定值序列 $\{β_T∈(0,1)\}_{t=1}^T $ 计算得到任意时刻 $x_t$ 

我们首先定义:
$$
\alpha_t = 1 - \beta_t
$$

$$
\bar{\alpha}_t = \prod_{i=1}^t \alpha_i = \prod_{i=1}^t (1 - \beta_i)
$$

我们可以直接通过下式采样得到某一时刻 $t$ 的带噪图像 $x_t$：
$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
$$
推导步骤：

> 我们希望从以下马尔可夫链定义的前向过程：
>
> $$
> q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{\alpha_t} x_{t-1}, (1 - \alpha_t) \mathbf{I})
> $$
>
> 推导出：
>
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 其中：
>
> - $\bar{\alpha}_t = \prod_{i=1}^t \alpha_i$
>
> 
>
> **推导过程**
>
> 首先，从一步扩散定义：
> $$
> x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1 - \alpha_t} \epsilon_t,\quad \epsilon_t \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 这表示 $x_t$ 是上一步 $x_{t-1}$ 的缩放加上独立高斯噪声的结果。
>
> 展开两步（将 $x_{t-1}$ 用 $x_{t-2}$ 表示）：
> $$
> x_{t-1} = \sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-1}
> $$
>
> 代入 $x_t$ 的公式中得到：
>
> $$
> x_t = \sqrt{\alpha_t} \left( \sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-1} \right) + \sqrt{1 - \alpha_t} \epsilon_t
> $$
>
> 继续展开并整理：
>
> $$
> x_t = \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1-\alpha_t \alpha_{t-1}} \bar\epsilon_{t-2}，\quad(*)
> $$
>
> 你可以看到，每次展开我们都得到一个 $x_0$ 的缩放加上一系列噪声项的线性组合。
>
> 
>
> > **关键技巧** $(*)$ :
> >
> > 这里使用了一个关键技巧，在 Diffusion 模型中常用于将**多步高斯噪声组合**成**一步标准高斯噪声**的形式，也叫**参数重整化**。
> >
> > 当我们合并两个均值都为 0，方差分别为 $\sigma_1^2$ 和 $\sigma_2^2$ 的高斯分布 $\mathcal{N}(0, \sigma_1^2 I)$ 和 $\mathcal{N}(0, \sigma_2^2 I)$ 时，我们得到的新的高斯分布为：
> > $$
> > \sqrt{\alpha_t - \alpha_t \alpha_{t-1}} z_{t-2} + \sqrt{1 - \alpha_t} z_{t-1}
> > $$
> > 因此可以通过参数重整化，变成只含一个随机变量 $z$ 构成的：
> > $$
> > \sqrt{1 - \bar{\alpha}_t} \cdot \bar{z}_t
> > $$
> > 的形式。
> >
> > 
> >
> > 这里使用了高斯变量的加法性质，假设我们有：
> > $$
> > z=aϵ_1+bϵ_2, \quad ϵ_1,ϵ_2∼N(0,I),独立
> > $$
> > 那么我们可以把它写成：
> > $$
> > z= \sqrt{a_2+b_2}⋅ϵ, \quad ϵ∼N(0,I)
> > $$
>
> 
>
> 继续递推 $t$ 次，可以得到一个形式：
>
> 继续这样递推下去 $t$ 次，可以得到一个形式：
>
> $$
> x_t = \sqrt{\prod_{i=1}^t \alpha_i} \cdot x_0 + \sum_{i=1}^t \text{噪声项}
> $$
>
> 通过定义：
>
> $$
> \bar{\alpha}_t = \prod_{i=1}^t \alpha_i
> $$
> 我们得到：
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 这里的 $\epsilon$ 是一系列高斯噪声线性组合后的结果。由于线性组合仍是高斯分布，它等价于一个新的标准正态随机变量。
>
> 
>
> **结论：**
>
> 最终我们推导出：
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 该公式允许我们跳过逐步采样过程，直接从 $x_0$ 构造出 $x_t$ 。这意味着我们**不需要一步一步模拟 $x_1 \to x_2 \to \dots \to x_t$ 的过程**，只需要用初始图像 $x_0$ 和随机噪声 $\epsilon$ 即可直接生成任意时间步的 $x_t$ 。
>
> 这一步是训练阶段的关键，它使得我们可以构造任意时间步的训练样本 $x_t$ 来训练一个模型预测 $\epsilon$ 。

因此，由公式：

$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
$$

可以看出，只要我们：

- 拥有初始图像或数据 \( x_0 \)；
- 知道固定的噪声调度表（即一组在区间 \( (0, 1) \) 内的预设值）：
  $$
  \{ \beta_t \}_{t=1}^T,\quad \alpha_t = 1 - \beta_t,\quad \bar{\alpha}_t = \prod_{i=1}^t \alpha_i
  $$
- 再从标准正态分布 $ \mathcal{N}(0, \mathbf{I}) $ 中采样一个噪声变量 $ \epsilon $；

就可以**直接计算出任意时间步 $ t $ 的加噪结果 $ x_t $**，而无需从 $ x_0 \to x_1 \to x_2 \to \dots \to x_t $ 一步步迭代。

这就是扩散模型中前向加噪过程的高效之处：虽然物理过程是马尔可夫链，但数值计算上我们可以跳步（skip steps），一步直接得出任意时刻的状态。



 **$β$ 序列与 $ᾱ$ 序列的单调性关系说明**

在扩散模型中，前向扩散过程采用高斯噪声不断扰动数据。在这一过程中，每一步的噪声强度由参数 $\beta_t$ 控制。

我们通常会选取一个单调递增的 $\beta_t$ 序列：

$$
0 < \beta_1 < \beta_2 < \cdots < \beta_T < 1
$$

- 这样设计的动机是：随着扩散步数 $t$ 的增大，图像中加入的噪声逐步增多，因此 $\beta_t$ 应该随时间增长，使得图像逐渐变为纯噪声。



我们定义：

$$
\alpha_t = 1 - \beta_t
$$

显然，$\alpha_t \in (0,1)$ 且也是单调递减的。

接着我们引入累积乘积项：

$$
\bar{\alpha}_t = \prod_{i=1}^t \alpha_i
$$

因为每个 $\alpha_i \in (0,1)$，所以 $\bar{\alpha}_t$ 会 随 $t$ 增大而逐渐减小：

$$
\bar{\alpha}_1 > \bar{\alpha}_2 > \cdots > \bar{\alpha}_T
$$


总结：

- $\beta_t$ 随时间增长，表示噪声比例增加；
- $\alpha_t = 1 - \beta_t$ 随时间减小；
- $\bar{\alpha}_t = \prod_{i=1}^t \alpha_i$ 也随时间单调减小。

这种设计保证了：
- 早期的图像保留更多原始信息；
- 后期的图像则接近完全高斯噪声。





#### 1.2.3 Reverse Diffusion逆向过程

##### a. 逆扩散过程近似模型 $p_θ$

如果我们能将上述过程转换方向，即从 $q(x_{t−1}|x_t)$ 中采样，那么我们就可以从一个随机的高斯分布 $N(0,I)$ 中重建出一个真实的原始样本，也就是从一个完全杂乱无章的噪声图片中得到一张真实图片。

但是，由于需要从完整数据集中找到数据分布，我们没办法很简单地预测 $q(x_{t−1}|x_t)$ ，因此我们需要学习一个模型 $p_θ$ 来近似模拟这个条件概率，从而运行逆扩散过程。



如果我们能学习逆过程：

$$
q(x_{t-1} \mid x_t)
$$

那么我们就可以从完全的噪声 $x_T \sim \mathcal{N}(0, \mathbf{I})$ 开始，通过一系列“去噪”步骤，逐步重建出原始的图像 $x_0$。

------

前向过程 $q(x_t \mid x_{t-1})$ 是已知的高斯扰动；

逆向过程 $q(x_{t-1} \mid x_t)$ 难以直接求解；

我们用神经网络 $p_\theta(x_{t-1} \mid x_t)$ 来近似它，从而实现从噪声到真实图像的生成建模。
$$
p_\theta(\mathbf{x}_{0:T}) = p(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)
$$

> **解释：**
>
> - $\mathbf{x}_{0:T}$ 表示从原始图像 $\mathbf{x}_0$ 到最终噪声图像 $\mathbf{x}_T$ 的整个序列。
> - $p(\mathbf{x}_T)$ 是在最终扩散步骤 $T$ 时，图像的先验分布，通常设为标准高斯分布 $\mathcal{N}(0, \mathbf{I})$。
> - $p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$ 是神经网络学习得到的近似逆过程的条件概率，表示如何从 $\mathbf{x}_t$ 还原出 $\mathbf{x}_{t-1}$。
> - 整个逆过程由 $T$ 个步骤组成，每一步都是一个高斯采样过程。

$$
p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}\left( \mathbf{x}_{t-1}; \mu_\theta(\mathbf{x}_t, t), \Sigma_\theta(\mathbf{x}_t, t) \right)
$$

> **解释：**
>
> - 我们假设从 $\mathbf{x}_t$ 到 $\mathbf{x}_{t-1}$ 的条件概率是一个高斯分布。
> - $\mu_\theta(\mathbf{x}_t, t)$ 是模型输出的均值，表示从 $\mathbf{x}_t$ 预测出的最可能的前一步图像。
> - $\Sigma_\theta(\mathbf{x}_t, t)$ 是预测的协方差矩阵，通常简化为对角阵，甚至是固定值（比如 $\sigma_t^2 \mathbf{I}$），代表预测不确定性。
> - 通过训练模型来尽可能地让这个条件分布 $p_\theta$ 逼近真实的后验分布 $q(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$。



##### b. 后验扩散条件概率 $q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$

在逆扩散过程中，如果我们给定了 $x_t$ 和 $x_0$ ,那么我们是可以计算出 $x_{t−1}$ 的，即后验扩散条件概率 $q(x_{t−1}|x_t,x_0)$ 是可以计算的。注意，这与直接用 $ q(x_{t-1} | x_t) $ 不同，因为我们无法在仅依赖于当前的噪声状态 $ x_t $ 就推断出 $q(x_{t−1}|x_t,x_0)$。



我们可以将后验扩散条件概率 $ q(x_{t-1} | x_t, x_0) $ 表达为以下的形式：
$$
q(x_{t-1} | x_t, x_0) = \mathcal{N}\left(x_{t-1} ; \tilde\mu_{t-1}(x_t, x_0), \tilde\beta_t \mathbf{I}\right)
$$

> **解释：**
>
> - $ q(x_{t-1} \mid x_t, x_0) $：表示在已知当前噪声状态 $ x_t $ 和原始图像 $ x_0 $ 的前提下，前一时刻状态 $ x_{t-1} $ 的**后验分布**。
> - 该分布是一个**高斯分布**，其：
>   - 均值为 $ \tilde\mu_{t-1}(x_t, x_0) $
>   - 协方差为 $ \tilde\beta_t \mathbf{I} $
>
> 这是一个**可解析的闭式解**，不需要模型学习，直接由前向过程的噪声调度参数推导而来
>
> 该高斯分布的均值和方差可以写作：
>
> $$
> \tilde\mu_{t-1}(x_t, x_0) = \frac{\sqrt{\bar\alpha_{t-1}} \beta_t}{1 - \bar\alpha_t} x_0 + \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t-1})}{1 - \bar\alpha_t} x_t
> $$
>
> $$
> \tilde\beta_t = \frac{1 - \bar\alpha_{t-1}}{1 - \bar\alpha_t} \beta_t
> $$
>
> 其中：
>
> - $ \alpha_t = 1 - \beta_t $
> - $ \bar\alpha_t = \prod_{s=1}^t \alpha_s $



使用贝叶斯公式可以得到：

在扩散模型中，已知当前状态 $ x_t $ 和原始图像 $ x_0 $，我们可以使用贝叶斯公式来推导出后验分布：

$$
q(x_{t-1} \mid x_t, x_0) = q(x_t \mid x_{t-1}) \cdot \frac{ q(x_{t-1} \mid x_0)}{q(x_t \mid x_0)}
$$

> 注意：上式在马尔可夫扩散模型中 $x_t$ **只依赖** $x_{t-1}$，与 $x_0$ 条件独立（因为前向过程是马尔可夫链）；
>
> 所以 $q(x_t \mid x_{t-1}, x_0) = q(x_t \mid x_{t-1})$



其中每一项都是一个高斯分布：

- $q(x_t \mid x_{t-1}) $：前向过程的一步高斯扰动：
  $$
  q(x_t \mid x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t \mathbf{I})
  $$

- $ q(x_{t-1} \mid x_0) $：前向过程的马尔可夫链的一部分，可以从 $ x_0 $ 直接采样出任意中间状态：
  $$
  q(x_{t-1} \mid x_0) = \mathcal{N}(x_{t-1}; \sqrt{\bar\alpha_{t-1}} x_0, (1 - \bar\alpha_{t-1}) \mathbf{I})
  $$

- $ q(x_t \mid x_0) $：类似地，可以从 $ x_0 $ 直接得到：
  $$
  q(x_t \mid x_0) = \mathcal{N}(x_t; \sqrt{\bar\alpha_t} x_0, (1 - \bar\alpha_t) \mathbf{I})
  $$

> 现在我们要计算：
> $$
> q(x_{t-1} \mid x_t, x_0) = q(x_t \mid x_{t-1}) \cdot \frac{ q(x_{t-1} \mid x_0)}{q(x_t \mid x_0)}
> $$
> 每一个高斯分布都可以写成如下形式：
> $$
> \mathcal{N}(x; \mu, \sigma^2 \mathbf{I}) = \frac{1}{Z} \exp\left(-\frac{1}{2\sigma^2} \|x - \mu\|^2\right)
> $$

我们将上面三个项都写成指数形式（写出三个项的负指数项，忽略常数）：

其中第一项 **$q(x_t \mid x_{t-1})$**:
$$
\exp\left( -\frac{1}{2\beta_t} \|x_t - \alpha_t x_{t-1} \|^2 \right)
$$
其中第二项 **$q(x_{t-1} \mid x_0)$**:

$$
\exp\left( -\frac{1}{2(1 - \bar{\alpha}_{t-1})} \|x_{t-1} - \bar{\alpha}_{t-1} x_0 \|^2 \right)
$$
其中第三项 **$q(x_t \mid x_0)$** （这是分母，带负号）:

$$
\exp\left( +\frac{1}{2(1 - \bar{\alpha}_t)} \|x_t - \bar{\alpha}_t x_0 \|^2 \right)
$$
现在，我们的目标是得到关于 $x_{t-1}$ 的分布，只有第1项和第2项中出现了 $x_{t-1}$ （第三项在后续推导中不会显示写出来，它是归一化常数，不影响高斯的形式）。根据贝叶斯规则（可看作条件高斯分布的推导）：
$$
q(x_{t-1} \mid x_t, x_0) \propto q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0)
$$


> 其中我们把右边的乘积 $q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0)$ 被当成一个**未归一化的概率密度函数**，然后通过归一化使其总和为1，这样就变成了一个合法的概率分布。
> 
>
> > **为什么 $q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0)$ 被当成一个未归一化的概率密度函数？**
> >
> > 它是两个高斯密度函数的乘积，关于 $x_{t-1}$ 的函数。
> >
> > - 这个乘积不一定积分为1（可能大于或小于1），所以它不是合法概率密度函数（缺少归一化）；
> > - 但它的函数形式依然是一个**关于 $x_{t-1}$ 的高斯函数的形式（未归一化）**；
> > - 为了让它成为合法的概率密度函数，我们除以归一化常数 $q(x_t \mid x_0)$，让积分变成1
> >
> > (乘积给了我们**后验的“形状”**，归一化常数保证它是个真正的概率分布)
>
> 
>
> 而归一化的常数正好就是 $q(x_t \mid x_0)$，即：
> $$
> q(x_t ∣x_0)=∫q(x_t∣x_{t−1})⋅q(x_{t−1}∣x_0)dx_{t−1}
> $$
> 所以：
> $$
> q(x_{t-1} \mid x_t, x_0) = \frac{
>     q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0)
> }{
>     q(x_t \mid x_0)
> }
> = \frac{
>     q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0)
> }{
>     \int q(x_t \mid x_{t-1}) \cdot q(x_{t-1} \mid x_0) \, dx_{t-1}
> }
> = \text{归一化的乘积}
> $$
> 
>
> > **为什么 $q(x_t \mid x_0)$ 是归一化常数？**
> >
> > 上式分母：
> >
> > $$
> > q(x_t \mid x_0) = \int q(x_t \mid x_{t-1}) \, q(x_{t-1} \mid x_0) \, dx_{t-1}
> > $$
> >
> > 是对所有可能的 $ x_{t-1} $ 积分得到的，保证右边的分布对 $ x_{t-1} $ 归一化（即积分为1）。
> >
> > 换句话说，分母是一个 **标量值**，不依赖于 $ x_{t-1} $，它负责保证分子所定义的函数（关于 $ x_{t-1} $）是个合法的概率密度函数。
>
> 
>
> 而当我们推导具体形式（比如均值和方差）时：
>
> 由于高斯的乘积结果形式 **不依赖归一化常数**，我们就只计算了：
> $$
> 一个关于 x_{t−1} 的未归一化高斯密度函数 ∝ exp(−Q(x_{t−1}))
> $$
> 
>
> > **为什么归一化常数不影响高斯形式？**
> >
> > 高斯分布的概率密度函数形式是：
> >
> > $$
> > \mathcal{N}(x; \mu, \Sigma) = \frac{1}{(2\pi)^{d/2} |\Sigma|^{1/2}} \exp\left( -\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu) \right)
> > $$
> >
> > - 归一化常数是开头的那部分（包含 $ (2\pi)^d $ 和 $ |\Sigma| $）；
> > - 指数部分控制了高斯的“形状”，即均值 $ \mu $ 和协方差矩阵 $ \Sigma $；
> >
> > ---
> >
> > 在推导后验时，我们先只关注**指数部分**，把它写成关于 $ x_{t-1} $ 的二次函数，然后通过配方（完成平方）得到新的均值和协方差矩阵。
> >
> > 归一化常数只是调整整体的“高度”，不会改变这个指数的结构，因而不会影响“是哪个均值、哪个方差的高斯”。
>
> 
>
> 并直接得到结果是一个新的高斯分布。
>
> 所以我们只用乘积那两项就可以**正确恢复一个高斯分布的形式**，而**第三项只是归一化常数，可以省略不写**。


我们带入第1项和第2项两个高斯分布后，得到：
$$
q(x_{t-1} \mid x_t, x_0) \propto 
\exp\left(
- \frac{1}{2\beta_t} \left\| x_t - \sqrt{\alpha_t} x_{t-1} \right\|^2
\right)
\cdot
\exp\left(
- \frac{1}{2(1 - \bar{\alpha}_{t-1})} \left\| x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_0 \right\|^2
\right)
$$
合并两个指数项：
$$
q(x_{t-1} \mid x_t, x_0) \propto 
\exp\left(
- \frac{1}{2\beta_t} \left\| x_t - \sqrt{\alpha_t} x_{t-1} \right\|^2
- \frac{1}{2(1 - \bar{\alpha}_{t-1})} \left\| x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_0 \right\|^2
\right)
$$
这是一个关于 $x_{t-1}$ 的二次函数指数项，所以它仍然是一个**高斯分布**！
现在我们将其合并成一个高斯（两高斯乘法）：

> 高斯乘积公式：
>
> - 协方差：
> $$
> \tilde{\Sigma} = \left( \Sigma_1^{-1} + \Sigma_2^{-1} \right)^{-1}
> $$
>
> - 均值：
>
> $$
> \tilde{\mu} = \tilde{\Sigma} \left( \Sigma_1^{-1} \mu_1 + \Sigma_2^{-1} \mu_2 \right)
> $$
>

那么两个高斯分布，记：

- $Σ_1=β_tI$, $\mu_1 = \frac{x_t}{\sqrt{\alpha_t}}$

- $Σ_2=(1−αˉ_{t−1})I$, $\mu_2 = \sqrt{\bar\alpha_{t-1}} x_0$

根据高斯分布乘法的协方差推导公式，我们可以得到：

$$
\tilde{\beta}_t 
= \left( \frac{1}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}} \right)^{-1}
= \frac{(1 - \bar{\alpha}_{t-1}) \beta_t}{(1 - \bar{\alpha}_{t-1}) + \beta_t}
\approx \frac{(1 - \bar{\alpha}_{t-1}) \beta_t}{1 - \bar{\alpha}_t}
$$

> 其中近似是因为：
>
> $$
> \bar{\alpha}_t = \alpha_t \cdot \bar{\alpha}_{t-1}
> \Rightarrow 1 - \bar{\alpha}_t = 1 - \alpha_t \bar{\alpha}_{t-1} \approx 1 - \bar{\alpha}_{t-1} + \beta_t
> $$
>
> 则：
>
> $$
> \frac{(1 - \bar{\alpha}_{t-1}) \beta_t}{(1 - \bar{\alpha}_{t-1}) + \beta_t}
> \approx \frac{(1 - \bar{\alpha}_{t-1}) \beta_t}{1 - \bar{\alpha}_t}
> $$



因此，最终我们可以推导得到：
$$
q(x_{t-1} \mid x_t, x_0) = \mathcal{N}\left(x_{t-1}; \tilde\mu_{t}(x_t, x_0), \tilde\beta_t \mathbf{I} \right)
$$

$$
\tilde\mu_{t}(x_t, x_0) = \frac{\sqrt{\bar\alpha_{t-1}} \beta_t}{1 - \bar\alpha_t} x_0 + \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t-1})}{1 - \bar\alpha_t} x_t
$$

$$
\tilde\beta_t = \frac{1 - \bar\alpha_{t-1}}{1 - \bar\alpha_t} \beta_t
$$



> 其中：
>
> - 均值 $ \tilde\mu_{t}(x_t, x_0) $
>
> - 方差 $\tilde\beta_t$
>
>
> 该公式说明：
>
> - 后验分布 $ q(x_{t-1} \mid x_t, x_0) $ 是一个已知参数的高斯分布；
> - 可由贝叶斯公式结合前向过程的联合概率推导得到；
> - 是训练过程中用于监督模型预测的核心工具。

由前面Forward前向过程我们推导得到的 $x_0$ 和 $x_t$ 的关系，我们有：
$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
$$

$$
x_0 = \frac{1}{ \sqrt{\bar{\alpha}_t} }(x_t - \sqrt{1-\bar{\alpha}_t}) \, \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
$$

由上式后验均值：
$$
\tilde\mu_{t}(x_t, x_0) = \frac{\sqrt{\bar\alpha_{t-1}} \beta_t}{1 - \bar\alpha_t} x_0 + \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t-1})}{1 - \bar\alpha_t} x_t
$$
代入 $x_0$ 得到：
$$
\tilde\mu_{t}(x_t, \epsilon) = \frac{\sqrt{\bar\alpha_{t-1}} \beta_t}{1 - \bar\alpha_t} \cdot \frac{1}{\sqrt{\bar{\alpha}_t}} \left(x_t - \sqrt{1-\bar{\alpha}_t} \epsilon \right) + \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t-1})}{1 - \bar\alpha_t} x_t
$$
合并得到：
$$
\tilde{\mu}_{t}(x_t, \epsilon) =\left( \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{(1 - \bar{\alpha}_t) \sqrt{\bar{\alpha}_t}} + \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \right) x_t 
 - \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \sqrt{1 - \bar{\alpha}_t}}{(1 - \bar{\alpha}_t) \sqrt{\bar{\alpha}_t}} \epsilon
$$

> 上式推导 $\tilde{\mu}_t(x_t, \epsilon)$ 的简洁形式
>
> 将 $\sqrt{\alpha_t} = \dfrac{\sqrt{\bar{\alpha}_t}}{\sqrt{\bar{\alpha}_{t-1}}}$ 代入第二项：
> $$
> = \left( \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}} + \frac{ \frac{\sqrt{\bar{\alpha}_t}}{\sqrt{\bar{\alpha}_{t-1}}}(1 - \bar{\alpha}_{t-1}) }{1 - \bar{\alpha}_t} \right) x_t 
> - \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \sqrt{1 - \bar{\alpha}_t}}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}} \epsilon
> $$
> 通分并合并 $x_t$ 系数项，得到：
> $$
> = \left(
> \frac{ \beta_t \bar{\alpha}_{t-1} + \bar{\alpha}_t(1 - \bar{\alpha}_{t-1}) }{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}\sqrt{\bar{\alpha}_{t-1}}}
> \right) x_t
> - \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \sqrt{1 - \bar{\alpha}_t}}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}} \epsilon
> $$
> 注意 $\bar{\alpha}_t = \bar{\alpha}_{t-1}(1 - \beta_t)$，因此：
> $$
> \beta_t \bar{\alpha}_{t-1} + \bar{\alpha}_t(1 - \bar{\alpha}_{t-1})
> = \bar{\alpha}_{t-1} \beta_t + \bar{\alpha}_{t-1}(1 - \beta_t)(1 - \bar{\alpha}_{t-1})
> $$
> 展开化简得：
> $$
> = \bar{\alpha}_{t-1} - \bar{\alpha}_t
> $$
> 代入回去：
> $$
> \tilde{\mu}_t(x_t, \epsilon)
> = \frac{\bar{\alpha}_{t-1} - \bar{\alpha}_t}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}\sqrt{\bar{\alpha}_{t-1}}} x_t 
> - \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \sqrt{1 - \bar{\alpha}_t}}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}} \epsilon
> $$
> 又因为：
> $$
> \bar{\alpha}_{t-1} - \bar{\alpha}_t = \bar{\alpha}_{t-1} \beta_t
> $$
> 因此：
> $$
> \tilde{\mu}_t(x_t, \epsilon)
> = \frac{ \sqrt{\bar{\alpha}_{t-1}} \beta_t }{ (1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t} } x_t 
> - \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t \sqrt{1 - \bar{\alpha}_t}}{(1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t}} \epsilon
> $$
> 提取公共因子：
> $$
> = \frac{ \sqrt{\bar{\alpha}_{t-1}} \beta_t }{ (1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t} }
> \left( x_t - \sqrt{1 - \bar{\alpha}_t} \epsilon \right)
> $$
> 注意：
> $$
> \frac{ \sqrt{\bar{\alpha}_{t-1}} \beta_t }{ (1 - \bar{\alpha}_t)\sqrt{\bar{\alpha}_t} } = \frac{1}{\sqrt{\bar{\alpha}_t}}
> $$
> 最终可得：
> $$
> \boxed{
> \tilde{\mu}_t(x_t, \epsilon) = \frac{1}{\sqrt{\bar{\alpha}_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon \right)
> }
> $$

由上式子可最终推导为：
$$
\tilde\mu_{t} = 

\frac{1}{ \sqrt{\bar{\alpha}_t} }(x_t -\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon)
$$


##### c. 目标数据分布的似然函数

假设数据的真实分布为 $ q(x_0) $，模型的联合分布为 $ p_\theta(x_{0:T}) $，其中 $ x_0 $ 是观测数据，$ x_{1:T} $ 是潜变量（如扩散模型中的中间状态）。

这里与VAE很类似，我们可以使用VAE中推导变分下界（Variational Lower Bound, 简称 ELBO）的方式来优化负对数似然函数。

> 变分下界，本质是**一个对难以直接优化的目标函数的下界逼近，用于可行的训练和优化**。
>
> **直观理解**
>
> 很多生成模型的目标是最大化对观测数据 $x$ 的对数似然：
> $$
> \log p_θ(x)
> $$
> 但这个量通常涉及对高维潜变量 $z$（或 $x_{1:T}$）的积分，计算上是不可解的。
>
> 所以我们引入一个 **近似分布 $q(z|x)$**，用它来辅助估计 $\log p_\theta(x)$。
>
> 这时，就可以推导出下面这个著名的不等式：
> $$
> \log p_\theta(x) \geq \mathbb{E}_{q(z|x)} \left[ \log \frac{p_\theta(x, z)}{q(z|x)} \right] \triangleq \mathcal{L}_{\text{VLB}}(x)
> $$
> 这右边的量，就是所谓的 **变分下界（VLB）**，也称为 **ELBO（Evidence Lower Bound）**。
>
> > **为什么叫“下界”？**
> >
> > 因为它是对 $\log p_\theta(x)$ 的一个下界估计：
> >
> > - $\log p_θ(x)$ 是我们想最大化的目标；
> > - 但我们优化不了它（积分太复杂）；
> > - 所以退而求其次，最大化一个它的下界（VLB）；
> > - 最大化 VLB 会间接推动 $\log p_\theta(x)$ 的增大。
>
> 

在这里，我们也看到了一种将难以直接优化的负对数似然 $-\log p_θ(x_0)$ 转化为更容易优化的下界 $𝓛_{VLB}$ 的技巧。

> **为什么是 负对数似然（Negative Log-Likelihood, NLL）？**
>
> 我们通常使用 最大似然估计（MLE） 来训练模型，也就是：
> $$
> 最大化 \log p_θ(x)
> $$
> 而在实际优化中，我们通常 **最小化损失函数**，所以把最大化问题改写为一个最小化问题：
> $$
> \min_\theta \, -\log p_\theta(x)
> $$
> **为什么要取对数？**
>
> 1. 数值稳定性：
>
>    概率密度值通常很小（比如 $10^{-10}$，甚至更小），直接乘积容易下溢，取对数变加法，避免数值问题。
>
> 2. 简化梯度计算：
>
>    对数可以把连乘变成连加，更容易计算梯度、优化，比如：
>    $$
>    \log \prod_i p_\theta(x_i) = \sum_i \log p_\theta(x_i)
>    $$
>    所以对于多个样本（或时间步骤）时非常方便。
>
> **总结：**
>
> 最小化负对数似然（NLL） = 最大化对数似然 = 最大化似然

我们从负对数似然函数出发。在构造变分下界（ELBO）时，我们是通过人为引入 KL 散度的非负性来得到一个可优化的下界：
$$
-\log p_\theta(x_0)
\leq -\log p_\theta(x_0) + D_{\mathrm{KL}}(q(x_{1:T}|x_0) \,\|\, p_\theta(x_{1:T}|x_0)) \\
= -\log p_\theta(x_0) + \mathbb{E}_{x_{1:T} \sim q(x_{1:T}|x_0)} \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{1:T}|x_0)} \right]
$$

> **如何理解人为引入 KL 散度的非负性来得到一个可优化的下界？**
>
> 一、我们要解决的问题：最大化似然
>
> 我们想训练一个模型，使得它最大化训练样本 $x_0$ 的对数似然，也就是：
> $$
> \max_\theta \, \log p_\theta(x)
> $$
> 但由于模型是通过某种复杂的 **隐变量过程（如扩散过程中的 $x_{1:T}$）**定义的，直接求这个对数似然非常困难，甚至无法直接计算。
>
> 二、引入后验的挑战：对数似然不好计算
>
> 根据概率的边缘化：
> $$
> p_\theta(x_0) = \int p_\theta(x_{1:T}, x_0) \, dx_{1:T} 
> = \int p_\theta(x_0 \mid x_{1:T}) p_\theta(x_{1:T}) \, dx_{1:T}
> $$
> 但由于这个积分过于复杂，**我们无法精确计算** $\log p_\theta(x_0)$，也就无法直接最大化它。
>
> 三、人为引入变分分布 $q(x_{1:T}|x_0)$
>
> 于是，我们**“人为地”引入一个辅助分布**（叫变分分布）$q(x_{1:T}|x_0)$，来代替模型的后验 $p_\theta(x_{1:T}|x_0)$，这是变分推断的核心策略。
>
> 然后我们引入 **KL 散度**（总是非负）：
> $$
> D_{\mathrm{KL}}\big(q(x_{1:T}|x_0) \,\|\, p_\theta(x_{1:T}|x_0)\big) \geq 0
> $$
> 把它加到目标函数上（注意是**“加”一个非负项，所以变成了一个下界**）：
> $$
> -\log p_\theta(x_0) \leq -\log p_\theta(x_0) + D_{\mathrm{KL}}(q \| p_\theta)
> $$
> 四、总结这句话的含义
>
> > “通过人为引入 KL 散度的非负性来得到一个可优化的下界”，分解如下：
>
> - “人为引入”：我们不是自然地得到这个 KL 项，而是**人为设计一个变分分布 $q(x_{1:T}|x_0)$** 来构造 KL。
>
> - “KL 散度的非负性”：KL 总是 ≥ 0，因此加到目标中不会违反数学原理。
>
> - “得到一个下界”：因为我们加了 KL 散度，我们对原始的 log-likelihood 得到一个**下界（ELBO）**。
>
> - “可优化”：这个下界可以被计算并用于梯度下降优化训练模型。
>
> 五、一个简单的比喻
>
> 你有一个山洞（log-likelihood），里面藏着黄金（最优模型参数），但你进不去（无法精确计算 log-likelihood）。于是你画了一个地图（变分分布），虽然不是最真实的地形（后验），但你通过地图可以知道自己最起码可以挖到哪里（ELBO）。然后你不断改进地图（优化 q 和模型），直到找到一个能尽量逼近山洞真实地形的路线。

> 个人理解：原始目标不可计算，因此自然无法使用自动微分计算梯度，导致无法直接做优化。通过引入变分分布 $q(x_{1:T}|x_0)$，我们把难算的积分变成了在 $q$ 下的**期望**。从而获得一个关于 $\theta$ 和 $q$ 参数的期望的ELBO，自动微分能无障碍计算梯度，从而进行梯度下降。
>
> > **为什么我通过估计一个变分下界就能够近似原始目标呢？**
> >
> > 个人理解：
> >
> > 一方面是ELBO是对数似然的下界，通过优化ELBO，间接最大化 $\log p_θ(x0)$ ；
> >
> > 另一方面是我引入的这个KL散度本身就直接衡量了代理值（变分下界ELBO）和真实对数似然之间的差距
> > $$
> > \log p_θ (x_0)−\text{ELBO}=D_{\mathrm{KL}}(q(x_{1:T}|x_0) \,\|\, p_\theta(x_{1:T}|x_0)) 
> > $$
> >
> > - KL 散度的值越小，说明 $q$ 越接近真实的后验 $p_\theta(x_{1:T}|x_0)$，
> > - 也就是说，**ELBO 越接近 $\log p_\theta(x_0)$，我们的代理目标就越准确。**
> >
> > 那么此时的优化目标就已经包含了对原始目标的近似了。

利用贝叶斯公式展开 $p_\theta(x_{1:T}|x_0)$：
$$
= -\log p_\theta(x_0) + \mathbb{E}_q \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T}) / p_\theta(x_0)} \right] \\
= -\log p_\theta(x_0) + \mathbb{E}_q \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} + \log p_\theta(x_0) \right]
$$
将 $\log p_\theta(x_0)$ 抵消后得到：
$$
= \mathbb{E}_q \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} \right]
$$
我们将其定义为变分下界（Variational Lower Bound, VLB）：
$$
\mathcal{L}_{\text{VLB}} = \mathbb{E}_{q(x_{0:T})} \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} \right] \geq -\mathbb{E}_q \log p_\theta(x_0)
$$
这说明我们可以通过最大化 $\mathcal{L}_{\text{VLB}}$ 来最小化负对数似然，即优化生成模型的目标。



------

使用 Jensen 不等式也很容易得到相同的结果。假设数据的真实分布为 $ q(x_0) $，模型的联合分布为 $ p_\theta(x_{0:T}) $，其中 $ x_0 $ 是观测数据，$ x_{1:T} $ 是潜变量（如扩散模型中的中间状态）。

我们想最小化交叉熵作为学习目标：
$$
\mathcal{L}_{\text{CE}} = -\mathbb{E}_{q(x_0)} \log p_\theta(x_0)
$$
其中 $p_\theta(x_0)$ 是模型给出的边缘概率。

> 模型定义了一个联合分布：
> $$
> p_\theta(x_{0:T}) = p_\theta(x_0, x_1, \dots, x_T)
> $$
> 这里，
>
> - $x_0$ 是我们真正关心的观测数据（例如一张真实图片），
> - $x_{1:T}$ 是模型中的潜变量（latent variables），比如扩散模型中的多个中间状态。

第一步：边缘概率难以直接计算，需要对潜变量积分

模型的边缘概率  $ p_\theta(x_0) $ 是对联合分布 $ p_\theta(x_{0:T}) $ 在潜变量上的积分：
$$
p_\theta(x_0) = \int p_\theta(x_{0:T}) \, dx_{1:T}
$$

> **边缘概率 $p_\theta(x_0)$** 是从联合分布中“忽略”潜变量 $ x_{1:T} $，只关心 $x_0$ 的概率：
> $$
> p_\theta(x_0) = \int p_\theta(x_0, x_1, \dots, x_T) \, dx_1 \cdots dx_T
> $$
> 也就是说，边缘概率就是把潜变量“积分掉”后，模型对观测数据 $x_0$ 的整体概率分布。

所以交叉熵可写为：
$$
\mathcal{L}_{\text{CE}} = -\mathbb{E}_{q(x_0)} \log \left( \int p_\theta(x_{0:T}) \, dx_{1:T} \right)
$$
第二步：引入变分分布 $ q(x_{1:T} | x_0) $ 把积分写成期望

这是变分推断的关键技巧，我们在积分中乘除上相同的量：
$$
\int p_\theta(x_{0:T}) \, dx_{1:T} = \int q(x_{1:T}|x_0) \cdot \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \, dx_{1:T}
$$
所以可以写成期望形式：
$$
\mathcal{L}_{\text{CE}} = -\mathbb{E}_{q(x_0)} \log \left( \mathbb{E}_{q(x_{1:T}|x_0)} \left[ \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \right] \right)
$$
第三步：使用 Jensen 不等式

因为 $\log$ 是 concave 函数，我们可以使用 Jensen 不等式将 $\log$ 移入期望：

> Jensen 不等式利用对数的凹性，将对数期望变成期望对数，得到下界

$$
\log \mathbb{E}[X] \geq \mathbb{E}[\log X] \quad \Rightarrow \quad -\log \mathbb{E}[X] \leq - \mathbb{E}[\log X]
$$

应用公式中就是：
$$
\mathcal{L}_{\text{CE}} = -\mathbb{E}_{q(x_0)} \log \left( \mathbb{E}_{q(x_{1:T}|x_0)} \left[ \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \right] \right) 
\leq -\mathbb{E}_{q(x_0)} \mathbb{E}_{q(x_{1:T}|x_0)} \log \left( \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \right)
$$
换顺序（合并期望）：
$$
= \mathbb{E}_{q(x_{0:T})} \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} \right]
$$
最后我们得到了变分下界：
$$
\mathcal{L}_{\text{VLB}} = \mathbb{E}_{q(x_{0:T})} \left[ \log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})} \right]
$$
也就是交叉熵的上界（因为 Jensen 是反向的）：
$$
\mathcal{L}_{\text{CE}} \leq \mathcal{L}_{\text{VLB}}
$$

> 总结：
>
> - 目标是最小化 $ -\log p_\theta(x_0) $，但 $ p_\theta(x_0) $ 需要积分，难以直接计算。
> - 引入变分分布 $ q(x_{1:T}|x_0) $，把积分写成一个期望。
> - 利用 Jensen 不等式，把 $\log$ 外面的期望换成 $\log$ 内的期望，从而形成可 tractable 的表达式。
> - 得到的是一个可优化的上界：变分下界（VLB），作为训练目标。

这个过程是变分推断和扩散模型训练中的核心技巧。训练时优化的实际上是这个变分下界 $\mathcal{L}_{\text{VLB}}$，它是交叉熵的上界，也是 ELBO（Evidence Lower Bound）的负值形式

> **变分下界的物理意义**
>
> - $q(x_{1:T}|x_0)$ 是对潜变量的近似后验。通过选择合适的 $q$，使得变分下界尽可能接近真实的对数边缘似然。
> - 优化 $\mathcal{L}_{\text{VLB}}$ 意味着同时让模型分布 $p_\theta$ 和变分分布 $q$ 之间的 KL 散度尽可能小，从而提升模型对观测数据的拟合能力。

------

为了将变分下界方程中的每一项都转换使其可分析计算，可以将目标进一步重写为几个 KL 散度和熵项的组合:

$$
L_{\text{VLB}} = \mathbb{E}_{q(x_{0:T})} \left[ \log \frac{q(x_{1:T} | x_0)}{p_\theta(x_{0:T})} \right]
$$

> 注意这里：
>
> - $q(x_{0:T}) = q(x_0) q(x_{1:T} | x_0)$
> - 由于 $x_0 \sim q(x_0)$ 是已知的真实样本，所以只需要考虑 $x_{1:T} | x_0$

展开联合分布形式：
$$
= \mathbb{E}_q \left[ \log \frac{ \prod_{t=1}^T q(x_t | x_{t-1}) }{ p_\theta(x_T) \prod_{t=1}^T p_\theta(x_{t-1} | x_t) } \right]
$$
将分子分母拆开对数：
$$
= \mathbb{E}_q \left[ - \log p_\theta(x_T) + \sum_{t=1}^T \log \frac{q(x_t | x_{t-1})}{p_\theta(x_{t-1} | x_t)} \right]
$$
我们可以将第一项和第二项拆开来看：

- 对 $ t = 1 $ 时：
  $$
  \log \frac{q(x_1 | x_0)}{p_\theta(x_0 | x_1)} + \log \frac{1}{p_\theta(x_T)} = \log \frac{q(x_1 | x_0)}{p_\theta(x_0 | x_1)} + \log \frac{1}{p_\theta(x_T)}
  $$

- 对 $ t \geq 2 $ 时：
  $$
  \sum_{t=2}^{T} \log \frac{q(x_t | x_{t-1})}{p_\theta(x_{t-1} | x_t)}
  $$

但我们没有 $q(x_{t-1}|x_t)$，因为正向模型是 $q(x_t|x_{t-1})$，不是反向的条件概率。

我们引入真实后验 $ q(x_{t-1}|x_t, x_0) $ 来帮助计算 KL 散度，并重写为：
$$
= \mathbb{E}_q \left[ -\log p_\theta(x_T) + \sum_{t=2}^{T} \log \frac{q(x_{t-1}|x_t, x_0)}{p_\theta(x_{t-1} | x_t)} + \log \frac{q(x_t | x_{t-1})}{q(x_{t-1}|x_t, x_0)} + \log \frac{q(x_1 | x_0)}{p_\theta(x_0 | x_1)} \right]
$$

> 注意这个变换并没有改变原式的值，因为：
> $$
> \log \frac{a}{b} = \log \frac{c}{b} + \log \frac{a}{c}
> $$
> 这种技巧可以把一项分解成**一个 KL 散度 + 一项我们可以消掉的交叉项**。

其中：

- 使用了 $ \frac{q(x_t|x_{t-1})}{q(x_{t-1}|x_t,x_0)} $ 的变换，使 KL 更易处理
- 最后一项变为重建项 $ -\log p_\theta(x_0|x_1) $

最终我们得到如下组合形式：
$$
L_{\text{VLB}} = \underbrace{ \mathbb{E}_q \left[ D_{\text{KL}}(q(x_T|x_0) \| p_\theta(x_T)) \right] }_{L_T}
+ \sum_{t=2}^{T} \underbrace{ \mathbb{E}_q \left[ D_{\text{KL}}(q(x_{t-1}|x_t, x_0) \| p_\theta(x_{t-1}|x_t)) \right] }_{L_{t-1}}
- \underbrace{ \mathbb{E}_q \left[ \log p_\theta(x_0 | x_1) \right] }_{L_0}
$$
我们分别标记变分下界损失中的每个分量（写为若干项的加和）：
$$
L_{\text{VLB}} = L_T + L_{T-1} + \cdots + L_0
$$
其中各项定义如下：

- 终止项（Prior 约束项）：
  $$
  L_T = D_{\text{KL}}(q(\mathbf{x}_T | \mathbf{x}_0) \;\| \; p_\theta(\mathbf{x}_T))
  $$
  该项衡量的是数据终点在先验分布下的拟合程度。

- 中间项（时间步 KL 项）（对于 $1 \leq t \leq T-1$）：
  $$
  L_t = D_{\text{KL}}(q(\mathbf{x}_t | \mathbf{x}_{t+1}, \mathbf{x}_0) \;\| \; p_\theta(\mathbf{x}_t | \mathbf{x}_{t+1}))
  $$
  此项用于约束每个中间时间步的推理分布与模型的逆扩散过程匹配。

- 重建项（Likelihood 项）：
  $$
  L_0 = - \log p_\theta(\mathbf{x}_0 | \mathbf{x}_1)
  $$
  该项衡量的是模型还原出原始数据 $\mathbf{x}_0$ 的能力。



将上述每一项代入主公式，即构成了完整的 VLB 损失：
$$
L_{\text{VLB}} = D_{\text{KL}}(q(\mathbf{x}_T | \mathbf{x}_0) \;\| \; p_\theta(\mathbf{x}_T)) + \sum_{t=1}^{T-1} D_{\text{KL}}(q(\mathbf{x}_t | \mathbf{x}_{t+1}, \mathbf{x}_0) \;\| \; p_\theta(\mathbf{x}_t | \mathbf{x}_{t+1})) - \log p_\theta(\mathbf{x}_0 | \mathbf{x}_1)
$$
在变分下界 $L_{\text{VLB}}$ 中，除了 $L_0$ 以外的每一个 KL 项都比较了两个高斯分布，因此它们可以使用封闭形式（closed-form）进行计算。

其中：

- $L_T$ 是一个常数项，可以在训练过程中忽略，因为：
  - 它不依赖于可学习的参数；
  - $\mathbf{x}_T$ 是从一个固定的高斯噪声分布中采样得到的。

> 参考文献 [Ho et al., 2020](https://arxiv.org/abs/2006.11239) 提出：
>
> 使用一个从 $\mathcal{N}(\mathbf{x}_0; \boldsymbol{\mu}_\theta(\mathbf{x}_1, 1), \boldsymbol{\Sigma}_\theta(\mathbf{x}_1, 1))$ 推导出的独立的离散解码器（discrete decoder）来模拟 $L_0$。

这种处理方式使得模型训练更稳定，并将 $L_0$ 看作一种重建损失（reconstruction loss）。

 



#### 1.2.4 DDPM的训练

##### a. 训练损失 $L_t$ 的参数化

回忆一下，我们之前说到需要学习一个神经网络来近似模拟在逆扩散过程中的条件概率分布 $p_θ(x_{t−1}∣x_t)=N(x_{t−1};μ_θ(x_t,t),∑_θ(x_t,t))$ 。我们希望 $μ_θ$ 来预测 $μ~t=1αt(xt−βt1−α¯tzt)$ .因为我们已经有了 $xt$ 作为训练时的输入，我们可以将高斯噪声项进行参数化，从而在时刻 $t$ 从 $x_t$ 来预测 $z_t$ 。

 $\mu_\theta(\mathbf{x}_t, t)$ 的表达式：
$$
\mu_\theta(\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_\theta(\mathbf{x}_t, t) \right)
$$

> 其中：
>
> - $\alpha_t$, $\bar{\alpha}_t$：是时间步 $t$ 的调度参数（noise schedule）；
> - $\beta_t = 1 - \frac{\alpha_t}{\alpha_{t-1}}$：是每步添加的噪声比例；
> - $\mathbf{z}_\theta(\mathbf{x}_t, t)$：神经网络预测的噪声；
> - $\mu_\theta$：目标高斯分布的均值

从逆扩散分布中采样的方式：
$$
\mathbf{x}_{t-1} \sim \mathcal{N}\left(\mu_\theta(\mathbf{x}_t, t), \Sigma_\theta(\mathbf{x}_t, t)\right)
$$
展开写就是：
$$
\mathbf{x}_{t-1} \sim \mathcal{N}\left( \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_\theta(\mathbf{x}_t, t) \right), \Sigma_\theta(\mathbf{x}_t, t) \right)
$$
损失项 $L_t$ 被参数化，从而最小化它与 $\tilde{μ}_t$ 的差距。

我们希望学习的模型均值 $\mu_\theta(\mathbf{x}_t, t)$ 趋近于真实均值 $\tilde{\mu}_t(\mathbf{x}_t, \mathbf{x}_0)$，于是损失定义为：
$$
L_t = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \left[ \frac{1}{2 \| \Sigma_\theta(\mathbf{x}_t, t) \|_2^2} \left\| \tilde{\mu}_t(\mathbf{x}_t, \mathbf{x}_0) - \mu_\theta(\mathbf{x}_t, t) \right\|_2^2 \right]
$$
将两者的表达式带入：

- $\tilde{\mu}_t = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_t \right)$
- $\mu_\theta = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \mathbf{z}_\theta(\mathbf{x}_t, t) \right)$

两者相减后，消去公共项 $\frac{1}{\sqrt{\alpha_t}} \mathbf{x}_t$，得到的是对噪声项差异的度量：
$$
L_t = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \left[ \frac{\beta_t^2}{2 \alpha_t (1 - \bar{\alpha}_t) \| \Sigma_\theta \|_2^2} \left\| \mathbf{z}_t - \mathbf{z}_\theta(\mathbf{x}_t, t) \right\|_2^2 \right]
$$
最后用到了前向过程中的表达式：
$$
\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \mathbf{z}_t
$$
所以我们可以将 $\mathbf{x}_t$ 替换掉，只用 $\mathbf{x}_0$ 和 $\mathbf{z}_t$ 表达模型输入：
$$
L_t = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \left[ C_t \cdot \left\| \mathbf{z}_t - \mathbf{z}_\theta(\sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \mathbf{z}_t, t) \right\|_2^2 \right]
$$

$$
C_t = \frac{\beta_t^2}{2 \alpha_t (1 - \bar{\alpha}_t) \| \Sigma_\theta \|_2^2}
$$

根据经验，[Ho et al. (2020)](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2006.11239) 发现，在忽略加权项的简化目标函数下，扩散模型可以训练得效果更好：
$$
L_t^{\text{simple}} = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}, t} \left[ \left\| \mathbf{z}_t - \mathbf{z}_\theta\left( \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \mathbf{z}_t, t \right) \right\|_2^2 \right]
$$

> **为什么这种简化有效？**
>
> 在原始推导中我们知道，训练目标是最小化预测均值的误差，即：
> $$
> \| \tilde{\mu}_t - \mu_\theta \|^2
> $$
> 但由于真实均值依赖于真实数据 $\mathbf{x}_0$，而预测均值依赖于网络参数，因此通过变量替换可以转换成对**高斯噪声 $\mathbf{z}$**的预测。
>
> **更稳定**：去掉了动态的加权系数 $\frac{\beta_t^2}{2\alpha_t(1 - \bar{\alpha}_t)}$，训练更加平滑。
>
> **直接学习噪声**：模型 $\mathbf{z}_\theta$ 直接学习去噪，从而可以反推出 $\mathbf{x}_0$，简化采样过程。



因此最终简化后得目标函数为：
$$
L_{\text{simple}} = L_t^{\text{simple}} + C_t
$$
其中， $C_t$ 是一个与 $θ$ 无关的常量。



##### b. 训练与推理过程伪代码

> **训练伪代码**
>
> - $\textbf{repeat}$
>
>   - $x_0 \sim q(x_0)$ 
>
>     从真实数据分布采样
>
>   - $t \sim \text{Uniform}(\{1, \ldots, T\})$
>
>     随机选择时间步
>
>   - $\epsilon \sim \mathcal{N}(0, I)$ 
>
>     生成高斯噪声
>
>   - $x_t = \sqrt{\alpha_t} x_0 + \sqrt{1 - \alpha_t} \epsilon$ 
>
>     构造带噪样本
>
>   - 梯度下降更新：$\nabla_\theta \left\| \epsilon - z_\theta(x_t, t) \right\|^2$
>
> - $\textbf{until}$ 收敛

> **采样伪代码**
>
> - $x_T \sim \mathcal{N}(0, I)$ 
>
>   初始化标准高斯噪声
>
> - $\textbf{for}$  $x_T \sim \mathcal{N}(0, I)$  $\textbf{do}$
>
>   - $z \sim \mathcal{N}(0, I)$  $\textbf{if}$  $t > 1$  $\textbf{else}$  $z = 0$
>   - $x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \Big( x_t - \frac{1-\alpha_t}{\sqrt{1-\alpha_t}} z_\theta(x_t, t) \Big) + \sigma_t z$
>
> - $\textbf{end for}$
>
> - $\textbf{return}$ $x_0$
>
>   生成最终样本





## 2. DDIM（TODO）

DDIM: Denoising Diffusion Implicit Models | DaNing的博客
https://adaning.github.io/posts/40650.html

《Denoising Diffusion Implicit Models》https://arxiv.org/abs/2010.02502



在DDPM中我们提到, 其前向过程和反向过程都是在**一阶马尔科夫链**下定义的。但是依赖马尔科夫链的DDPM生成速度非常慢, 有没有什么办法来加速采样, 实现更高效率的生成呢?

要是能在这个基础上和DDPM的前向过程兼容, 只改变反向过程, 以此达到复用训练好的DDPM模型权重的目的就更好了。



### 2.1 非马尔可夫前向过程的变分推断

> **我们有DDPM训练目标：**
> $$
> L_t = \mathbb{E}_{\mathbf{x}_0, \mathbf{z}} \left[ C_t \cdot \left\| \mathbf{z}_t - \mathbf{z}_\theta(\sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \mathbf{z}_t, t) \right\|_2^2 \right]
> $$
>
> $$
> C_t = \frac{\beta_t^2}{2 \alpha_t (1 - \bar{\alpha}_t) \| \Sigma_\theta \|_2^2}
> $$
>

通过对DDPM的训练目标 $L_t$ 的观察, 发现 $L_t$ 实际上只取决于边缘分布$q(x_t∣x_0)$ , 而不是取决于联合分布 $q(x_{1:T}∣x_0)$ 。 因此可以考虑将 $q(x_t∣x_0)$ 推导过程中的遵循马尔科夫假设的 $q(x_t∣x_{t−1})$ 剥离, 建立一个非马尔科夫前向过程, 从而得到一个新的反向过程与生成过程.

> 因此这个观察也给我们一个启发, 只要任何满足DDPM条件, 且能保证模型具有等价目标函数的前向过程设计都是可行的.



#### 2.1.1 非马尔可夫前向过程

我们不考虑马尔科夫性依赖时，可以将前向过程写成一组由方差 $σ$ 控制的分布：

$$
q_σ(\mathbf{x}_{1:T} \mid \mathbf{x}_0) := q_σ(\mathbf{x}_T \mid \mathbf{x}_0) \prod_{t=2}^T q_σ(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)
$$
由于DDPM的定义，所以需要满足 $t>1$ 时，$q_σ(\mathbf{x}_T \mid \mathbf{x}_0) = \mathcal{N}(\sqrt{\bar{\alpha}_T} \mathbf{x}_0, (1 - \bar{\alpha}_T) \mathbf{I})$ ，即 $q_σ(\mathbf{x}_T \mid \mathbf{x}_0)$ 已知。

> 其中：
>
> - $\mathbf{x}_0$ 为原始图像或数据（通常来自真实数据分布 $q(\mathbf{x}_0)$）
> - $\mathbf{x}_t$ 为第 $t$ 步的中间状态，是逐步添加噪声后的图像或数据
> - $T$ 为前向过程的总步数
> - $q_σ(\cdot)$ 为前向过程的联合概率分布，受方差控制
> - $q_σ(\mathbf{x}_{1:T} \mid \mathbf{x}_0)$ 为给定原始数据 $\mathbf{x}_0$，整个噪声过程从 1 到 $T$ 步的联合分布
>
> - $q_σ(\mathbf{x}_T \mid \mathbf{x}_0)$ 为给定原始数据 $\mathbf{x}_0$，直接跳到第 $T$ 步的分布
> - $q_σ(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$ 为给定第 $t$ 步状态和原始数据的条件概率，描述 **从 $\mathbf{x}_{t}$ 到 $\mathbf{x}_{t-1}$ 的反向推理**
>
> - $\bar{\alpha}_T$ 为从时间 1 到 $T$ 的累计噪声衰减系数
> - $\mathbf{I}$ 为单位矩阵，代表各维度独立、协方差为单位值
>
> 而这里我们讨论的非马尔可夫性前向过程，意味着每一步的状态不仅依赖于前一状态，还可依赖原始状态 $\mathbf{x}_0$（这是合理的，因为我们可以显式知道 $q(\mathbf{x}_t \mid \mathbf{x}_0)$ 为高斯分布）。因此该表示形式允许我们构建一个 **完全基于 $\mathbf{x}_0$ 的分布族**，从 $\mathbf{x}*0$ 推出 $\mathbf{x}_{T}$，然后通过条件分布逐步重建前面的状态（如 $\mathbf{x}_{T-1}$、$\mathbf{x}_{T-2}$ 等）。

以上是 DDPM 中对完整前向过程联合分布的定义。

DDPM中出现的 $q_σ(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$ 被使用一阶马尔可夫链替换成 $q_σ(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$ 。若想拜托对马尔可夫链的依赖，这里肯定就不能再把它替换成 $q_σ(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$ 了，需要直接定义分布 $q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)$：
$$
q_\sigma(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N} \left( 
\sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \cdot \frac{\mathbf{x}_t - \sqrt{\bar{\alpha}_t} \mathbf{x}_0}{\sqrt{1 - \bar{\alpha}_t}}, \ \sigma_t^2 \mathbf{I}
\right)
$$

> 解释如下：
> - 这项直接指定均值和方差，而不使用马尔科夫链的递归结构。
> - 该公式允许在 $\sigma_t \to 0$ 时实现确定性生成（DDIM 模式），或在 $\sigma_t$ 较大时引入随机性（DDPM 模式）。

























# B. Flow Matching

通俗易懂的Flow Matching原理解读（附核心公式推导和源代码） - 知乎
https://zhuanlan.zhihu.com/p/4116861550























# C. Diffusion VS Flow Matching

https://diffusionflow.github.io/#closing-takeaways
