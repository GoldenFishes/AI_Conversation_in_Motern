# 1. Diffusion

DDPM解读（一）| 数学基础，扩散与逆扩散过程和训练推理方法 - 卡卡猡特的文章 - 知乎
https://zhuanlan.zhihu.com/p/530602852

## 2. DDPM

《Denoising Diffusion Probabilistic Models》[[2006.11239\] Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)

### 2.1 数学基础

#### 2.1.1 先验概率与后验概率

直观理解：

**先验概率 (Prior)**：在看到数据之前，你对某件事的**原本相信程度**。

**后验概率 (Posterior)**：在看到数据之后，你根据**数据更新后的相信程度**。

------

举个例子：

比如你丢一枚硬币，事先不知道是不是公平的。

- 你**先验地认为**，硬币正反面各 50%（也可能觉得偏某一边）。

后来你丢了 100 次，结果正面出来了 80 次，这个数据很不对劲。

- 根据数据，你**更新你的相信**，硬币可能是偏向正面的一枚。

这个从 "50%" 更新到 "更偏向正面" 的过程，就是：

> **先验 →（看见数据）→ 后验**

------

数学推导：

设

- 事件 $A$ 是我们关心的（比如，"硬币是偏的"）
- 数据 $B$ 是我们观察到的（比如，"丢了100次，正面出了80次"）

那么：
$$
\text{后验概率} = \frac{\text{似然} \times \text{先验概率}}{\text{证据}}
$$
公式写成：
$$
P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}
$$
其中：

- $P(A)$：**先验概率**，观察数据前对 $A$ 的主观相信
- $P(B|A)$：**似然（Likelihood）**，如果 $A$ 成立，数据 $B$ 出现的概率
- $P(B)$：**证据（Evidence）**，所有可能情况下数据 $B$ 出现的总体概率
- $P(A|B)$：**后验概率**，看过数据 $B$ 后，对 $A$ 的相信程度



| 名称       | 含义                                   |
| ---------- | -------------------------------------- |
| 先验概率   | 看到数据前的主观相信程度               |
| 似然函数   | 如果假设成立，观察到数据的可能性有多大 |
| 后验概率   | 看到数据后，新的相信程度               |
| 贝叶斯公式 | 后验 = 似然 × 先验 / 证据              |



#### 2.1.2 条件概率的一般形式

**定义**：
 如果你已经知道了事件 $B$ 发生，那么在这种条件下，事件 $A$ 发生的概率，叫做 **条件概率**。

数学上，记作：
$$
P(A|B)
$$
**公式是**：
$$
P(A|B) = \frac{P(A \cap B)}{P(B)}
\quad\quad \text{(前提是 } P(B) > 0\text{)}
$$

------

如果你有三个事件 $A$、$B$、$C$，那么：

1. **联合概率** $P(A, B, C)$ 表示
    → $A$、$B$、$C$ 三个**同时发生**的概率。
2. **条件概率的一般形式**可以写成：

$$
P(A, B, C) = P(A|B, C) \times P(B|C) \times P(C)
$$



也可以理解成：

> 联合概率可以被分解成一连串的条件概率相乘。



#### 2.1.3 马尔可夫链条件概率形式

> 马尔可夫链（**Markov Chain**）里，条件概率有个非常重要、特别简洁的形式。
> $$
> P(Xn+1∣Xn,Xn−1,…,X1)=P(Xn+1∣Xn)
> $$

马尔科夫链指当前状态的概率只与上一时刻有关，例如如满足马尔可夫关系 A→B→C ，ABC符合马尔可夫性质，那么我们可以用链式法则展开联合概 $P(A, B, C)$ :
$$
P(A,B,C)=P(A)⋅P(B∣A)⋅P(C∣B)
$$

> 马尔可夫链指当前状态的概率只与上一时刻有关，例如 $A \rightarrow B \rightarrow C$，那么有：
> $$
> P(C∣B,A)=P(C∣B)
> $$
> 马尔可夫性质。



#### 2.1.4 高斯分布的KL散度公式

设有两个一维高斯分布：

- $ p(x) = \mathcal{N}(\mu_p, \sigma_p^2) $

- $ q(x) = \mathcal{N}(\mu_q, \sigma_q^2) $

则 KL 散度 $ D_{\text{KL}}(p \,\|\, q) $ 的计算公式为：

$$
D_{\text{KL}}(p \,\|\, q) = \log\left( \frac{\sigma_q}{\sigma_p} \right) + \frac{\sigma_p^2 + (\mu_p - \mu_q)^2}{2\sigma_q^2} - \frac{1}{2}
$$
参数解释：

> 1. **第一项：**  $\log\left( \frac{\sigma_q}{\sigma_p} \right)$
>
>    反映两个分布在方差上的差异。
>
> 2. **第二项：**  $\frac{\sigma_p^2 + (\mu_p - \mu_q)^2}{2\sigma_q^2}$
>
>    包含：
>
>    - $\frac{\sigma_p^2}{2\sigma_q^2}$：分布宽度差异；
>    - $\frac{(\mu_p - \mu_q)^2}{2\sigma_q^2}$：均值之间的差异。
>
> 3. **第三项：**  $- \frac{1}{2}$
>
>    归一化常数，使散度为零时，代表两个分布完全相同。

特殊情况（均值相同）：

若 $mu_p = \mu_q$，KL 散度简化为：

$$
D_{\text{KL}}(p \,\|\, q) = \log\left( \frac{\sigma_q}{\sigma_p} \right) + \frac{\sigma_p^2}{2\sigma_q^2} - \frac{1}{2}
$$
注：

- KL 散度 $ D_{\text{KL}}(p \,\|\, q) \geq 0 $，当且仅当 $ p = q $ 时取到 0；

- KL 散度是非对称的：
  $$
  D_{\text{KL}}(p \,\|\, q) \neq D_{\text{KL}}(q \,\|\, p)
  $$



#### 2.1.5 参数重整化（重参数技巧）

我们希望从一个高斯分布中采样：
$$
x \sim \mathcal{N}(\mu, \sigma^2)
$$
但由于采样操作不可导，无法直接用于反向传播。为了解决这个问题，我们使用重参数化技巧，将随机性转移到一个独立于模型参数的随机变量中。



**重参数化形式**

我们引入标准正态变量：
$$
z \sim \mathcal{N}(0, 1)
$$
然后构造采样变量：
$$
x = \mu + \sigma \cdot z
$$
这样，$ x $ 的分布为：
$$
x \sim \mathcal{N}(\mu, \sigma^2)
$$


这么做的好处：
- 将不可导的采样操作转化为可导的仿射变换；
- 使得模型在训练过程中可以使用反向传播更新 $ \mu $ 和 $ \sigma $；
- 是变分推断中训练 VAE（Variational Autoencoder）的关键技术。



**注意事项**

- 为保证正值，通常使用 $\log \sigma^2$ 表示，训练过程中实际预测的是 $\log \sigma^2$，然后用 $\exp(\frac{1}{2} \log \sigma^2)$ 计算 $\sigma$；

- 重参数化技巧仅适用于可以重参数化的分布（如高斯分布），对于离散分布则较为困难。



### 2.2 DDPM模型

#### 2.2.1 模型总览

DDPM，全称 **Denoising Diffusion Probabilistic Model**，是一种基于**马尔可夫链的生成模型**。

![img](./asset/v2-c77c080d146c4e9d9edf17e264ebdb98_r.jpg)



DDPM模型主要分为两个过程：forward加噪过程（从右往左）和reverse去噪过程（从左往右）。

模型通过逐步添加噪声和反向去噪学习数据分布。



#### 2.2.2 Diffusion扩散过程（Forward加噪过程）

**逐步加噪过程**

给定初始数据分布 $q(x_0)$（例如图像分布），我们定义一个前向扩散过程，在这个过程中逐步向数据中添加高斯噪声，使得原始数据在 $T$ 步之后几乎退化成各向同性高斯分布。

在这个持续 $T$ 次的加噪过程中，我们会产生一系列带噪声的图片 $x_1, ..., x_T$ 。在这个过程中，噪声的标准差/方差是以一个在区间 (0,1) 内的固定值 $β_T$ 来确定的，均值是以固定值 $β_T$ 和当前时刻的图片数据 $x_{t−1}$ 来确定的。



**加噪过程定义**

对于 $t = 1, 2, ..., T$，我们定义马尔可夫过程：

$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)
$$
其中：

- $\beta_t \in (0, 1)$ 是一个预设的固定方差调度表（称为 noise schedule），通常线性或余弦方式递增；
- $\sqrt{1 - \beta_t}$ 是该步的缩放因子。



> **加噪过程的另一种表示**
>
> 每一步的加噪过程如下：
>
> $$
> q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
> $$
>
> $$
> \bar{\alpha}_t = \prod_{i=1}^T (1 - \alpha_i)
> $$
>
> $$
> \alpha_t = 1- \beta_t
> $$
>
> 
>
> - 这是一个高斯分布，其 **均值** 为 $\sqrt{\bar{\alpha}_t} x_0$，**方差** 为 $1 - \bar{\alpha}_t$；
> - 其中 $\bar{\alpha}_t = \prod_{i=1}^T (1 - \alpha_i)$ 是噪声衰减因子；
> - 因为 $\beta_t$ 是预定义的 schedule，所以 $\bar{\alpha}_t$ 也是固定的；
> - 因此，这个分布完全由 $x_0$ 和 $t$ 决定 —— 无需学习，**不是模型的一部分**。



**加噪结果**

随着 $t$ 的不断增大，最终原始数据 $x_0$ 会逐步失去它的特征。最终当 $T→∞$ 时， $x_T$ 趋近于一个各向独立的高斯分布。从视觉上来看，就是将原本一张完好的照片加噪很多步后，图片几乎变成了一张完全是噪声的图片。



**任意时刻数据 $X_t$ 的计算（参数重整化技巧）**

在前向扩散过程中，虽然 $x_t$ 是通过从 $x_{t-1}$ 不断加噪得到的，但我们其实可以跳过中间所有步骤，直接从 $x_0$ 和固定值序列 $\{β_T∈(0,1)\}_{t=1}^T $ 计算得到任意时刻 $x_t$ 

我们首先定义:
$$
\alpha_t = 1 - \beta_t
$$

$$
\bar{\alpha}_t = \prod_{i=1}^t \alpha_i = \prod_{i=1}^t (1 - \beta_i)
$$

我们可以直接通过下式采样得到某一时刻 $t$ 的带噪图像 $x_t$：
$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
$$
推导步骤：

> 我们希望从以下马尔可夫链定义的前向过程：
>
> $$
> q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{\alpha_t} x_{t-1}, (1 - \alpha_t) \mathbf{I})
> $$
>
> 推导出：
>
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 其中：
>
> - $\bar{\alpha}_t = \prod_{i=1}^t \alpha_i$
>
> 
>
> **推导过程**
>
> 首先，从一步扩散定义：
> $$
> x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1 - \alpha_t} \epsilon_t,\quad \epsilon_t \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 这表示 $x_t$ 是上一步 $x_{t-1}$ 的缩放加上独立高斯噪声的结果。
>
> 展开两步（将 $x_{t-1}$ 用 $x_{t-2}$ 表示）：
> $$
> x_{t-1} = \sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-1}
> $$
>
> 代入 $x_t$ 的公式中得到：
>
> $$
> x_t = \sqrt{\alpha_t} \left( \sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-1} \right) + \sqrt{1 - \alpha_t} \epsilon_t
> $$
>
> 继续展开并整理：
>
> $$
> x_t = \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1-\alpha_t \alpha_{t-1}} \bar\epsilon_{t-2}，\quad(*)
> $$
>
> 你可以看到，每次展开我们都得到一个 $x_0$ 的缩放加上一系列噪声项的线性组合。
>
> > **关键技巧** $(*)$ :
> >
> > 这里使用了一个关键技巧，在 Diffusion 模型中常用于将**多步高斯噪声组合**成**一步标准高斯噪声**的形式，也叫**参数重整化**。
> >
> > 当我们合并两个均值都为 0，方差分别为 $\sigma_1^2$ 和 $\sigma_2^2$ 的高斯分布 $\mathcal{N}(0, \sigma_1^2 I)$ 和 $\mathcal{N}(0, \sigma_2^2 I)$ 时，我们得到的新的高斯分布为：
> > $$
> > \sqrt{\alpha_t - \alpha_t \alpha_{t-1}} z_{t-2} + \sqrt{1 - \alpha_t} z_{t-1}
> > $$
> > 因此可以通过参数重整化，变成只含一个随机变量 $z$ 构成的：
> > $$
> > \sqrt{1 - \bar{\alpha}_t} \cdot \bar{z}_t
> > $$
> > 的形式
>
> 继续递推 $t$ 次，可以得到一个形式：
>
> 继续这样递推下去 $t$ 次，可以得到一个形式：
>
> $$
> x_t = \sqrt{\prod_{i=1}^t \alpha_i} \cdot x_0 + \sum_{i=1}^t \text{噪声项}
> $$
>
> 通过定义：
>
> $$
> \bar{\alpha}_t = \prod_{i=1}^t \alpha_i
> $$
> 我们得到：
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 这里的 $\epsilon$ 是一系列高斯噪声线性组合后的结果。由于线性组合仍是高斯分布，它等价于一个新的标准正态随机变量。
>
> 
>
> **结论：**
>
> 最终我们推导出：
> $$
> x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,\quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
> $$
>
> 该公式允许我们跳过逐步采样过程，直接从 $x_0$ 构造出 $x_t$ 。这意味着我们**不需要一步一步模拟 $x_1 \to x_2 \to \dots \to x_t$ 的过程**，只需要用初始图像 $x_0$ 和随机噪声 $\epsilon$ 即可直接生成任意时间步的 $x_t$ 。
>
> 这一步是训练阶段的关键，它使得我们可以构造任意时间步的训练样本 $x_t$ 来训练一个模型预测 $\epsilon$ 。









(*) 这里注意：当我们合并两个均值都为0，方差分别为 $σ_1^2$ 和 $σ_2^2$ 的高斯分布 N(0,σ12I) 和 N(0,σ22I) 时，我们得到的新的高斯分布为 αt−αtαt−1zt−2+1−αtzt−1 。因此可以通过参数重整化，变成只含一个随机变量 z 构成的 1−αtαt−1z¯t−2 形式。



























































#### 2.2.3 Reverse Diffusion逆扩散过程（Reverse去噪过程）













#### 2.2.4 DDPM的训练











# 2. Flow Matching

























# 3. Diffusion VS Flow Matching

https://diffusionflow.github.io/#closing-takeaways
